{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4382912",
   "metadata": {},
   "source": [
    "# 영화 총 상영주차 예측"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d872291",
   "metadata": {},
   "source": [
    "## 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f73a23ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "124c9c29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movie_Title</th>\n",
       "      <th>Total_Audience_Count</th>\n",
       "      <th>Total_Show_Days</th>\n",
       "      <th>Total_Weeks</th>\n",
       "      <th>wk1_Audience</th>\n",
       "      <th>wk1_AudiencePerShow</th>\n",
       "      <th>wk2_Audience</th>\n",
       "      <th>wk2_AudiencePerShow</th>\n",
       "      <th>Show_Change</th>\n",
       "      <th>opening_Ho_Retention</th>\n",
       "      <th>...</th>\n",
       "      <th>e247</th>\n",
       "      <th>e248</th>\n",
       "      <th>e249</th>\n",
       "      <th>e250</th>\n",
       "      <th>e251</th>\n",
       "      <th>e252</th>\n",
       "      <th>e253</th>\n",
       "      <th>e254</th>\n",
       "      <th>e255</th>\n",
       "      <th>e256</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>도쿄 리벤저스</td>\n",
       "      <td>13122</td>\n",
       "      <td>47</td>\n",
       "      <td>8</td>\n",
       "      <td>8617.0</td>\n",
       "      <td>5.654199</td>\n",
       "      <td>2925</td>\n",
       "      <td>5.034423</td>\n",
       "      <td>0.381234</td>\n",
       "      <td>0.130780</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014526</td>\n",
       "      <td>-0.000427</td>\n",
       "      <td>-0.020264</td>\n",
       "      <td>-0.001076</td>\n",
       "      <td>-0.061279</td>\n",
       "      <td>-0.018188</td>\n",
       "      <td>-0.023438</td>\n",
       "      <td>0.012329</td>\n",
       "      <td>0.036133</td>\n",
       "      <td>0.010742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>매직브러시</td>\n",
       "      <td>169106</td>\n",
       "      <td>36</td>\n",
       "      <td>8</td>\n",
       "      <td>145560.0</td>\n",
       "      <td>37.670807</td>\n",
       "      <td>18117</td>\n",
       "      <td>14.717303</td>\n",
       "      <td>0.318582</td>\n",
       "      <td>0.182869</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.022339</td>\n",
       "      <td>-0.037598</td>\n",
       "      <td>-0.021973</td>\n",
       "      <td>0.033936</td>\n",
       "      <td>-0.026855</td>\n",
       "      <td>0.005646</td>\n",
       "      <td>0.013794</td>\n",
       "      <td>-0.010071</td>\n",
       "      <td>0.014709</td>\n",
       "      <td>0.017578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>숨바꼭질</td>\n",
       "      <td>656089</td>\n",
       "      <td>48</td>\n",
       "      <td>8</td>\n",
       "      <td>195760.0</td>\n",
       "      <td>92.645528</td>\n",
       "      <td>307980</td>\n",
       "      <td>65.807692</td>\n",
       "      <td>2.214860</td>\n",
       "      <td>0.892172</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000511</td>\n",
       "      <td>-0.023926</td>\n",
       "      <td>-0.005707</td>\n",
       "      <td>-0.001305</td>\n",
       "      <td>-0.061523</td>\n",
       "      <td>-0.008118</td>\n",
       "      <td>-0.018921</td>\n",
       "      <td>0.002823</td>\n",
       "      <td>0.055176</td>\n",
       "      <td>0.015747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>해빙</td>\n",
       "      <td>1201576</td>\n",
       "      <td>52</td>\n",
       "      <td>9</td>\n",
       "      <td>906864.0</td>\n",
       "      <td>44.818820</td>\n",
       "      <td>232306</td>\n",
       "      <td>13.362439</td>\n",
       "      <td>0.859197</td>\n",
       "      <td>0.189943</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007996</td>\n",
       "      <td>-0.017456</td>\n",
       "      <td>0.000427</td>\n",
       "      <td>-0.008911</td>\n",
       "      <td>-0.024536</td>\n",
       "      <td>-0.024658</td>\n",
       "      <td>-0.013306</td>\n",
       "      <td>0.004303</td>\n",
       "      <td>0.047119</td>\n",
       "      <td>0.011414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>다시, 봄</td>\n",
       "      <td>25506</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>18609.0</td>\n",
       "      <td>5.126446</td>\n",
       "      <td>3969</td>\n",
       "      <td>3.598368</td>\n",
       "      <td>0.303857</td>\n",
       "      <td>0.028099</td>\n",
       "      <td>...</td>\n",
       "      <td>0.052734</td>\n",
       "      <td>-0.000683</td>\n",
       "      <td>-0.014465</td>\n",
       "      <td>0.025146</td>\n",
       "      <td>-0.018188</td>\n",
       "      <td>-0.022705</td>\n",
       "      <td>-0.027100</td>\n",
       "      <td>-0.036621</td>\n",
       "      <td>0.073242</td>\n",
       "      <td>-0.016113</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 280 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Movie_Title  Total_Audience_Count  Total_Show_Days  Total_Weeks  \\\n",
       "0     도쿄 리벤저스                 13122               47            8   \n",
       "1       매직브러시                169106               36            8   \n",
       "2        숨바꼭질                656089               48            8   \n",
       "3          해빙               1201576               52            9   \n",
       "4       다시, 봄                 25506               18            4   \n",
       "\n",
       "   wk1_Audience  wk1_AudiencePerShow  wk2_Audience  wk2_AudiencePerShow  \\\n",
       "0        8617.0             5.654199          2925             5.034423   \n",
       "1      145560.0            37.670807         18117            14.717303   \n",
       "2      195760.0            92.645528        307980            65.807692   \n",
       "3      906864.0            44.818820        232306            13.362439   \n",
       "4       18609.0             5.126446          3969             3.598368   \n",
       "\n",
       "   Show_Change  opening_Ho_Retention  ...      e247      e248      e249  \\\n",
       "0     0.381234              0.130780  ...  0.014526 -0.000427 -0.020264   \n",
       "1     0.318582              0.182869  ... -0.022339 -0.037598 -0.021973   \n",
       "2     2.214860              0.892172  ... -0.000511 -0.023926 -0.005707   \n",
       "3     0.859197              0.189943  ...  0.007996 -0.017456  0.000427   \n",
       "4     0.303857              0.028099  ...  0.052734 -0.000683 -0.014465   \n",
       "\n",
       "       e250      e251      e252      e253      e254      e255      e256  \n",
       "0 -0.001076 -0.061279 -0.018188 -0.023438  0.012329  0.036133  0.010742  \n",
       "1  0.033936 -0.026855  0.005646  0.013794 -0.010071  0.014709  0.017578  \n",
       "2 -0.001305 -0.061523 -0.008118 -0.018921  0.002823  0.055176  0.015747  \n",
       "3 -0.008911 -0.024536 -0.024658 -0.013306  0.004303  0.047119  0.011414  \n",
       "4  0.025146 -0.018188 -0.022705 -0.027100 -0.036621  0.073242 -0.016113  \n",
       "\n",
       "[5 rows x 280 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_data= pd.read_csv(\"C:/Users/강태희/Documents/BAF-25-2-Marketing/week_predict/full_data_for_week_predict.csv\")\n",
    "movie_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e5be468",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movie_Title</th>\n",
       "      <th>FA1</th>\n",
       "      <th>FA2</th>\n",
       "      <th>FA3</th>\n",
       "      <th>FA4</th>\n",
       "      <th>FA5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>도쿄 리벤저스</td>\n",
       "      <td>-0.581703</td>\n",
       "      <td>-0.873621</td>\n",
       "      <td>0.334321</td>\n",
       "      <td>-0.860584</td>\n",
       "      <td>-0.302076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>매직브러시</td>\n",
       "      <td>-0.235392</td>\n",
       "      <td>0.273776</td>\n",
       "      <td>-1.353467</td>\n",
       "      <td>-0.748044</td>\n",
       "      <td>-0.342353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>숨바꼭질</td>\n",
       "      <td>0.103283</td>\n",
       "      <td>2.615669</td>\n",
       "      <td>0.523378</td>\n",
       "      <td>1.502512</td>\n",
       "      <td>0.556472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>해빙</td>\n",
       "      <td>1.734376</td>\n",
       "      <td>-0.007841</td>\n",
       "      <td>0.617193</td>\n",
       "      <td>-1.091703</td>\n",
       "      <td>-0.357989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>다시, 봄</td>\n",
       "      <td>-0.598004</td>\n",
       "      <td>-0.887915</td>\n",
       "      <td>0.400546</td>\n",
       "      <td>-1.055799</td>\n",
       "      <td>-0.290591</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Movie_Title       FA1       FA2       FA3       FA4       FA5\n",
       "0     도쿄 리벤저스 -0.581703 -0.873621  0.334321 -0.860584 -0.302076\n",
       "1       매직브러시 -0.235392  0.273776 -1.353467 -0.748044 -0.342353\n",
       "2        숨바꼭질  0.103283  2.615669  0.523378  1.502512  0.556472\n",
       "3          해빙  1.734376 -0.007841  0.617193 -1.091703 -0.357989\n",
       "4       다시, 봄 -0.598004 -0.887915  0.400546 -1.055799 -0.290591"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fa_data= pd.read_csv(\"C:/Users/강태희/Documents/BAF-25-2-Marketing/week_predict/fa_data_for_week_predict.csv\")\n",
    "fa_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72958604",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movie_Title</th>\n",
       "      <th>hit_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>도쿄 리벤저스</td>\n",
       "      <td>중반 균형형</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>매직브러시</td>\n",
       "      <td>초반 폭발형</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>숨바꼭질</td>\n",
       "      <td>초반 폭발형</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>해빙</td>\n",
       "      <td>초반 폭발형</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>다시, 봄</td>\n",
       "      <td>중반 균형형</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Movie_Title hit_category\n",
       "0     도쿄 리벤저스       중반 균형형\n",
       "1       매직브러시       초반 폭발형\n",
       "2        숨바꼭질       초반 폭발형\n",
       "3          해빙       초반 폭발형\n",
       "4       다시, 봄       중반 균형형"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hit_data= pd.read_csv(\"C:/Users/강태희/Documents/BAF-25-2-Marketing/week_predict/movie_hit_category.csv\")\n",
    "hit_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05d3052f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movie_Title</th>\n",
       "      <th>Total_Audience_Count</th>\n",
       "      <th>Total_Show_Days</th>\n",
       "      <th>Total_Weeks</th>\n",
       "      <th>wk1_Audience</th>\n",
       "      <th>wk1_AudiencePerShow</th>\n",
       "      <th>wk2_Audience</th>\n",
       "      <th>wk2_AudiencePerShow</th>\n",
       "      <th>Show_Change</th>\n",
       "      <th>opening_Ho_Retention</th>\n",
       "      <th>...</th>\n",
       "      <th>e253</th>\n",
       "      <th>e254</th>\n",
       "      <th>e255</th>\n",
       "      <th>e256</th>\n",
       "      <th>FA1</th>\n",
       "      <th>FA2</th>\n",
       "      <th>FA3</th>\n",
       "      <th>FA4</th>\n",
       "      <th>FA5</th>\n",
       "      <th>hit_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>도쿄 리벤저스</td>\n",
       "      <td>13122</td>\n",
       "      <td>47</td>\n",
       "      <td>8</td>\n",
       "      <td>8617.0</td>\n",
       "      <td>5.654199</td>\n",
       "      <td>2925</td>\n",
       "      <td>5.034423</td>\n",
       "      <td>0.381234</td>\n",
       "      <td>0.130780</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.023438</td>\n",
       "      <td>0.012329</td>\n",
       "      <td>0.036133</td>\n",
       "      <td>0.010742</td>\n",
       "      <td>-0.581703</td>\n",
       "      <td>-0.873621</td>\n",
       "      <td>0.334321</td>\n",
       "      <td>-0.860584</td>\n",
       "      <td>-0.302076</td>\n",
       "      <td>중반 균형형</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>매직브러시</td>\n",
       "      <td>169106</td>\n",
       "      <td>36</td>\n",
       "      <td>8</td>\n",
       "      <td>145560.0</td>\n",
       "      <td>37.670807</td>\n",
       "      <td>18117</td>\n",
       "      <td>14.717303</td>\n",
       "      <td>0.318582</td>\n",
       "      <td>0.182869</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013794</td>\n",
       "      <td>-0.010071</td>\n",
       "      <td>0.014709</td>\n",
       "      <td>0.017578</td>\n",
       "      <td>-0.235392</td>\n",
       "      <td>0.273776</td>\n",
       "      <td>-1.353467</td>\n",
       "      <td>-0.748044</td>\n",
       "      <td>-0.342353</td>\n",
       "      <td>초반 폭발형</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>숨바꼭질</td>\n",
       "      <td>656089</td>\n",
       "      <td>48</td>\n",
       "      <td>8</td>\n",
       "      <td>195760.0</td>\n",
       "      <td>92.645528</td>\n",
       "      <td>307980</td>\n",
       "      <td>65.807692</td>\n",
       "      <td>2.214860</td>\n",
       "      <td>0.892172</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018921</td>\n",
       "      <td>0.002823</td>\n",
       "      <td>0.055176</td>\n",
       "      <td>0.015747</td>\n",
       "      <td>0.103283</td>\n",
       "      <td>2.615669</td>\n",
       "      <td>0.523378</td>\n",
       "      <td>1.502512</td>\n",
       "      <td>0.556472</td>\n",
       "      <td>초반 폭발형</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>해빙</td>\n",
       "      <td>1201576</td>\n",
       "      <td>52</td>\n",
       "      <td>9</td>\n",
       "      <td>906864.0</td>\n",
       "      <td>44.818820</td>\n",
       "      <td>232306</td>\n",
       "      <td>13.362439</td>\n",
       "      <td>0.859197</td>\n",
       "      <td>0.189943</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.013306</td>\n",
       "      <td>0.004303</td>\n",
       "      <td>0.047119</td>\n",
       "      <td>0.011414</td>\n",
       "      <td>1.734376</td>\n",
       "      <td>-0.007841</td>\n",
       "      <td>0.617193</td>\n",
       "      <td>-1.091703</td>\n",
       "      <td>-0.357989</td>\n",
       "      <td>초반 폭발형</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>다시, 봄</td>\n",
       "      <td>25506</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>18609.0</td>\n",
       "      <td>5.126446</td>\n",
       "      <td>3969</td>\n",
       "      <td>3.598368</td>\n",
       "      <td>0.303857</td>\n",
       "      <td>0.028099</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.027100</td>\n",
       "      <td>-0.036621</td>\n",
       "      <td>0.073242</td>\n",
       "      <td>-0.016113</td>\n",
       "      <td>-0.598004</td>\n",
       "      <td>-0.887915</td>\n",
       "      <td>0.400546</td>\n",
       "      <td>-1.055799</td>\n",
       "      <td>-0.290591</td>\n",
       "      <td>중반 균형형</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 286 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Movie_Title  Total_Audience_Count  Total_Show_Days  Total_Weeks  \\\n",
       "0     도쿄 리벤저스                 13122               47            8   \n",
       "1       매직브러시                169106               36            8   \n",
       "2        숨바꼭질                656089               48            8   \n",
       "3          해빙               1201576               52            9   \n",
       "4       다시, 봄                 25506               18            4   \n",
       "\n",
       "   wk1_Audience  wk1_AudiencePerShow  wk2_Audience  wk2_AudiencePerShow  \\\n",
       "0        8617.0             5.654199          2925             5.034423   \n",
       "1      145560.0            37.670807         18117            14.717303   \n",
       "2      195760.0            92.645528        307980            65.807692   \n",
       "3      906864.0            44.818820        232306            13.362439   \n",
       "4       18609.0             5.126446          3969             3.598368   \n",
       "\n",
       "   Show_Change  opening_Ho_Retention  ...      e253      e254      e255  \\\n",
       "0     0.381234              0.130780  ... -0.023438  0.012329  0.036133   \n",
       "1     0.318582              0.182869  ...  0.013794 -0.010071  0.014709   \n",
       "2     2.214860              0.892172  ... -0.018921  0.002823  0.055176   \n",
       "3     0.859197              0.189943  ... -0.013306  0.004303  0.047119   \n",
       "4     0.303857              0.028099  ... -0.027100 -0.036621  0.073242   \n",
       "\n",
       "       e256       FA1       FA2       FA3       FA4       FA5  hit_category  \n",
       "0  0.010742 -0.581703 -0.873621  0.334321 -0.860584 -0.302076        중반 균형형  \n",
       "1  0.017578 -0.235392  0.273776 -1.353467 -0.748044 -0.342353        초반 폭발형  \n",
       "2  0.015747  0.103283  2.615669  0.523378  1.502512  0.556472        초반 폭발형  \n",
       "3  0.011414  1.734376 -0.007841  0.617193 -1.091703 -0.357989        초반 폭발형  \n",
       "4 -0.016113 -0.598004 -0.887915  0.400546 -1.055799 -0.290591        중반 균형형  \n",
       "\n",
       "[5 rows x 286 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 합치기\n",
    "df= pd.merge(movie_data, fa_data, on=\"Movie_Title\", how=\"inner\")\n",
    "df= pd.merge(df, hit_data, on=\"Movie_Title\", how=\"inner\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6beed93d",
   "metadata": {},
   "source": [
    "총 상영주차 예측에 쓸 변수는 FA4, 팬데믹, 영화 대표 제작국가, 영화 흥행 패턴  \n",
    "여기서 추가할 변수를 찾기 위해 상관계수를 구해본다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93dd92b5",
   "metadata": {},
   "source": [
    "## 상관계수 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f96215c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hit_category\n",
       "초반 폭발형     1695\n",
       "중반 균형형      694\n",
       "후반 입소문형     179\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['hit_category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6cb5c57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#범주형 변수 원핫인코딩\n",
    "cat_cols = ['Month', 'Pandemic', 'Grade', 'Main_Country','hit_category']\n",
    "\n",
    "# 원핫인코딩\n",
    "combined_encoded = pd.get_dummies(df, columns=cat_cols, drop_first=False, dtype=int)\n",
    "\n",
    "# 한글 → 영어 변수명 매핑\n",
    "rename_map = {\n",
    "    # Grade (관람등급)\n",
    "    'Grade_전체관람가': 'Grade_All',\n",
    "    'Grade_12세이상관람가': 'Grade_12plus',\n",
    "    'Grade_15세이상관람가': 'Grade_15plus',\n",
    "    'Grade_청소년관람불가': 'Grade_Restricted',\n",
    "\n",
    "    # Main_Country (국가)\n",
    "    'Main_Country_한국': 'Country_KR',\n",
    "    'Main_Country_미국': 'Country_US',\n",
    "    'Main_Country_일본': 'Country_JP',\n",
    "    'Main_Country_기타': 'Country_Other',\n",
    "\n",
    "    # hit_category (영화 흥행 패턴)\n",
    "    'hit_category_초반 폭발형': 'Early_Explosion',\n",
    "    'hit_category_중반 균형형': 'Mid_Balanced',\n",
    "    'hit_category_후반 입소문형': 'Later_Viral'\n",
    "}\n",
    "combined_encoded = combined_encoded.rename(columns=rename_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43fb006c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movie_Title</th>\n",
       "      <th>Total_Audience_Count</th>\n",
       "      <th>Total_Show_Days</th>\n",
       "      <th>Total_Weeks</th>\n",
       "      <th>wk1_Audience</th>\n",
       "      <th>wk1_AudiencePerShow</th>\n",
       "      <th>wk2_Audience</th>\n",
       "      <th>wk2_AudiencePerShow</th>\n",
       "      <th>Show_Change</th>\n",
       "      <th>opening_Ho_Retention</th>\n",
       "      <th>...</th>\n",
       "      <th>Grade_15plus</th>\n",
       "      <th>Grade_All</th>\n",
       "      <th>Grade_Restricted</th>\n",
       "      <th>Country_Other</th>\n",
       "      <th>Country_US</th>\n",
       "      <th>Country_JP</th>\n",
       "      <th>Country_KR</th>\n",
       "      <th>Mid_Balanced</th>\n",
       "      <th>Early_Explosion</th>\n",
       "      <th>Later_Viral</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>도쿄 리벤저스</td>\n",
       "      <td>13122</td>\n",
       "      <td>47</td>\n",
       "      <td>8</td>\n",
       "      <td>8617.0</td>\n",
       "      <td>5.654199</td>\n",
       "      <td>2925</td>\n",
       "      <td>5.034423</td>\n",
       "      <td>0.381234</td>\n",
       "      <td>0.130780</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>매직브러시</td>\n",
       "      <td>169106</td>\n",
       "      <td>36</td>\n",
       "      <td>8</td>\n",
       "      <td>145560.0</td>\n",
       "      <td>37.670807</td>\n",
       "      <td>18117</td>\n",
       "      <td>14.717303</td>\n",
       "      <td>0.318582</td>\n",
       "      <td>0.182869</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>숨바꼭질</td>\n",
       "      <td>656089</td>\n",
       "      <td>48</td>\n",
       "      <td>8</td>\n",
       "      <td>195760.0</td>\n",
       "      <td>92.645528</td>\n",
       "      <td>307980</td>\n",
       "      <td>65.807692</td>\n",
       "      <td>2.214860</td>\n",
       "      <td>0.892172</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>해빙</td>\n",
       "      <td>1201576</td>\n",
       "      <td>52</td>\n",
       "      <td>9</td>\n",
       "      <td>906864.0</td>\n",
       "      <td>44.818820</td>\n",
       "      <td>232306</td>\n",
       "      <td>13.362439</td>\n",
       "      <td>0.859197</td>\n",
       "      <td>0.189943</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>다시, 봄</td>\n",
       "      <td>25506</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>18609.0</td>\n",
       "      <td>5.126446</td>\n",
       "      <td>3969</td>\n",
       "      <td>3.598368</td>\n",
       "      <td>0.303857</td>\n",
       "      <td>0.028099</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 307 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Movie_Title  Total_Audience_Count  Total_Show_Days  Total_Weeks  \\\n",
       "0     도쿄 리벤저스                 13122               47            8   \n",
       "1       매직브러시                169106               36            8   \n",
       "2        숨바꼭질                656089               48            8   \n",
       "3          해빙               1201576               52            9   \n",
       "4       다시, 봄                 25506               18            4   \n",
       "\n",
       "   wk1_Audience  wk1_AudiencePerShow  wk2_Audience  wk2_AudiencePerShow  \\\n",
       "0        8617.0             5.654199          2925             5.034423   \n",
       "1      145560.0            37.670807         18117            14.717303   \n",
       "2      195760.0            92.645528        307980            65.807692   \n",
       "3      906864.0            44.818820        232306            13.362439   \n",
       "4       18609.0             5.126446          3969             3.598368   \n",
       "\n",
       "   Show_Change  opening_Ho_Retention  ...  Grade_15plus  Grade_All  \\\n",
       "0     0.381234              0.130780  ...             1          0   \n",
       "1     0.318582              0.182869  ...             0          1   \n",
       "2     2.214860              0.892172  ...             1          0   \n",
       "3     0.859197              0.189943  ...             1          0   \n",
       "4     0.303857              0.028099  ...             0          0   \n",
       "\n",
       "   Grade_Restricted  Country_Other  Country_US  Country_JP  Country_KR  \\\n",
       "0                 0              0           0           1           0   \n",
       "1                 0              1           0           0           0   \n",
       "2                 0              0           1           0           0   \n",
       "3                 0              0           0           0           1   \n",
       "4                 0              0           0           0           1   \n",
       "\n",
       "   Mid_Balanced  Early_Explosion  Later_Viral  \n",
       "0             1                0            0  \n",
       "1             0                1            0  \n",
       "2             0                1            0  \n",
       "3             0                1            0  \n",
       "4             1                0            0  \n",
       "\n",
       "[5 rows x 307 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bb630ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "핵심 변수들과 상관계수가 높은 변수들:\n",
      "                           FA4  Pandemic_0  Pandemic_1  Pandemic_2  \\\n",
      "Total_Show_Days            NaN         NaN         NaN         NaN   \n",
      "Total_Weeks                NaN         NaN         NaN         NaN   \n",
      "wk2_AudiencePerShow   0.592138         NaN         NaN         NaN   \n",
      "Show_Change           0.716173         NaN         NaN         NaN   \n",
      "opening_Ho_Retention  0.964034         NaN         NaN         NaN   \n",
      "Year                       NaN   -0.723462         NaN    0.530996   \n",
      "\n",
      "                      Country_Other  Country_US  Country_JP  Country_KR  \\\n",
      "Total_Show_Days                 NaN         NaN         NaN         NaN   \n",
      "Total_Weeks                     NaN         NaN         NaN         NaN   \n",
      "wk2_AudiencePerShow             NaN         NaN         NaN         NaN   \n",
      "Show_Change                     NaN         NaN         NaN         NaN   \n",
      "opening_Ho_Retention            NaN         NaN         NaN         NaN   \n",
      "Year                            NaN         NaN         NaN         NaN   \n",
      "\n",
      "                      Early_Explosion  Mid_Balanced  Later_Viral  \n",
      "Total_Show_Days             -0.550761           NaN          NaN  \n",
      "Total_Weeks                 -0.533079           NaN          NaN  \n",
      "wk2_AudiencePerShow               NaN           NaN          NaN  \n",
      "Show_Change                       NaN           NaN          NaN  \n",
      "opening_Ho_Retention              NaN           NaN          NaN  \n",
      "Year                              NaN           NaN          NaN  \n"
     ]
    }
   ],
   "source": [
    "# 주요 변수 지정\n",
    "core_vars = [\"FA4\", \"Pandemic_0\", \"Pandemic_1\", \"Pandemic_2\", \"Country_Other\",\"Country_US\",\t\"Country_JP\",\"Country_KR\", \n",
    "             'Early_Explosion', 'Mid_Balanced','Later_Viral']\n",
    "\n",
    "# FA1~FA3, FA5, e1~e256 제외 (이전과 동일)\n",
    "cols_to_drop = [f\"e{i}\" for i in range(1, 257)] + [\"FA1\", \"FA2\", \"FA3\", \"FA5\",\"Movie_Title\"]\n",
    "filtered_df = combined_encoded.drop(columns=cols_to_drop, errors=\"ignore\")\n",
    "\n",
    "# 상관계수 행렬 계산\n",
    "corr_matrix = filtered_df.corr()\n",
    "\n",
    "# 핵심 변수들과의 상관관계만 추출\n",
    "corr_with_core = corr_matrix[core_vars]\n",
    "\n",
    "# 절댓값이 큰 변수들만 선택 (예: |r| > 0.5)\n",
    "threshold = 0.5\n",
    "high_corr = corr_with_core[abs(corr_with_core) > threshold].dropna(how='all')\n",
    "\n",
    "# 핵심 변수 자기 자신 제외\n",
    "high_corr = high_corr.loc[~high_corr.index.isin(core_vars)]\n",
    "\n",
    "# 결과 확인\n",
    "print(\"핵심 변수들과 상관계수가 높은 변수들:\")\n",
    "print(high_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d2a1ae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 feature        VIF\n",
      "0                    FA4  19.585708\n",
      "1             Pandemic_0        inf\n",
      "2             Pandemic_1        inf\n",
      "3             Pandemic_2        inf\n",
      "4          Country_Other        inf\n",
      "5             Country_US        inf\n",
      "6             Country_JP        inf\n",
      "7             Country_KR        inf\n",
      "8        Early_Explosion        inf\n",
      "9           Mid_Balanced        inf\n",
      "10           Later_Viral        inf\n",
      "11   wk2_AudiencePerShow   1.867773\n",
      "12           Show_Change   2.545153\n",
      "13  opening_Ho_Retention  16.111717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\uni\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:197: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import pandas as pd\n",
    "\n",
    "X = combined_encoded[[\"FA4\", \"Pandemic_0\", \"Pandemic_1\", \"Pandemic_2\", \"Country_Other\",\"Country_US\", \"Country_JP\",\"Country_KR\", \n",
    "                      'Early_Explosion', 'Mid_Balanced','Later_Viral',\n",
    "                      \"wk2_AudiencePerShow\", \"Show_Change\", \"opening_Ho_Retention\"]].dropna()\n",
    "\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"feature\"] = X.columns\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "print(vif_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2023a851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                feature       VIF\n",
      "0                   FA4  2.525333\n",
      "1            Pandemic_0       inf\n",
      "2            Pandemic_1       inf\n",
      "3            Pandemic_2       inf\n",
      "4         Country_Other       inf\n",
      "5            Country_US       inf\n",
      "6            Country_JP       inf\n",
      "7            Country_KR       inf\n",
      "8       Early_Explosion       inf\n",
      "9          Mid_Balanced       inf\n",
      "10          Later_Viral       inf\n",
      "11  wk2_AudiencePerShow  1.865931\n",
      "12          Show_Change  2.376742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\uni\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:197: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    }
   ],
   "source": [
    "# opening_Ho_Retentiond을 제외하고 다시 vif 구해보기\n",
    "\n",
    "X = combined_encoded[[\"FA4\", \"Pandemic_0\", \"Pandemic_1\", \"Pandemic_2\", \"Country_Other\",\"Country_US\", \"Country_JP\",\"Country_KR\", \n",
    "                      'Early_Explosion', 'Mid_Balanced','Later_Viral',\n",
    "                      \"wk2_AudiencePerShow\", \"Show_Change\"]].dropna()\n",
    "\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"feature\"] = X.columns\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "print(vif_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba719ba",
   "metadata": {},
   "source": [
    "총 상영주차 예측에 쓸 변수는 FA4, 팬데믹, 영화 대표 제작국가, 영화 흥행 패턴  \n",
    "여기서 추가로 wk2_AudiencePerShow ,Show_Change 만 사용할 것"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f8614f",
   "metadata": {},
   "source": [
    "## 학습 데이터셋 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9da26ec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (2054, 307)\n",
      "Test shape: (514, 307)\n",
      "                  Movie_Title  Total_Audience_Count  Total_Show_Days  \\\n",
      "2054  버즈 오브 프레이(할리 퀸의 황홀한 해방)                400643               63   \n",
      "2055                      언데드                214638               41   \n",
      "2056                   정글 크루즈                246029               28   \n",
      "2057                       핸콕               2722284               35   \n",
      "2058                     잭 리처                782892               22   \n",
      "\n",
      "      Total_Weeks  wk1_Audience  wk1_AudiencePerShow  wk2_Audience  \\\n",
      "2054           10      264467.0            11.721789        115766   \n",
      "2055            7      123849.0            30.258734         68579   \n",
      "2056            5      155216.0            13.723784         81108   \n",
      "2057            6     1318928.0            72.033206        979822   \n",
      "2058            4      464142.0            60.839166        278123   \n",
      "\n",
      "      wk2_AudiencePerShow  Show_Change  opening_Ho_Retention  ...  \\\n",
      "2054             8.792132     0.583592              0.222414  ...   \n",
      "2055            13.420548     1.248473              0.388975  ...   \n",
      "2056            10.025711     0.715296              0.245114  ...   \n",
      "2057            44.412202     1.204915              0.618481  ...   \n",
      "2058            30.276834     1.204090              0.337220  ...   \n",
      "\n",
      "      Grade_15plus  Grade_All  Grade_Restricted  Country_Other  Country_US  \\\n",
      "2054             1          0                 0              0           1   \n",
      "2055             1          0                 0              0           1   \n",
      "2056             0          0                 0              0           1   \n",
      "2057             0          0                 0              0           1   \n",
      "2058             1          0                 0              0           1   \n",
      "\n",
      "      Country_JP  Country_KR  Mid_Balanced  Early_Explosion  Later_Viral  \n",
      "2054           0           0             0                1            0  \n",
      "2055           0           0             0                1            0  \n",
      "2056           0           0             0                1            0  \n",
      "2057           0           0             0                1            0  \n",
      "2058           0           0             0                1            0  \n",
      "\n",
      "[5 rows x 307 columns]\n"
     ]
    }
   ],
   "source": [
    "# 다시 train / test 분리\n",
    "df_train_encoded = combined_encoded.iloc[:2054, :].copy()\n",
    "df_test_encoded = combined_encoded.iloc[2054:, :].copy()\n",
    "\n",
    "# 확인\n",
    "print(\"Train shape:\", df_train_encoded.shape)\n",
    "print(\"Test shape:\", df_test_encoded.shape)\n",
    "print(df_test_encoded.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "70cc65b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['FA4', 'Pandemic_0', 'Pandemic_1', 'Pandemic_2', 'Country_Other', 'Country_US', 'Country_JP', 'Country_KR', 'Early_Explosion', 'Mid_Balanced', 'Later_Viral', 'wk2_AudiencePerShow', 'Show_Change']\n",
      "['Total_Weeks']\n"
     ]
    }
   ],
   "source": [
    "# 학습 데이터셋 만들기\n",
    "\n",
    "# 1. 타겟 (Y) 컬럼 목록 정의\n",
    "target_columns = ['Total_Weeks']\n",
    "\n",
    "# 2. X (특성 데이터) 생성: 타겟 컬럼들을 제외한 나머지\n",
    "X = df_train_encoded[[\"FA4\", \"Pandemic_0\", \"Pandemic_1\", \"Pandemic_2\", \"Country_Other\",\"Country_US\",\t\"Country_JP\",\"Country_KR\", \n",
    "                     'Early_Explosion', 'Mid_Balanced','Later_Viral','wk2_AudiencePerShow','Show_Change']]\n",
    "\n",
    "# 3. Y (타겟 데이터) 생성: 타겟 컬럼들만 선택\n",
    "y = df_train_encoded[target_columns]\n",
    "\n",
    "# 결과 확인\n",
    "print(X.columns.tolist())\n",
    "print(y.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fa87745f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "52d0faef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1643"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5e4ec1c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af7b4f6",
   "metadata": {},
   "source": [
    "## XGB 모델 예측"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c227c4c",
   "metadata": {},
   "source": [
    "옵튜나로 파라미터 조절"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "502eb7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6edd6d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "aa0de807",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-03 18:14:03,324] A new study created in memory with name: no-name-4f089993-30be-4eb3-8949-e0aaae9858dc\n",
      "[I 2025-11-03 18:14:04,234] Trial 0 finished with value: 4.954547629725761 and parameters: {'max_depth': 5, 'learning_rate': 0.1974384660476855, 'n_estimators': 256, 'subsample': 0.8704270428014653, 'colsample_bytree': 0.7246833079313311, 'min_child_weight': 1, 'reg_alpha': 6.765392299377129, 'reg_lambda': 0.1540401744356359}. Best is trial 0 with value: 4.954547629725761.\n",
      "[I 2025-11-03 18:14:04,448] Trial 1 finished with value: 4.87195872747701 and parameters: {'max_depth': 5, 'learning_rate': 0.12085921317684582, 'n_estimators': 103, 'subsample': 0.7324299441998614, 'colsample_bytree': 0.5504200102857477, 'min_child_weight': 7, 'reg_alpha': 6.933716224918623, 'reg_lambda': 7.443413982581855}. Best is trial 1 with value: 4.87195872747701.\n",
      "[I 2025-11-03 18:14:04,782] Trial 2 finished with value: 4.77498020599403 and parameters: {'max_depth': 9, 'learning_rate': 0.07584937786444232, 'n_estimators': 115, 'subsample': 0.5331529490398599, 'colsample_bytree': 0.8157267917255135, 'min_child_weight': 8, 'reg_alpha': 6.568528013751878, 'reg_lambda': 4.6444332673575435}. Best is trial 2 with value: 4.77498020599403.\n",
      "[I 2025-11-03 18:14:06,571] Trial 3 finished with value: 5.077328876949963 and parameters: {'max_depth': 10, 'learning_rate': 0.24423851094620036, 'n_estimators': 734, 'subsample': 0.9056651910931698, 'colsample_bytree': 0.9811520551449094, 'min_child_weight': 10, 'reg_alpha': 7.196120231456145, 'reg_lambda': 1.7452882589052956}. Best is trial 2 with value: 4.77498020599403.\n",
      "[I 2025-11-03 18:14:08,621] Trial 4 finished with value: 5.1567451945466765 and parameters: {'max_depth': 8, 'learning_rate': 0.12270929205152839, 'n_estimators': 975, 'subsample': 0.9884337784824022, 'colsample_bytree': 0.6993592344992305, 'min_child_weight': 9, 'reg_alpha': 4.294161765868016, 'reg_lambda': 5.644126376728812}. Best is trial 2 with value: 4.77498020599403.\n",
      "[I 2025-11-03 18:14:09,018] Trial 5 finished with value: 4.890212093817521 and parameters: {'max_depth': 5, 'learning_rate': 0.25799859980103107, 'n_estimators': 213, 'subsample': 0.7428745842859557, 'colsample_bytree': 0.819366779099941, 'min_child_weight': 5, 'reg_alpha': 9.271483845144763, 'reg_lambda': 8.533100075661915}. Best is trial 2 with value: 4.77498020599403.\n",
      "[I 2025-11-03 18:14:10,135] Trial 6 finished with value: 4.82625933661329 and parameters: {'max_depth': 5, 'learning_rate': 0.03708121807421544, 'n_estimators': 556, 'subsample': 0.811126102694288, 'colsample_bytree': 0.5749720739390025, 'min_child_weight': 2, 'reg_alpha': 7.07037620495764, 'reg_lambda': 9.482218855617488}. Best is trial 2 with value: 4.77498020599403.\n",
      "[I 2025-11-03 18:14:11,025] Trial 7 finished with value: 4.927442469732097 and parameters: {'max_depth': 9, 'learning_rate': 0.0614643452922778, 'n_estimators': 363, 'subsample': 0.6195566484770885, 'colsample_bytree': 0.7382913669806728, 'min_child_weight': 9, 'reg_alpha': 2.7401546073295093, 'reg_lambda': 2.3423184817946576}. Best is trial 2 with value: 4.77498020599403.\n",
      "[I 2025-11-03 18:14:12,152] Trial 8 finished with value: 4.932883825770633 and parameters: {'max_depth': 9, 'learning_rate': 0.15790814485683358, 'n_estimators': 941, 'subsample': 0.9999065013408017, 'colsample_bytree': 0.7492723956118259, 'min_child_weight': 1, 'reg_alpha': 6.608534768708264, 'reg_lambda': 4.40677425768304}. Best is trial 2 with value: 4.77498020599403.\n",
      "[I 2025-11-03 18:14:13,664] Trial 9 finished with value: 4.991478099932712 and parameters: {'max_depth': 8, 'learning_rate': 0.08534240563004118, 'n_estimators': 631, 'subsample': 0.8279057421492568, 'colsample_bytree': 0.7555721267291312, 'min_child_weight': 1, 'reg_alpha': 2.1532906840507007, 'reg_lambda': 0.5797675660328762}. Best is trial 2 with value: 4.77498020599403.\n",
      "[I 2025-11-03 18:14:14,175] Trial 10 finished with value: 4.686996236241707 and parameters: {'max_depth': 3, 'learning_rate': 0.015145019572858139, 'n_estimators': 413, 'subsample': 0.5299415411822793, 'colsample_bytree': 0.9062294926870853, 'min_child_weight': 6, 'reg_alpha': 0.11104717551541388, 'reg_lambda': 4.510558918249971}. Best is trial 10 with value: 4.686996236241707.\n",
      "[I 2025-11-03 18:14:14,695] Trial 11 finished with value: 4.691899426218582 and parameters: {'max_depth': 3, 'learning_rate': 0.03415918302239861, 'n_estimators': 409, 'subsample': 0.5005224275865385, 'colsample_bytree': 0.9090451714891951, 'min_child_weight': 6, 'reg_alpha': 0.07838824997711669, 'reg_lambda': 4.498739269264161}. Best is trial 10 with value: 4.686996236241707.\n",
      "[I 2025-11-03 18:14:15,196] Trial 12 finished with value: 4.677515643934485 and parameters: {'max_depth': 3, 'learning_rate': 0.011941967352495067, 'n_estimators': 404, 'subsample': 0.5056803180230535, 'colsample_bytree': 0.9769672406984334, 'min_child_weight': 5, 'reg_alpha': 0.11682353164062782, 'reg_lambda': 3.601041831311573}. Best is trial 12 with value: 4.677515643934485.\n",
      "[I 2025-11-03 18:14:15,745] Trial 13 finished with value: 4.691024088808236 and parameters: {'max_depth': 3, 'learning_rate': 0.010056342762061054, 'n_estimators': 456, 'subsample': 0.6030779478380095, 'colsample_bytree': 0.9699779827283539, 'min_child_weight': 4, 'reg_alpha': 0.36715082158733203, 'reg_lambda': 2.949404527045431}. Best is trial 12 with value: 4.677515643934485.\n",
      "[I 2025-11-03 18:14:16,545] Trial 14 finished with value: 4.9012809159042625 and parameters: {'max_depth': 3, 'learning_rate': 0.10238783342953958, 'n_estimators': 716, 'subsample': 0.6265131655474557, 'colsample_bytree': 0.8943329965243181, 'min_child_weight': 4, 'reg_alpha': 1.7282555179222252, 'reg_lambda': 6.154860194778062}. Best is trial 12 with value: 4.677515643934485.\n",
      "[I 2025-11-03 18:14:17,041] Trial 15 finished with value: 4.692929063156828 and parameters: {'max_depth': 4, 'learning_rate': 0.01636304029762896, 'n_estimators': 323, 'subsample': 0.5614913865031997, 'colsample_bytree': 0.9071496605602918, 'min_child_weight': 6, 'reg_alpha': 3.868795684798579, 'reg_lambda': 3.3011708215006452}. Best is trial 12 with value: 4.677515643934485.\n",
      "[I 2025-11-03 18:14:17,998] Trial 16 finished with value: 5.163120646930849 and parameters: {'max_depth': 6, 'learning_rate': 0.1753654797840113, 'n_estimators': 499, 'subsample': 0.6538112270025798, 'colsample_bytree': 0.9814656910311528, 'min_child_weight': 3, 'reg_alpha': 1.1444652992014386, 'reg_lambda': 6.770085798382463}. Best is trial 12 with value: 4.677515643934485.\n",
      "[I 2025-11-03 18:14:18,781] Trial 17 finished with value: 4.902088279927958 and parameters: {'max_depth': 4, 'learning_rate': 0.05615635831209242, 'n_estimators': 568, 'subsample': 0.6847844484541228, 'colsample_bytree': 0.8567935540912636, 'min_child_weight': 5, 'reg_alpha': 3.125402869763822, 'reg_lambda': 3.6787777167202473}. Best is trial 12 with value: 4.677515643934485.\n",
      "[I 2025-11-03 18:14:19,316] Trial 18 finished with value: 5.501457831096325 and parameters: {'max_depth': 7, 'learning_rate': 0.29146784856695296, 'n_estimators': 250, 'subsample': 0.5719623314474497, 'colsample_bytree': 0.9357984628866135, 'min_child_weight': 7, 'reg_alpha': 1.1471472915885714, 'reg_lambda': 1.3929652354667978}. Best is trial 12 with value: 4.677515643934485.\n",
      "[I 2025-11-03 18:14:20,369] Trial 19 finished with value: 4.847490947563218 and parameters: {'max_depth': 4, 'learning_rate': 0.046423889866899846, 'n_estimators': 798, 'subsample': 0.5015404851612657, 'colsample_bytree': 0.6382165492659829, 'min_child_weight': 4, 'reg_alpha': 5.063576907656447, 'reg_lambda': 5.48777468453168}. Best is trial 12 with value: 4.677515643934485.\n",
      "[I 2025-11-03 18:14:21,013] Trial 20 finished with value: 5.092207899810414 and parameters: {'max_depth': 6, 'learning_rate': 0.20816837420533033, 'n_estimators': 325, 'subsample': 0.5626412040442992, 'colsample_bytree': 0.8523153773744003, 'min_child_weight': 7, 'reg_alpha': 0.03785433084588488, 'reg_lambda': 7.073446131873167}. Best is trial 12 with value: 4.677515643934485.\n",
      "[I 2025-11-03 18:14:21,573] Trial 21 finished with value: 4.659413491213417 and parameters: {'max_depth': 3, 'learning_rate': 0.0185460119639627, 'n_estimators': 446, 'subsample': 0.5982013911067369, 'colsample_bytree': 0.9989002824900927, 'min_child_weight': 4, 'reg_alpha': 0.7823191644342076, 'reg_lambda': 2.940216934269445}. Best is trial 21 with value: 4.659413491213417.\n",
      "[I 2025-11-03 18:14:22,226] Trial 22 finished with value: 4.691258792326151 and parameters: {'max_depth': 3, 'learning_rate': 0.023629009754303425, 'n_estimators': 455, 'subsample': 0.685794528191315, 'colsample_bytree': 0.9437127048556848, 'min_child_weight': 3, 'reg_alpha': 1.066702430811751, 'reg_lambda': 3.50373129419806}. Best is trial 21 with value: 4.659413491213417.\n",
      "[I 2025-11-03 18:14:22,917] Trial 23 finished with value: 4.888436050839957 and parameters: {'max_depth': 4, 'learning_rate': 0.08702015172877811, 'n_estimators': 379, 'subsample': 0.5431767176035837, 'colsample_bytree': 0.9774095862187433, 'min_child_weight': 5, 'reg_alpha': 2.2185642669205996, 'reg_lambda': 2.650961329624355}. Best is trial 21 with value: 4.659413491213417.\n",
      "[I 2025-11-03 18:14:23,872] Trial 24 finished with value: 4.67749749947429 and parameters: {'max_depth': 3, 'learning_rate': 0.012164817003989557, 'n_estimators': 628, 'subsample': 0.5971644187517282, 'colsample_bytree': 0.9993559262476082, 'min_child_weight': 3, 'reg_alpha': 0.8581581570687383, 'reg_lambda': 3.990478792929342}. Best is trial 21 with value: 4.659413491213417.\n",
      "[I 2025-11-03 18:14:24,909] Trial 25 finished with value: 5.108608786917039 and parameters: {'max_depth': 4, 'learning_rate': 0.11331365172544279, 'n_estimators': 641, 'subsample': 0.6814544186079706, 'colsample_bytree': 0.9969826264806545, 'min_child_weight': 3, 'reg_alpha': 1.1882718807888848, 'reg_lambda': 1.7297845846216042}. Best is trial 21 with value: 4.659413491213417.\n",
      "[I 2025-11-03 18:14:26,335] Trial 26 finished with value: 4.839506154806599 and parameters: {'max_depth': 3, 'learning_rate': 0.060912789676874995, 'n_estimators': 839, 'subsample': 0.6068532197701954, 'colsample_bytree': 0.940708244619548, 'min_child_weight': 2, 'reg_alpha': 3.270835201020768, 'reg_lambda': 3.854413013984314}. Best is trial 21 with value: 4.659413491213417.\n",
      "[I 2025-11-03 18:14:27,196] Trial 27 finished with value: 4.864012004027876 and parameters: {'max_depth': 4, 'learning_rate': 0.03897393589610044, 'n_estimators': 620, 'subsample': 0.5971368009447486, 'colsample_bytree': 0.8704579690086405, 'min_child_weight': 4, 'reg_alpha': 4.981164243750793, 'reg_lambda': 1.0281045934266095}. Best is trial 21 with value: 4.659413491213417.\n",
      "[I 2025-11-03 18:14:28,127] Trial 28 finished with value: 5.031286551104702 and parameters: {'max_depth': 6, 'learning_rate': 0.14638235243516695, 'n_estimators': 511, 'subsample': 0.6546219437878218, 'colsample_bytree': 0.7868690874449541, 'min_child_weight': 2, 'reg_alpha': 1.7139463293139328, 'reg_lambda': 2.3594635720433472}. Best is trial 21 with value: 4.659413491213417.\n",
      "[I 2025-11-03 18:14:29,188] Trial 29 finished with value: 5.117264765293368 and parameters: {'max_depth': 5, 'learning_rate': 0.06566669170416801, 'n_estimators': 695, 'subsample': 0.7163845034876642, 'colsample_bytree': 0.9992088632166303, 'min_child_weight': 5, 'reg_alpha': 0.7166649306220629, 'reg_lambda': 0.32533947228567595}. Best is trial 21 with value: 4.659413491213417.\n",
      "[I 2025-11-03 18:14:29,610] Trial 30 finished with value: 4.769279457129525 and parameters: {'max_depth': 3, 'learning_rate': 0.09474591114943656, 'n_estimators': 290, 'subsample': 0.583542462361289, 'colsample_bytree': 0.5006105143314279, 'min_child_weight': 3, 'reg_alpha': 9.740466043981401, 'reg_lambda': 5.278045150512662}. Best is trial 21 with value: 4.659413491213417.\n",
      "[I 2025-11-03 18:14:30,160] Trial 31 finished with value: 4.679160423221067 and parameters: {'max_depth': 3, 'learning_rate': 0.010624479742167126, 'n_estimators': 441, 'subsample': 0.5244647384683302, 'colsample_bytree': 0.9549904617317994, 'min_child_weight': 6, 'reg_alpha': 0.5914991548689927, 'reg_lambda': 4.229874837802141}. Best is trial 21 with value: 4.659413491213417.\n",
      "[I 2025-11-03 18:14:30,867] Trial 32 finished with value: 4.748948065729068 and parameters: {'max_depth': 4, 'learning_rate': 0.029653578208139127, 'n_estimators': 474, 'subsample': 0.5195851516725392, 'colsample_bytree': 0.946144958503675, 'min_child_weight': 4, 'reg_alpha': 1.821701316137117, 'reg_lambda': 3.937073215551453}. Best is trial 21 with value: 4.659413491213417.\n",
      "[I 2025-11-03 18:14:31,540] Trial 33 finished with value: 4.668870989652488 and parameters: {'max_depth': 3, 'learning_rate': 0.010300696391250638, 'n_estimators': 560, 'subsample': 0.5478146739507214, 'colsample_bytree': 0.9544640989105369, 'min_child_weight': 7, 'reg_alpha': 0.6826100177596238, 'reg_lambda': 4.9156275148753465}. Best is trial 21 with value: 4.659413491213417.\n",
      "[I 2025-11-03 18:14:32,414] Trial 34 finished with value: 4.879170643180213 and parameters: {'max_depth': 4, 'learning_rate': 0.04704871446485773, 'n_estimators': 577, 'subsample': 0.7916162022987965, 'colsample_bytree': 0.9233836720797869, 'min_child_weight': 8, 'reg_alpha': 2.691646882655813, 'reg_lambda': 4.961081374903032}. Best is trial 21 with value: 4.659413491213417.\n",
      "[I 2025-11-03 18:14:32,658] Trial 35 finished with value: 4.696092835527125 and parameters: {'max_depth': 3, 'learning_rate': 0.07277093164037587, 'n_estimators': 164, 'subsample': 0.6372719140285344, 'colsample_bytree': 0.8744928009526584, 'min_child_weight': 7, 'reg_alpha': 0.6649378941910068, 'reg_lambda': 3.0083938517045454}. Best is trial 21 with value: 4.659413491213417.\n",
      "[I 2025-11-03 18:14:33,820] Trial 36 finished with value: 4.907270128933002 and parameters: {'max_depth': 5, 'learning_rate': 0.033202360591912145, 'n_estimators': 757, 'subsample': 0.5490070686040656, 'colsample_bytree': 0.8276936762461551, 'min_child_weight': 5, 'reg_alpha': 1.7792867790812812, 'reg_lambda': 2.0827420591621646}. Best is trial 21 with value: 4.659413491213417.\n",
      "[I 2025-11-03 18:14:34,441] Trial 37 finished with value: 4.87538593893537 and parameters: {'max_depth': 3, 'learning_rate': 0.13385993698074422, 'n_estimators': 525, 'subsample': 0.5816948340583675, 'colsample_bytree': 0.9990825758924307, 'min_child_weight': 7, 'reg_alpha': 8.326232495735995, 'reg_lambda': 6.285246214467678}. Best is trial 21 with value: 4.659413491213417.\n",
      "[I 2025-11-03 18:14:36,139] Trial 38 finished with value: 5.057060226529804 and parameters: {'max_depth': 10, 'learning_rate': 0.04842390635277127, 'n_estimators': 665, 'subsample': 0.9335939361662834, 'colsample_bytree': 0.965933058942287, 'min_child_weight': 8, 'reg_alpha': 2.4717404992769114, 'reg_lambda': 7.908955004840509}. Best is trial 21 with value: 4.659413491213417.\n",
      "[I 2025-11-03 18:14:36,989] Trial 39 finished with value: 4.846778273575329 and parameters: {'max_depth': 5, 'learning_rate': 0.024214744607599422, 'n_estimators': 606, 'subsample': 0.7804190850877453, 'colsample_bytree': 0.6915322615210293, 'min_child_weight': 10, 'reg_alpha': 1.3537818187908153, 'reg_lambda': 5.070433664038266}. Best is trial 21 with value: 4.659413491213417.\n",
      "[I 2025-11-03 18:14:38,126] Trial 40 finished with value: 5.026423719360382 and parameters: {'max_depth': 7, 'learning_rate': 0.07564746012348365, 'n_estimators': 538, 'subsample': 0.5465890654712168, 'colsample_bytree': 0.8846880723022224, 'min_child_weight': 3, 'reg_alpha': 3.8453220497504312, 'reg_lambda': 5.838477876199828}. Best is trial 21 with value: 4.659413491213417.\n",
      "[I 2025-11-03 18:14:38,610] Trial 41 finished with value: 4.699219879461072 and parameters: {'max_depth': 3, 'learning_rate': 0.025716628637123776, 'n_estimators': 407, 'subsample': 0.5248628758825843, 'colsample_bytree': 0.9566476115531845, 'min_child_weight': 6, 'reg_alpha': 0.7152476560475166, 'reg_lambda': 4.199906034983168}. Best is trial 21 with value: 4.659413491213417.\n",
      "[I 2025-11-03 18:14:39,016] Trial 42 finished with value: 4.709335603712561 and parameters: {'max_depth': 3, 'learning_rate': 0.012291121487950387, 'n_estimators': 341, 'subsample': 0.5168062381349923, 'colsample_bytree': 0.9219595956334934, 'min_child_weight': 9, 'reg_alpha': 0.6108870403229271, 'reg_lambda': 3.0656488644067634}. Best is trial 21 with value: 4.659413491213417.\n",
      "[I 2025-11-03 18:14:39,630] Trial 43 finished with value: 4.697550693006896 and parameters: {'max_depth': 4, 'learning_rate': 0.011444645400644831, 'n_estimators': 440, 'subsample': 0.5835488943514917, 'colsample_bytree': 0.9623994311843728, 'min_child_weight': 6, 'reg_alpha': 0.0040264303575313215, 'reg_lambda': 4.8234300695632335}. Best is trial 21 with value: 4.659413491213417.\n",
      "[I 2025-11-03 18:14:40,221] Trial 44 finished with value: 4.706931146572419 and parameters: {'max_depth': 3, 'learning_rate': 0.0415966363748209, 'n_estimators': 489, 'subsample': 0.5012580674144378, 'colsample_bytree': 0.9784044878810338, 'min_child_weight': 5, 'reg_alpha': 0.5214804441638634, 'reg_lambda': 4.040453233815112}. Best is trial 21 with value: 4.659413491213417.\n",
      "[I 2025-11-03 18:14:40,683] Trial 45 finished with value: 4.776415248877794 and parameters: {'max_depth': 3, 'learning_rate': 0.05377162136934305, 'n_estimators': 378, 'subsample': 0.8644075165240193, 'colsample_bytree': 0.9303055698927692, 'min_child_weight': 6, 'reg_alpha': 1.4646135261520317, 'reg_lambda': 3.4981673267888853}. Best is trial 21 with value: 4.659413491213417.\n",
      "[I 2025-11-03 18:14:41,266] Trial 46 finished with value: 5.035190858025854 and parameters: {'max_depth': 4, 'learning_rate': 0.2297756082798476, 'n_estimators': 416, 'subsample': 0.5444939874650455, 'colsample_bytree': 0.7881419696937904, 'min_child_weight': 8, 'reg_alpha': 5.596171316140297, 'reg_lambda': 9.706570237350295}. Best is trial 21 with value: 4.659413491213417.\n",
      "[I 2025-11-03 18:14:42,001] Trial 47 finished with value: 4.7151616587159735 and parameters: {'max_depth': 3, 'learning_rate': 0.025867788408532343, 'n_estimators': 584, 'subsample': 0.6421482206541427, 'colsample_bytree': 0.9586669771232298, 'min_child_weight': 4, 'reg_alpha': 2.0549247882161605, 'reg_lambda': 4.419902482628148}. Best is trial 21 with value: 4.659413491213417.\n",
      "[I 2025-11-03 18:14:42,416] Trial 48 finished with value: 4.765074033192526 and parameters: {'max_depth': 5, 'learning_rate': 0.010984409648890714, 'n_estimators': 242, 'subsample': 0.6108543251983557, 'colsample_bytree': 0.9093143189443205, 'min_child_weight': 6, 'reg_alpha': 0.934887958003992, 'reg_lambda': 2.6503075895649197}. Best is trial 21 with value: 4.659413491213417.\n",
      "[I 2025-11-03 18:14:43,304] Trial 49 finished with value: 4.831272506254912 and parameters: {'max_depth': 4, 'learning_rate': 0.03643837286761558, 'n_estimators': 691, 'subsample': 0.5589071655163079, 'colsample_bytree': 0.9846516429683181, 'min_child_weight': 5, 'reg_alpha': 0.4262652585072425, 'reg_lambda': 5.996637621829717}. Best is trial 21 with value: 4.659413491213417.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RMSE: 4.6594\n",
      "Best Parameters:\n",
      "  max_depth: 3\n",
      "  learning_rate: 0.0185460119639627\n",
      "  n_estimators: 446\n",
      "  subsample: 0.5982013911067369\n",
      "  colsample_bytree: 0.9989002824900927\n",
      "  min_child_weight: 4\n",
      "  reg_alpha: 0.7823191644342076\n",
      "  reg_lambda: 2.940216934269445\n",
      "MAE: 2.6531, R²: 0.4460\n"
     ]
    }
   ],
   "source": [
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 1e-8, 10),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 1e-8, 10),\n",
    "        'random_state': 42,\n",
    "        'tree_method': 'hist'  \n",
    "    }\n",
    "\n",
    "    model = XGBRegressor(**params)\n",
    "    model.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=False)\n",
    "\n",
    "    y_pred = model.predict(X_val)\n",
    "\n",
    "    # 여러 지표 계산\n",
    "    rmse_val = rmse(y_val, y_pred)\n",
    "    mae_val = mean_absolute_error(y_val, y_pred)\n",
    "    r2_val = r2_score(y_val, y_pred)\n",
    "\n",
    "    # 참고용 출력 (튜닝 과정에서 로그로 볼 수 있음)\n",
    "    trial.set_user_attr(\"MAE\", mae_val)\n",
    "    trial.set_user_attr(\"R2\", r2_val)\n",
    "\n",
    "    # 최적화 기준은 RMSE (낮을수록 좋음)\n",
    "    return rmse_val\n",
    "\n",
    "# Optuna 실행\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# 결과 출력\n",
    "best_trial = study.best_trial\n",
    "print(f\"Best RMSE: {best_trial.value:.4f}\")\n",
    "print(\"Best Parameters:\")\n",
    "for key, value in best_trial.params.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "print(f\"MAE: {best_trial.user_attrs['MAE']:.4f}, R²: {best_trial.user_attrs['R2']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daee3866",
   "metadata": {},
   "source": [
    "XGB의 Best Parameters:   \n",
    "  max_depth: 3  \n",
    "  learning_rate: 0.0185460119639627  \n",
    "  n_estimators: 446  \n",
    "  subsample: 0.5982013911067369  \n",
    "  colsample_bytree: 0.9989002824900927  \n",
    "  min_child_weight: 4  \n",
    "  reg_alpha: 0.7823191644342076  \n",
    "  reg_lambda: 2.940216934269445  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7fa5e18",
   "metadata": {},
   "source": [
    "### random search로 파라미터 조절"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ed451c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a92d0691",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:41: SyntaxWarning: invalid escape sequence '\\ '\n",
      "<>:41: SyntaxWarning: invalid escape sequence '\\ '\n",
      "C:\\Users\\강태희\\AppData\\Local\\Temp\\ipykernel_20304\\2783306007.py:41: SyntaxWarning: invalid escape sequence '\\ '\n",
      "  print(\"\\ Best RMSE (CV):\", -random_search.best_score_)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "\\ Best RMSE (CV): 3.7269386615490867\n",
      " Best Parameters: {'subsample': 1.0, 'reg_lambda': 10.0, 'reg_alpha': 0.001, 'min_child_weight': 1, 'max_depth': 3, 'learning_rate': 0.16999999999999998, 'gamma': 3.0, 'colsample_bytree': 1.0}\n",
      "\n",
      " Test Set Performance\n",
      "RMSE: 4.7939\n",
      "MAE : 2.7218\n",
      "R²  : 0.4136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\uni\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBRegressor(\n",
    "    objective='reg:squarederror',\n",
    "    tree_method='hist',      \n",
    "    random_state=42,\n",
    "    n_estimators=500         \n",
    ")\n",
    "\n",
    "# -----------------------------------------\n",
    "# 랜덤서치 하이퍼파라미터 범위 정의\n",
    "# -----------------------------------------\n",
    "param_distributions = {\n",
    "    'learning_rate': np.linspace(0.01, 0.3, 30),\n",
    "    'max_depth': np.arange(3, 10),\n",
    "    'min_child_weight': np.arange(1, 10),\n",
    "    'subsample': np.linspace(0.5, 1.0, 6),\n",
    "    'colsample_bytree': np.linspace(0.5, 1.0, 6),\n",
    "    'gamma': np.linspace(0, 5, 11),\n",
    "    'reg_alpha': np.logspace(-3, 1, 10),  # L1 정규화\n",
    "    'reg_lambda': np.logspace(-3, 1, 10)  # L2 정규화\n",
    "}\n",
    "\n",
    "# -----------------------------------------\n",
    "# RandomizedSearchCV 실행\n",
    "# -----------------------------------------\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=xgb,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=50,                   # 랜덤 탐색 시도 횟수 (보통 30~100 적당)\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    cv=5,                        \n",
    "    verbose=2,\n",
    "    random_state=42,\n",
    "    n_jobs=-1                    \n",
    ")\n",
    "\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# -----------------------------------------\n",
    "# 결과 출력\n",
    "# -----------------------------------------\n",
    "print(\"\\ Best RMSE (CV):\", -random_search.best_score_)\n",
    "print(\" Best Parameters:\", random_search.best_params_)\n",
    "\n",
    "# -----------------------------------------\n",
    "# 6️⃣ 최적 모델로 테스트 세트 평가\n",
    "# -----------------------------------------\n",
    "best_model = random_search.best_estimator_\n",
    "y_pred = best_model.predict(X_val)\n",
    "\n",
    "rmse = mean_squared_error(y_val, y_pred, squared=False)\n",
    "mae = mean_absolute_error(y_val, y_pred)\n",
    "r2 = r2_score(y_val, y_pred)\n",
    "\n",
    "print(\"\\n Test Set Performance\")\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "print(f\"MAE : {mae:.4f}\")\n",
    "print(f\"R²  : {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f2ec6fc",
   "metadata": {},
   "source": [
    "## LGB 모델 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f188eea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e801005d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-03 17:35:34,718] A new study created in memory with name: no-name-6bb8f81a-f1c6-4d15-a9b0-d6b42242c56c\n",
      "[I 2025-11-03 17:35:36,205] Trial 0 finished with value: 5.198702863560119 and parameters: {'num_leaves': 35, 'n_estimators': 771, 'min_child_weight': 16, 'max_depth': 17, 'learning_rate': 0.07938433332786657, 'colsample_bytree': 0.451254771546166}. Best is trial 0 with value: 5.198702863560119.\n",
      "[I 2025-11-03 17:35:36,377] Trial 1 finished with value: 4.862066512150573 and parameters: {'num_leaves': 23, 'n_estimators': 252, 'min_child_weight': 8, 'max_depth': 27, 'learning_rate': 0.011263166370192463, 'colsample_bytree': 0.4477836524089067}. Best is trial 1 with value: 4.862066512150573.\n",
      "[I 2025-11-03 17:35:37,374] Trial 2 finished with value: 5.136363365328018 and parameters: {'num_leaves': 22, 'n_estimators': 709, 'min_child_weight': 15, 'max_depth': 16, 'learning_rate': 0.08619900668523305, 'colsample_bytree': 0.5155947519272781}. Best is trial 1 with value: 4.862066512150573.\n",
      "[I 2025-11-03 17:35:37,520] Trial 3 finished with value: 4.901347571528915 and parameters: {'num_leaves': 24, 'n_estimators': 236, 'min_child_weight': 7, 'max_depth': 17, 'learning_rate': 0.05708823638796255, 'colsample_bytree': 0.443354612190737}. Best is trial 1 with value: 4.862066512150573.\n",
      "[I 2025-11-03 17:35:37,743] Trial 4 finished with value: 4.782733214881328 and parameters: {'num_leaves': 23, 'n_estimators': 362, 'min_child_weight': 6, 'max_depth': 28, 'learning_rate': 0.011552260876080083, 'colsample_bytree': 0.6518299296886484}. Best is trial 4 with value: 4.782733214881328.\n",
      "[I 2025-11-03 17:35:38,117] Trial 5 finished with value: 5.021457485340226 and parameters: {'num_leaves': 38, 'n_estimators': 423, 'min_child_weight': 6, 'max_depth': 29, 'learning_rate': 0.059216061502287705, 'colsample_bytree': 0.7500167078609385}. Best is trial 4 with value: 4.782733214881328.\n",
      "[I 2025-11-03 17:35:38,329] Trial 6 finished with value: 4.836779075353206 and parameters: {'num_leaves': 23, 'n_estimators': 386, 'min_child_weight': 19, 'max_depth': 17, 'learning_rate': 0.02571936371026013, 'colsample_bytree': 0.4183912983640773}. Best is trial 4 with value: 4.782733214881328.\n",
      "[I 2025-11-03 17:35:38,937] Trial 7 finished with value: 5.074047371255287 and parameters: {'num_leaves': 39, 'n_estimators': 741, 'min_child_weight': 12, 'max_depth': 22, 'learning_rate': 0.03523001625259528, 'colsample_bytree': 0.7897760205540373}. Best is trial 4 with value: 4.782733214881328.\n",
      "[I 2025-11-03 17:35:39,391] Trial 8 finished with value: 5.021693702143868 and parameters: {'num_leaves': 32, 'n_estimators': 631, 'min_child_weight': 11, 'max_depth': 29, 'learning_rate': 0.04279043612606892, 'colsample_bytree': 0.7558635416063966}. Best is trial 4 with value: 4.782733214881328.\n",
      "[I 2025-11-03 17:35:39,835] Trial 9 finished with value: 5.0626583924414446 and parameters: {'num_leaves': 23, 'n_estimators': 752, 'min_child_weight': 9, 'max_depth': 18, 'learning_rate': 0.050785900755302545, 'colsample_bytree': 0.7902694295151962}. Best is trial 4 with value: 4.782733214881328.\n",
      "[I 2025-11-03 17:35:40,395] Trial 10 finished with value: 4.835298326686451 and parameters: {'num_leaves': 28, 'n_estimators': 940, 'min_child_weight': 5, 'max_depth': 10, 'learning_rate': 0.01137272095851815, 'colsample_bytree': 0.6522982659578953}. Best is trial 4 with value: 4.782733214881328.\n",
      "[I 2025-11-03 17:35:40,965] Trial 11 finished with value: 4.840433512222059 and parameters: {'num_leaves': 28, 'n_estimators': 920, 'min_child_weight': 5, 'max_depth': 11, 'learning_rate': 0.010991011419454036, 'colsample_bytree': 0.6313865712604092}. Best is trial 4 with value: 4.782733214881328.\n",
      "[I 2025-11-03 17:35:41,642] Trial 12 finished with value: 4.986997553446704 and parameters: {'num_leaves': 28, 'n_estimators': 983, 'min_child_weight': 5, 'max_depth': 23, 'learning_rate': 0.025211602999198866, 'colsample_bytree': 0.6619345679049015}. Best is trial 4 with value: 4.782733214881328.\n",
      "[I 2025-11-03 17:35:41,977] Trial 13 finished with value: 4.871127064036876 and parameters: {'num_leaves': 28, 'n_estimators': 507, 'min_child_weight': 10, 'max_depth': 10, 'learning_rate': 0.02272846288012103, 'colsample_bytree': 0.5590413820510636}. Best is trial 4 with value: 4.782733214881328.\n",
      "[I 2025-11-03 17:35:42,071] Trial 14 finished with value: 4.830400808668282 and parameters: {'num_leaves': 20, 'n_estimators': 129, 'min_child_weight': 8, 'max_depth': 25, 'learning_rate': 0.07207780817584691, 'colsample_bytree': 0.6849807345351735}. Best is trial 4 with value: 4.782733214881328.\n",
      "[I 2025-11-03 17:35:42,176] Trial 15 finished with value: 4.870319327386848 and parameters: {'num_leaves': 20, 'n_estimators': 122, 'min_child_weight': 8, 'max_depth': 25, 'learning_rate': 0.0996314903549568, 'colsample_bytree': 0.6995993171075836}. Best is trial 4 with value: 4.782733214881328.\n",
      "[I 2025-11-03 17:35:42,252] Trial 16 finished with value: 4.848784356280748 and parameters: {'num_leaves': 20, 'n_estimators': 102, 'min_child_weight': 14, 'max_depth': 26, 'learning_rate': 0.06803484572181463, 'colsample_bytree': 0.593010643374748}. Best is trial 4 with value: 4.782733214881328.\n",
      "[I 2025-11-03 17:35:42,451] Trial 17 finished with value: 4.944106867248133 and parameters: {'num_leaves': 25, 'n_estimators': 282, 'min_child_weight': 10, 'max_depth': 30, 'learning_rate': 0.0731778436250871, 'colsample_bytree': 0.6857480290981464}. Best is trial 4 with value: 4.782733214881328.\n",
      "[I 2025-11-03 17:35:42,681] Trial 18 finished with value: 5.070262596704656 and parameters: {'num_leaves': 26, 'n_estimators': 370, 'min_child_weight': 7, 'max_depth': 22, 'learning_rate': 0.09329613464956069, 'colsample_bytree': 0.7181359540711785}. Best is trial 4 with value: 4.782733214881328.\n",
      "[I 2025-11-03 17:35:42,827] Trial 19 finished with value: 4.93747486165037 and parameters: {'num_leaves': 32, 'n_estimators': 185, 'min_child_weight': 13, 'max_depth': 24, 'learning_rate': 0.0665250696968714, 'colsample_bytree': 0.5989874577041931}. Best is trial 4 with value: 4.782733214881328.\n",
      "[I 2025-11-03 17:35:43,106] Trial 20 finished with value: 4.954202221088319 and parameters: {'num_leaves': 20, 'n_estimators': 502, 'min_child_weight': 20, 'max_depth': 20, 'learning_rate': 0.049834977628578414, 'colsample_bytree': 0.5198529643066193}. Best is trial 4 with value: 4.782733214881328.\n",
      "[I 2025-11-03 17:35:43,632] Trial 21 finished with value: 4.923161525888628 and parameters: {'num_leaves': 26, 'n_estimators': 867, 'min_child_weight': 5, 'max_depth': 14, 'learning_rate': 0.019504033203764204, 'colsample_bytree': 0.6459224997520429}. Best is trial 4 with value: 4.782733214881328.\n",
      "[I 2025-11-03 17:35:44,105] Trial 22 finished with value: 5.0045382886437695 and parameters: {'num_leaves': 32, 'n_estimators': 585, 'min_child_weight': 7, 'max_depth': 27, 'learning_rate': 0.03467286351388104, 'colsample_bytree': 0.6243951270181327}. Best is trial 4 with value: 4.782733214881328.\n",
      "[I 2025-11-03 17:35:44,388] Trial 23 finished with value: 4.764655498481592 and parameters: {'num_leaves': 21, 'n_estimators': 450, 'min_child_weight': 6, 'max_depth': 20, 'learning_rate': 0.016654806203493126, 'colsample_bytree': 0.6746097200750574}. Best is trial 23 with value: 4.764655498481592.\n",
      "[I 2025-11-03 17:35:44,586] Trial 24 finished with value: 4.8356070355281355 and parameters: {'num_leaves': 21, 'n_estimators': 330, 'min_child_weight': 8, 'max_depth': 28, 'learning_rate': 0.03532009403207727, 'colsample_bytree': 0.6906123238369863}. Best is trial 23 with value: 4.764655498481592.\n",
      "[I 2025-11-03 17:35:44,838] Trial 25 finished with value: 5.046510332215141 and parameters: {'num_leaves': 22, 'n_estimators': 455, 'min_child_weight': 9, 'max_depth': 20, 'learning_rate': 0.078104899917437, 'colsample_bytree': 0.7228693082138247}. Best is trial 23 with value: 4.764655498481592.\n",
      "[I 2025-11-03 17:35:45,011] Trial 26 finished with value: 4.88106081849486 and parameters: {'num_leaves': 21, 'n_estimators': 294, 'min_child_weight': 6, 'max_depth': 24, 'learning_rate': 0.03008767087256716, 'colsample_bytree': 0.5647591773681853}. Best is trial 23 with value: 4.764655498481592.\n",
      "[I 2025-11-03 17:35:45,134] Trial 27 finished with value: 4.766160943980997 and parameters: {'num_leaves': 25, 'n_estimators': 159, 'min_child_weight': 10, 'max_depth': 21, 'learning_rate': 0.017665758034841585, 'colsample_bytree': 0.6803540087408843}. Best is trial 23 with value: 4.764655498481592.\n",
      "[I 2025-11-03 17:35:45,286] Trial 28 finished with value: 4.749244292486353 and parameters: {'num_leaves': 25, 'n_estimators': 209, 'min_child_weight': 17, 'max_depth': 14, 'learning_rate': 0.01762520444176587, 'colsample_bytree': 0.738309788645241}. Best is trial 28 with value: 4.749244292486353.\n",
      "[I 2025-11-03 17:35:45,436] Trial 29 finished with value: 4.752607483571394 and parameters: {'num_leaves': 30, 'n_estimators': 185, 'min_child_weight': 16, 'max_depth': 13, 'learning_rate': 0.019033463266964867, 'colsample_bytree': 0.7525523631054182}. Best is trial 28 with value: 4.749244292486353.\n",
      "[I 2025-11-03 17:35:45,586] Trial 30 finished with value: 4.836279443643714 and parameters: {'num_leaves': 30, 'n_estimators': 201, 'min_child_weight': 17, 'max_depth': 13, 'learning_rate': 0.04399204060413704, 'colsample_bytree': 0.7352492135836548}. Best is trial 28 with value: 4.749244292486353.\n",
      "[I 2025-11-03 17:35:45,738] Trial 31 finished with value: 4.752760661267853 and parameters: {'num_leaves': 35, 'n_estimators': 168, 'min_child_weight': 17, 'max_depth': 14, 'learning_rate': 0.01853752131048096, 'colsample_bytree': 0.7647257905984863}. Best is trial 28 with value: 4.749244292486353.\n",
      "[I 2025-11-03 17:35:45,939] Trial 32 finished with value: 4.75941637919183 and parameters: {'num_leaves': 34, 'n_estimators': 225, 'min_child_weight': 17, 'max_depth': 14, 'learning_rate': 0.017361656758983955, 'colsample_bytree': 0.7639715101607026}. Best is trial 28 with value: 4.749244292486353.\n",
      "[I 2025-11-03 17:35:46,171] Trial 33 finished with value: 4.800507360192097 and parameters: {'num_leaves': 34, 'n_estimators': 246, 'min_child_weight': 17, 'max_depth': 14, 'learning_rate': 0.03059446640656817, 'colsample_bytree': 0.7680929849852314}. Best is trial 28 with value: 4.749244292486353.\n",
      "[I 2025-11-03 17:35:46,327] Trial 34 finished with value: 4.760431588747944 and parameters: {'num_leaves': 36, 'n_estimators': 200, 'min_child_weight': 16, 'max_depth': 13, 'learning_rate': 0.018418790584809185, 'colsample_bytree': 0.7667837900699006}. Best is trial 28 with value: 4.749244292486353.\n",
      "[I 2025-11-03 17:35:46,546] Trial 35 finished with value: 4.813794094612535 and parameters: {'num_leaves': 35, 'n_estimators': 308, 'min_child_weight': 18, 'max_depth': 15, 'learning_rate': 0.02689982861888652, 'colsample_bytree': 0.7937167082392205}. Best is trial 28 with value: 4.749244292486353.\n",
      "[I 2025-11-03 17:35:46,741] Trial 36 finished with value: 4.763647897498299 and parameters: {'num_leaves': 37, 'n_estimators': 242, 'min_child_weight': 15, 'max_depth': 12, 'learning_rate': 0.015586956345590802, 'colsample_bytree': 0.7124418639156059}. Best is trial 28 with value: 4.749244292486353.\n",
      "[I 2025-11-03 17:35:46,888] Trial 37 finished with value: 4.757892766456342 and parameters: {'num_leaves': 33, 'n_estimators': 171, 'min_child_weight': 18, 'max_depth': 16, 'learning_rate': 0.020643291057004617, 'colsample_bytree': 0.7451425301361277}. Best is trial 28 with value: 4.749244292486353.\n",
      "[I 2025-11-03 17:35:47,025] Trial 38 finished with value: 4.795761505804985 and parameters: {'num_leaves': 30, 'n_estimators': 152, 'min_child_weight': 19, 'max_depth': 16, 'learning_rate': 0.04073946333249036, 'colsample_bytree': 0.7373946979599727}. Best is trial 28 with value: 4.749244292486353.\n",
      "[I 2025-11-03 17:35:47,174] Trial 39 finished with value: 4.7735630404115135 and parameters: {'num_leaves': 30, 'n_estimators': 175, 'min_child_weight': 15, 'max_depth': 18, 'learning_rate': 0.022646282310120412, 'colsample_bytree': 0.7428642570922743}. Best is trial 28 with value: 4.749244292486353.\n",
      "[I 2025-11-03 17:35:47,285] Trial 40 finished with value: 4.752907595074549 and parameters: {'num_leaves': 40, 'n_estimators': 101, 'min_child_weight': 18, 'max_depth': 16, 'learning_rate': 0.028630418228984232, 'colsample_bytree': 0.7776645894454758}. Best is trial 28 with value: 4.749244292486353.\n",
      "[I 2025-11-03 17:35:47,407] Trial 41 finished with value: 4.747833779759572 and parameters: {'num_leaves': 40, 'n_estimators': 107, 'min_child_weight': 18, 'max_depth': 16, 'learning_rate': 0.031136929532986968, 'colsample_bytree': 0.7798132673179637}. Best is trial 41 with value: 4.747833779759572.\n",
      "[I 2025-11-03 17:35:47,529] Trial 42 finished with value: 4.755321453851648 and parameters: {'num_leaves': 40, 'n_estimators': 111, 'min_child_weight': 19, 'max_depth': 12, 'learning_rate': 0.030106701872626727, 'colsample_bytree': 0.7997180135247658}. Best is trial 41 with value: 4.747833779759572.\n",
      "[I 2025-11-03 17:35:47,751] Trial 43 finished with value: 4.870488120479022 and parameters: {'num_leaves': 40, 'n_estimators': 257, 'min_child_weight': 16, 'max_depth': 18, 'learning_rate': 0.03777355627405038, 'colsample_bytree': 0.7736591397676059}. Best is trial 41 with value: 4.747833779759572.\n",
      "[I 2025-11-03 17:35:47,860] Trial 44 finished with value: 4.929580222238259 and parameters: {'num_leaves': 38, 'n_estimators': 101, 'min_child_weight': 18, 'max_depth': 15, 'learning_rate': 0.013337245274609787, 'colsample_bytree': 0.7823622360667037}. Best is trial 41 with value: 4.747833779759572.\n",
      "[I 2025-11-03 17:35:48,149] Trial 45 finished with value: 4.876092422327832 and parameters: {'num_leaves': 38, 'n_estimators': 341, 'min_child_weight': 20, 'max_depth': 17, 'learning_rate': 0.027702630988692592, 'colsample_bytree': 0.7080432569062943}. Best is trial 41 with value: 4.747833779759572.\n",
      "[I 2025-11-03 17:35:48,574] Trial 46 finished with value: 4.914480552240675 and parameters: {'num_leaves': 39, 'n_estimators': 658, 'min_child_weight': 15, 'max_depth': 12, 'learning_rate': 0.023826754796503164, 'colsample_bytree': 0.7551201373366301}. Best is trial 41 with value: 4.747833779759572.\n",
      "[I 2025-11-03 17:35:48,753] Trial 47 finished with value: 4.87539047096209 and parameters: {'num_leaves': 36, 'n_estimators': 220, 'min_child_weight': 14, 'max_depth': 15, 'learning_rate': 0.04679964806910948, 'colsample_bytree': 0.7290346783628475}. Best is trial 41 with value: 4.747833779759572.\n",
      "[I 2025-11-03 17:35:48,899] Trial 48 finished with value: 4.915157757941016 and parameters: {'num_leaves': 39, 'n_estimators': 139, 'min_child_weight': 16, 'max_depth': 17, 'learning_rate': 0.010059761908294412, 'colsample_bytree': 0.7789635096000228}. Best is trial 41 with value: 4.747833779759572.\n",
      "[I 2025-11-03 17:35:49,091] Trial 49 finished with value: 4.9607933504888475 and parameters: {'num_leaves': 37, 'n_estimators': 265, 'min_child_weight': 18, 'max_depth': 11, 'learning_rate': 0.058426549615350334, 'colsample_bytree': 0.47027183507691084}. Best is trial 41 with value: 4.747833779759572.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RMSE: 4.7478\n",
      "Best Parameters:\n",
      "  num_leaves: 40\n",
      "  n_estimators: 107\n",
      "  min_child_weight: 18\n",
      "  max_depth: 16\n",
      "  learning_rate: 0.031136929532986968\n",
      "  colsample_bytree: 0.7798132673179637\n",
      "MAE: 2.7049, R²: 0.4248\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    params = {\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 20, 40),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 5, 20),\n",
    "        'max_depth': trial.suggest_int('max_depth', 10, 30),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.4, 0.8),\n",
    "        'random_state': 42,\n",
    "        'force_row_wise': True,\n",
    "        'verbose': -1 \n",
    "    }\n",
    "    model = LGBMRegressor(**params)\n",
    "\n",
    "    model.fit(X_train, y_train, eval_set=[(X_val, y_val)],)\n",
    "    y_pred = model.predict(X_val)\n",
    "\n",
    "    # 여러 지표 계산\n",
    "    rmse_val = rmse(y_val, y_pred)\n",
    "    mae_val = mean_absolute_error(y_val, y_pred)\n",
    "    r2_val = r2_score(y_val, y_pred)\n",
    "\n",
    "    # 참고용 출력 (튜닝 과정에서 로그로 볼 수 있음)\n",
    "    trial.set_user_attr(\"MAE\", mae_val)\n",
    "    trial.set_user_attr(\"R2\", r2_val)\n",
    "\n",
    "    # 최적화 기준은 RMSE (낮을수록 좋음)\n",
    "    return rmse_val\n",
    "\n",
    "# Optuna 실행\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# 결과 출력\n",
    "best_trial = study.best_trial\n",
    "print(f\"Best RMSE: {best_trial.value:.4f}\")\n",
    "print(\"Best Parameters:\")\n",
    "for key, value in best_trial.params.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "print(f\"MAE: {best_trial.user_attrs['MAE']:.4f}, R²: {best_trial.user_attrs['R2']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75a96a4",
   "metadata": {},
   "source": [
    "LGB의 Best Parameters:  \n",
    "  num_leaves: 40  \n",
    "  n_estimators: 107  \n",
    "  min_child_weight: 18  \n",
    "  max_depth: 16  \n",
    "  learning_rate: 0.031136929532986968  \n",
    "  colsample_bytree: 0.7798132673179637  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d18649c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2d595671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000251 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 785\n",
      "[LightGBM] [Info] Number of data points in the train set: 1643, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 8.712112\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\n",
      " Best RMSE (CV): 3.715502194181763\n",
      " Best Parameters: {'subsample': 1.0, 'reg_lambda': 0.021544346900318832, 'reg_alpha': 0.46415888336127775, 'num_leaves': 70, 'min_child_samples': 95, 'max_depth': 4, 'learning_rate': 0.019999999999999997, 'colsample_bytree': 0.6}\n",
      "\n",
      " Test Set Performance (LightGBM)\n",
      "RMSE: 4.7589\n",
      "MAE : 2.7217\n",
      "R²  : 0.4221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\uni\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "lgb = LGBMRegressor(\n",
    "    objective='regression',\n",
    "    random_state=42,\n",
    "    n_estimators=1000,\n",
    ")\n",
    "\n",
    "# --------------------------\n",
    "# 하이퍼파라미터 범위 설정\n",
    "# --------------------------\n",
    "param_distributions = {\n",
    "    'num_leaves': np.arange(20, 200, 10),\n",
    "    'max_depth': np.arange(3, 15),\n",
    "    'learning_rate': np.linspace(0.01, 0.3, 30),\n",
    "    'subsample': np.linspace(0.5, 1.0, 6),\n",
    "    'colsample_bytree': np.linspace(0.5, 1.0, 6),\n",
    "    'min_child_samples': np.arange(5, 100, 5),\n",
    "    'reg_alpha': np.logspace(-3, 1, 10),\n",
    "    'reg_lambda': np.logspace(-3, 1, 10)\n",
    "}\n",
    "\n",
    "# --------------------------\n",
    "#  랜덤서치 수행\n",
    "# --------------------------\n",
    "random_search_lgb = RandomizedSearchCV(\n",
    "    estimator=lgb,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=50,\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    cv=5,\n",
    "    verbose=2,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "random_search_lgb.fit(X_train, y_train)\n",
    "\n",
    "# --------------------------\n",
    "# 5️⃣ 결과 및 평가\n",
    "# --------------------------\n",
    "print(\"\\n Best RMSE (CV):\", -random_search_lgb.best_score_)\n",
    "print(\" Best Parameters:\", random_search_lgb.best_params_)\n",
    "\n",
    "best_lgb = random_search_lgb.best_estimator_\n",
    "y_pred = best_lgb.predict(X_val)\n",
    "\n",
    "rmse = mean_squared_error(y_val, y_pred, squared=False)\n",
    "mae = mean_absolute_error(y_val, y_pred)\n",
    "r2 = r2_score(y_val, y_pred)\n",
    "\n",
    "print(\"\\n Test Set Performance (LightGBM)\")\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "print(f\"MAE : {mae:.4f}\")\n",
    "print(f\"R²  : {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ffafc12",
   "metadata": {},
   "source": [
    "## Catboost 모델 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4155c18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7724c601",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-03 17:48:17,925] A new study created in memory with name: no-name-5bed38f0-1097-4f9b-902c-45330cfd7577\n",
      "[I 2025-11-03 17:48:18,894] Trial 0 finished with value: 4.766718256718546 and parameters: {'iterations': 951, 'depth': 9, 'learning_rate': 0.09178110743022803, 'l2_leaf_reg': 4.379493202010171, 'border_count': 247, 'bagging_temperature': 0.7918651011979015, 'random_strength': 5.474332058067621}. Best is trial 0 with value: 4.766718256718546.\n",
      "[I 2025-11-03 17:48:19,325] Trial 1 finished with value: 4.718909148055081 and parameters: {'iterations': 885, 'depth': 7, 'learning_rate': 0.07038395423767098, 'l2_leaf_reg': 5.567868800643655, 'border_count': 231, 'bagging_temperature': 0.8203229658264228, 'random_strength': 5.14708735502997}. Best is trial 1 with value: 4.718909148055081.\n",
      "[I 2025-11-03 17:48:19,653] Trial 2 finished with value: 4.759440551622628 and parameters: {'iterations': 597, 'depth': 8, 'learning_rate': 0.207944721502538, 'l2_leaf_reg': 9.50339686643955, 'border_count': 206, 'bagging_temperature': 0.7298804955755221, 'random_strength': 5.180972402696724}. Best is trial 1 with value: 4.718909148055081.\n",
      "[I 2025-11-03 17:48:19,854] Trial 3 finished with value: 4.673422784599844 and parameters: {'iterations': 938, 'depth': 4, 'learning_rate': 0.06431636772725963, 'l2_leaf_reg': 10.328874823778767, 'border_count': 102, 'bagging_temperature': 0.2863737332985712, 'random_strength': 1.3616276954241984}. Best is trial 3 with value: 4.673422784599844.\n",
      "[I 2025-11-03 17:48:20,144] Trial 4 finished with value: 4.710659537821617 and parameters: {'iterations': 625, 'depth': 4, 'learning_rate': 0.03787209792034976, 'l2_leaf_reg': 4.11372939856624, 'border_count': 146, 'bagging_temperature': 0.8377662276449652, 'random_strength': 1.8260609180828968}. Best is trial 3 with value: 4.673422784599844.\n",
      "[I 2025-11-03 17:48:20,448] Trial 5 finished with value: 4.749430974131515 and parameters: {'iterations': 508, 'depth': 8, 'learning_rate': 0.16471583230612194, 'l2_leaf_reg': 10.923318648096046, 'border_count': 69, 'bagging_temperature': 0.00797515794818393, 'random_strength': 3.9722147626947355}. Best is trial 3 with value: 4.673422784599844.\n",
      "[I 2025-11-03 17:48:20,597] Trial 6 finished with value: 4.675468075902371 and parameters: {'iterations': 963, 'depth': 4, 'learning_rate': 0.28205336552695026, 'l2_leaf_reg': 5.069660725228984, 'border_count': 198, 'bagging_temperature': 0.39687645040399167, 'random_strength': 3.930456088418911}. Best is trial 3 with value: 4.673422784599844.\n",
      "[I 2025-11-03 17:48:21,590] Trial 7 finished with value: 4.736783172663525 and parameters: {'iterations': 560, 'depth': 7, 'learning_rate': 0.016266399278842, 'l2_leaf_reg': 2.8780031381026623, 'border_count': 62, 'bagging_temperature': 0.974276996801952, 'random_strength': 7.887951633749435}. Best is trial 3 with value: 4.673422784599844.\n",
      "[I 2025-11-03 17:48:23,037] Trial 8 finished with value: 4.762446135214565 and parameters: {'iterations': 555, 'depth': 9, 'learning_rate': 0.05257905567419567, 'l2_leaf_reg': 8.254220568077319, 'border_count': 216, 'bagging_temperature': 0.5110122616358164, 'random_strength': 2.0624904716516195}. Best is trial 3 with value: 4.673422784599844.\n",
      "[I 2025-11-03 17:48:23,803] Trial 9 finished with value: 4.806198886048641 and parameters: {'iterations': 513, 'depth': 10, 'learning_rate': 0.07337718075532065, 'l2_leaf_reg': 10.780998866567009, 'border_count': 84, 'bagging_temperature': 0.5333416560303472, 'random_strength': 6.277436072887817}. Best is trial 3 with value: 4.673422784599844.\n",
      "[I 2025-11-03 17:48:24,004] Trial 10 finished with value: 4.7196361805959794 and parameters: {'iterations': 801, 'depth': 5, 'learning_rate': 0.12348781225972161, 'l2_leaf_reg': 14.773950213137441, 'border_count': 121, 'bagging_temperature': 0.12965130704603967, 'random_strength': 0.46622283761809746}. Best is trial 3 with value: 4.673422784599844.\n",
      "[I 2025-11-03 17:48:24,250] Trial 11 finished with value: 4.691189785353681 and parameters: {'iterations': 999, 'depth': 5, 'learning_rate': 0.28618099525431784, 'l2_leaf_reg': 6.802462558011511, 'border_count': 160, 'bagging_temperature': 0.27097866569571977, 'random_strength': 2.986781248803978}. Best is trial 3 with value: 4.673422784599844.\n",
      "[I 2025-11-03 17:48:24,370] Trial 12 finished with value: 4.638840580697891 and parameters: {'iterations': 855, 'depth': 4, 'learning_rate': 0.288813599168531, 'l2_leaf_reg': 1.0342850221391329, 'border_count': 186, 'bagging_temperature': 0.32366041122193456, 'random_strength': 0.24757810681054515}. Best is trial 12 with value: 4.638840580697891.\n",
      "[I 2025-11-03 17:48:24,473] Trial 13 finished with value: 4.756958461084394 and parameters: {'iterations': 827, 'depth': 5, 'learning_rate': 0.2262517435876154, 'l2_leaf_reg': 1.7213394633891759, 'border_count': 113, 'bagging_temperature': 0.2976982022190787, 'random_strength': 0.1607322986840558}. Best is trial 12 with value: 4.638840580697891.\n",
      "[I 2025-11-03 17:48:24,617] Trial 14 finished with value: 4.73395763385063 and parameters: {'iterations': 736, 'depth': 6, 'learning_rate': 0.16975762864270383, 'l2_leaf_reg': 13.093867536248617, 'border_count': 33, 'bagging_temperature': 0.20678097529034262, 'random_strength': 1.4302700953857843}. Best is trial 12 with value: 4.638840580697891.\n",
      "[I 2025-11-03 17:48:24,760] Trial 15 finished with value: 4.764440136937077 and parameters: {'iterations': 887, 'depth': 4, 'learning_rate': 0.12670266642619063, 'l2_leaf_reg': 12.06253792094316, 'border_count': 174, 'bagging_temperature': 0.6088868825617644, 'random_strength': 8.99521925828985}. Best is trial 12 with value: 4.638840580697891.\n",
      "[I 2025-11-03 17:48:24,892] Trial 16 finished with value: 4.749407095100214 and parameters: {'iterations': 742, 'depth': 6, 'learning_rate': 0.22943496622775264, 'l2_leaf_reg': 7.9892479610416745, 'border_count': 110, 'bagging_temperature': 0.376994348928157, 'random_strength': 1.0158698793512322}. Best is trial 12 with value: 4.638840580697891.\n",
      "[I 2025-11-03 17:48:25,083] Trial 17 finished with value: 4.716934422761932 and parameters: {'iterations': 898, 'depth': 6, 'learning_rate': 0.11994675565117105, 'l2_leaf_reg': 1.7700397465694042, 'border_count': 180, 'bagging_temperature': 0.08485650384654597, 'random_strength': 2.6818568712132334}. Best is trial 12 with value: 4.638840580697891.\n",
      "[I 2025-11-03 17:48:25,187] Trial 18 finished with value: 4.653351273747345 and parameters: {'iterations': 680, 'depth': 4, 'learning_rate': 0.2662591153182177, 'l2_leaf_reg': 6.922130715584719, 'border_count': 141, 'bagging_temperature': 0.3972250186857898, 'random_strength': 3.540360001270244}. Best is trial 12 with value: 4.638840580697891.\n",
      "[I 2025-11-03 17:48:25,348] Trial 19 finished with value: 4.6963858256837305 and parameters: {'iterations': 677, 'depth': 5, 'learning_rate': 0.24821705795521865, 'l2_leaf_reg': 6.417526026008012, 'border_count': 135, 'bagging_temperature': 0.42623903081675035, 'random_strength': 3.8708398628578573}. Best is trial 12 with value: 4.638840580697891.\n",
      "[I 2025-11-03 17:48:25,523] Trial 20 finished with value: 4.698065497894977 and parameters: {'iterations': 685, 'depth': 6, 'learning_rate': 0.2600990695329388, 'l2_leaf_reg': 1.0558476469133273, 'border_count': 181, 'bagging_temperature': 0.6014772473633174, 'random_strength': 7.395724219008304}. Best is trial 12 with value: 4.638840580697891.\n",
      "[I 2025-11-03 17:48:25,638] Trial 21 finished with value: 4.673548583176062 and parameters: {'iterations': 814, 'depth': 4, 'learning_rate': 0.29618270582643946, 'l2_leaf_reg': 8.441274461560687, 'border_count': 97, 'bagging_temperature': 0.2958488541975493, 'random_strength': 0.03233392743482133}. Best is trial 12 with value: 4.638840580697891.\n",
      "[I 2025-11-03 17:48:25,766] Trial 22 finished with value: 4.686111201462738 and parameters: {'iterations': 933, 'depth': 4, 'learning_rate': 0.21530887711463925, 'l2_leaf_reg': 9.397560415458123, 'border_count': 144, 'bagging_temperature': 0.20831336675315076, 'random_strength': 2.7922213037533896}. Best is trial 12 with value: 4.638840580697891.\n",
      "[I 2025-11-03 17:48:25,923] Trial 23 finished with value: 4.732379820535328 and parameters: {'iterations': 861, 'depth': 5, 'learning_rate': 0.18717351312413055, 'l2_leaf_reg': 3.2172964869856298, 'border_count': 158, 'bagging_temperature': 0.4164523415720065, 'random_strength': 1.215379577289153}. Best is trial 12 with value: 4.638840580697891.\n",
      "[I 2025-11-03 17:48:26,057] Trial 24 finished with value: 4.647645725446426 and parameters: {'iterations': 771, 'depth': 4, 'learning_rate': 0.2595852668886866, 'l2_leaf_reg': 13.030154694006159, 'border_count': 131, 'bagging_temperature': 0.3286175776431828, 'random_strength': 2.0169202572389677}. Best is trial 12 with value: 4.638840580697891.\n",
      "[I 2025-11-03 17:48:26,201] Trial 25 finished with value: 4.716147586134801 and parameters: {'iterations': 769, 'depth': 5, 'learning_rate': 0.26378731872786565, 'l2_leaf_reg': 14.532017789301937, 'border_count': 128, 'bagging_temperature': 0.47073531592061096, 'random_strength': 2.5027319198893396}. Best is trial 12 with value: 4.638840580697891.\n",
      "[I 2025-11-03 17:48:26,340] Trial 26 finished with value: 4.652859313579165 and parameters: {'iterations': 684, 'depth': 4, 'learning_rate': 0.24752637170463088, 'l2_leaf_reg': 6.876654104609713, 'border_count': 165, 'bagging_temperature': 0.35473438159555754, 'random_strength': 3.641063850425169}. Best is trial 12 with value: 4.638840580697891.\n",
      "[I 2025-11-03 17:48:26,473] Trial 27 finished with value: 4.671751332622626 and parameters: {'iterations': 717, 'depth': 5, 'learning_rate': 0.24214670960914567, 'l2_leaf_reg': 13.792451359205433, 'border_count': 192, 'bagging_temperature': 0.21165897700435626, 'random_strength': 4.401612681317066}. Best is trial 12 with value: 4.638840580697891.\n",
      "[I 2025-11-03 17:48:26,587] Trial 28 finished with value: 4.71498142890706 and parameters: {'iterations': 766, 'depth': 4, 'learning_rate': 0.19615766764216033, 'l2_leaf_reg': 12.933071525233196, 'border_count': 160, 'bagging_temperature': 0.5899187254436065, 'random_strength': 2.104276668813085}. Best is trial 12 with value: 4.638840580697891.\n",
      "[I 2025-11-03 17:48:26,759] Trial 29 finished with value: 4.78693801507284 and parameters: {'iterations': 645, 'depth': 6, 'learning_rate': 0.28039010128912795, 'l2_leaf_reg': 11.901410814999767, 'border_count': 224, 'bagging_temperature': 0.34059873715206157, 'random_strength': 6.331892394349744}. Best is trial 12 with value: 4.638840580697891.\n",
      "[I 2025-11-03 17:48:26,973] Trial 30 finished with value: 4.8724281492214 and parameters: {'iterations': 829, 'depth': 8, 'learning_rate': 0.23885380985032306, 'l2_leaf_reg': 3.879418530612481, 'border_count': 241, 'bagging_temperature': 0.6875856935742088, 'random_strength': 3.144737616779844}. Best is trial 12 with value: 4.638840580697891.\n",
      "[I 2025-11-03 17:48:27,090] Trial 31 finished with value: 4.661545225760275 and parameters: {'iterations': 696, 'depth': 4, 'learning_rate': 0.2634498699798645, 'l2_leaf_reg': 6.806287686465805, 'border_count': 169, 'bagging_temperature': 0.459527747486701, 'random_strength': 3.4283643345493133}. Best is trial 12 with value: 4.638840580697891.\n",
      "[I 2025-11-03 17:48:27,181] Trial 32 finished with value: 4.739914364454683 and parameters: {'iterations': 644, 'depth': 4, 'learning_rate': 0.2980645716655199, 'l2_leaf_reg': 5.767879973330073, 'border_count': 147, 'bagging_temperature': 0.34849707049388784, 'random_strength': 0.9126173622047231}. Best is trial 12 with value: 4.638840580697891.\n",
      "[I 2025-11-03 17:48:27,307] Trial 33 finished with value: 4.72988756298847 and parameters: {'iterations': 785, 'depth': 5, 'learning_rate': 0.26838439103098105, 'l2_leaf_reg': 7.7258251309900015, 'border_count': 133, 'bagging_temperature': 0.14146316143340892, 'random_strength': 4.675657323193966}. Best is trial 12 with value: 4.638840580697891.\n",
      "[I 2025-11-03 17:48:27,465] Trial 34 finished with value: 4.687832304840943 and parameters: {'iterations': 848, 'depth': 4, 'learning_rate': 0.24912193174258723, 'l2_leaf_reg': 9.310514425007899, 'border_count': 190, 'bagging_temperature': 0.22753793008362244, 'random_strength': 5.458435608365538}. Best is trial 12 with value: 4.638840580697891.\n",
      "[I 2025-11-03 17:48:27,599] Trial 35 finished with value: 4.649549367804368 and parameters: {'iterations': 719, 'depth': 4, 'learning_rate': 0.2108874907447295, 'l2_leaf_reg': 4.956242981053228, 'border_count': 207, 'bagging_temperature': 0.3270878584601802, 'random_strength': 1.7850016657311352}. Best is trial 12 with value: 4.638840580697891.\n",
      "[I 2025-11-03 17:48:27,750] Trial 36 finished with value: 4.677835431016896 and parameters: {'iterations': 732, 'depth': 5, 'learning_rate': 0.20385349181099888, 'l2_leaf_reg': 5.02807762096725, 'border_count': 251, 'bagging_temperature': 0.3298343641203789, 'random_strength': 1.7522104155313838}. Best is trial 12 with value: 4.638840580697891.\n",
      "[I 2025-11-03 17:48:27,911] Trial 37 finished with value: 4.732504923773643 and parameters: {'iterations': 713, 'depth': 4, 'learning_rate': 0.18604093201199062, 'l2_leaf_reg': 3.1381618243907607, 'border_count': 208, 'bagging_temperature': 0.2600495174882447, 'random_strength': 0.6374457562921354}. Best is trial 12 with value: 4.638840580697891.\n",
      "[I 2025-11-03 17:48:28,201] Trial 38 finished with value: 4.726173943499815 and parameters: {'iterations': 606, 'depth': 7, 'learning_rate': 0.22501876185753442, 'l2_leaf_reg': 4.486693217166367, 'border_count': 233, 'bagging_temperature': 0.16453565787064162, 'random_strength': 2.3208945221392137}. Best is trial 12 with value: 4.638840580697891.\n",
      "[I 2025-11-03 17:48:28,392] Trial 39 finished with value: 4.664218318348564 and parameters: {'iterations': 652, 'depth': 4, 'learning_rate': 0.1463544157428659, 'l2_leaf_reg': 5.476588429362661, 'border_count': 204, 'bagging_temperature': 0.015491093534973133, 'random_strength': 1.640572159234855}. Best is trial 12 with value: 4.638840580697891.\n",
      "[I 2025-11-03 17:48:28,855] Trial 40 finished with value: 4.731264094925732 and parameters: {'iterations': 781, 'depth': 9, 'learning_rate': 0.2804786839339117, 'l2_leaf_reg': 10.226912547598861, 'border_count': 217, 'bagging_temperature': 0.5318506443802815, 'random_strength': 0.5962207671182407}. Best is trial 12 with value: 4.638840580697891.\n",
      "[I 2025-11-03 17:48:28,972] Trial 41 finished with value: 4.678135511353726 and parameters: {'iterations': 664, 'depth': 4, 'learning_rate': 0.2550570640853456, 'l2_leaf_reg': 7.4808708683445, 'border_count': 169, 'bagging_temperature': 0.3847221692620642, 'random_strength': 3.6135926894732964}. Best is trial 12 with value: 4.638840580697891.\n",
      "[I 2025-11-03 17:48:29,090] Trial 42 finished with value: 4.703761813099403 and parameters: {'iterations': 691, 'depth': 4, 'learning_rate': 0.27428235858209443, 'l2_leaf_reg': 6.555701331954562, 'border_count': 148, 'bagging_temperature': 0.4613893915420536, 'random_strength': 4.9024823532007105}. Best is trial 12 with value: 4.638840580697891.\n",
      "[I 2025-11-03 17:48:29,323] Trial 43 finished with value: 4.69589120306802 and parameters: {'iterations': 619, 'depth': 5, 'learning_rate': 0.2374194543305609, 'l2_leaf_reg': 5.883375384000036, 'border_count': 188, 'bagging_temperature': 0.32257975485836227, 'random_strength': 4.294029634404767}. Best is trial 12 with value: 4.638840580697891.\n",
      "[I 2025-11-03 17:48:29,463] Trial 44 finished with value: 4.7146675111364305 and parameters: {'iterations': 758, 'depth': 4, 'learning_rate': 0.21656268056668035, 'l2_leaf_reg': 8.811575179998618, 'border_count': 154, 'bagging_temperature': 0.37792632909409724, 'random_strength': 3.1537017063526944}. Best is trial 12 with value: 4.638840580697891.\n",
      "[I 2025-11-03 17:48:29,585] Trial 45 finished with value: 4.69417683453761 and parameters: {'iterations': 711, 'depth': 4, 'learning_rate': 0.2950053610435614, 'l2_leaf_reg': 7.253281833797356, 'border_count': 116, 'bagging_temperature': 0.25197309766376197, 'random_strength': 2.108943812653881}. Best is trial 12 with value: 4.638840580697891.\n",
      "[I 2025-11-03 17:48:29,749] Trial 46 finished with value: 4.7644745875966 and parameters: {'iterations': 577, 'depth': 5, 'learning_rate': 0.27370602812187, 'l2_leaf_reg': 2.445825646079074, 'border_count': 101, 'bagging_temperature': 0.4226505922864501, 'random_strength': 5.963719006318479}. Best is trial 12 with value: 4.638840580697891.\n",
      "[I 2025-11-03 17:48:29,885] Trial 47 finished with value: 4.716513582060937 and parameters: {'iterations': 794, 'depth': 4, 'learning_rate': 0.25405082647239924, 'l2_leaf_reg': 5.032120431788261, 'border_count': 133, 'bagging_temperature': 0.5067194696871542, 'random_strength': 1.3478197645154995}. Best is trial 12 with value: 4.638840580697891.\n",
      "[I 2025-11-03 17:48:30,640] Trial 48 finished with value: 4.8726324862957044 and parameters: {'iterations': 920, 'depth': 10, 'learning_rate': 0.28648277411503775, 'l2_leaf_reg': 3.76839568777809, 'border_count': 203, 'bagging_temperature': 0.2947744085805193, 'random_strength': 3.501332189111946}. Best is trial 12 with value: 4.638840580697891.\n",
      "[I 2025-11-03 17:48:30,807] Trial 49 finished with value: 4.801714773200582 and parameters: {'iterations': 857, 'depth': 5, 'learning_rate': 0.23003839241448965, 'l2_leaf_reg': 4.572317246043427, 'border_count': 73, 'bagging_temperature': 0.5544712484147455, 'random_strength': 9.615659672711525}. Best is trial 12 with value: 4.638840580697891.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RMSE: 4.6388\n",
      "Best Parameters:\n",
      "  iterations: 855\n",
      "  depth: 4\n",
      "  learning_rate: 0.288813599168531\n",
      "  l2_leaf_reg: 1.0342850221391329\n",
      "  border_count: 186\n",
      "  bagging_temperature: 0.32366041122193456\n",
      "  random_strength: 0.24757810681054515\n",
      "MAE: 2.6918, R²: 0.4509\n"
     ]
    }
   ],
   "source": [
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "# Optuna objective 함수\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'iterations': trial.suggest_int('iterations', 500, 1000),\n",
    "        'depth': trial.suggest_int('depth', 4, 10),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "        'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1, 15),\n",
    "        'border_count': trial.suggest_int('border_count', 32, 255),\n",
    "        'bagging_temperature': trial.suggest_float('bagging_temperature', 0.0, 1.0),\n",
    "        'random_strength': trial.suggest_float('random_strength', 1e-9, 10),\n",
    "        'random_seed': 42,\n",
    "        'verbose': False,\n",
    "        'thread_count': -1\n",
    "    }\n",
    "\n",
    "    model = CatBoostRegressor(**params)\n",
    "    model.fit(X_train, y_train, eval_set=(X_val, y_val), early_stopping_rounds=50)\n",
    "    \n",
    "    y_pred = model.predict(X_val)\n",
    "    \n",
    "    # 여러 지표 계산\n",
    "    rmse_val = rmse(y_val, y_pred)\n",
    "    mae_val = mean_absolute_error(y_val, y_pred)\n",
    "    r2_val = r2_score(y_val, y_pred)\n",
    "\n",
    "    # 참고용 출력 (튜닝 과정에서 로그로 볼 수 있음)\n",
    "    trial.set_user_attr(\"MAE\", mae_val)\n",
    "    trial.set_user_attr(\"R2\", r2_val)\n",
    "\n",
    "    return rmse(y_val, y_pred)\n",
    "\n",
    "# Optuna 실행\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# 결과 출력\n",
    "best_trial = study.best_trial\n",
    "print(f\"Best RMSE: {best_trial.value:.4f}\")\n",
    "print(\"Best Parameters:\")\n",
    "for key, value in best_trial.params.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "print(f\"MAE: {best_trial.user_attrs['MAE']:.4f}, R²: {best_trial.user_attrs['R2']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee30f85f",
   "metadata": {},
   "source": [
    "Catboost의 Best Parameters:  \n",
    "  iterations: 855  \n",
    "  depth: 4  \n",
    "  learning_rate: 0.288813599168531  \n",
    "  l2_leaf_reg: 1.0342850221391329  \n",
    "  border_count: 186  \n",
    "  bagging_temperature: 0.32366041122193456  \n",
    "  random_strength: 0.24757810681054515  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9762e43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "107743a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n",
      "\n",
      "✅ Best RMSE (CV): 3.657675433747881\n",
      "✅ Best Parameters: {'learning_rate': 0.01, 'l2_leaf_reg': 7.0, 'iterations': 400, 'depth': 4, 'border_count': 128, 'bagging_temperature': 0.7000000000000001}\n",
      "\n",
      "📊 Test Set Performance (CatBoost)\n",
      "RMSE: 4.7574\n",
      "MAE : 2.7036\n",
      "R²  : 0.4225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\uni\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "cat = CatBoostRegressor(\n",
    "    loss_function='RMSE',\n",
    "    random_state=42,\n",
    "    silent=True\n",
    ")\n",
    "\n",
    "# --------------------------\n",
    "# 3하이퍼파라미터 범위 설정\n",
    "# --------------------------\n",
    "param_distributions = {\n",
    "    'depth': np.arange(3, 12),\n",
    "    'learning_rate': np.linspace(0.01, 0.3, 30),\n",
    "    'iterations': np.arange(300, 1200, 100),\n",
    "    'l2_leaf_reg': np.linspace(1, 10, 10),\n",
    "    'bagging_temperature': np.linspace(0, 1, 11),\n",
    "    'border_count': [32, 64, 128, 254],\n",
    "}\n",
    "\n",
    "# --------------------------\n",
    "# 4랜덤서치 수행\n",
    "# --------------------------\n",
    "random_search_cat = RandomizedSearchCV(\n",
    "    estimator=cat,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=40,\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    cv=5,\n",
    "    verbose=2,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "random_search_cat.fit(X_train, y_train)\n",
    "\n",
    "# --------------------------\n",
    "# 5️⃣ 결과 및 평가\n",
    "# --------------------------\n",
    "print(\"\\n✅ Best RMSE (CV):\", -random_search_cat.best_score_)\n",
    "print(\"✅ Best Parameters:\", random_search_cat.best_params_)\n",
    "\n",
    "best_cat = random_search_cat.best_estimator_\n",
    "y_pred = best_cat.predict(X_val)\n",
    "\n",
    "rmse = mean_squared_error(y_val, y_pred, squared=False)\n",
    "mae = mean_absolute_error(y_val, y_pred)\n",
    "r2 = r2_score(y_val, y_pred)\n",
    "\n",
    "print(\"\\n📊 Test Set Performance (CatBoost)\")\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "print(f\"MAE : {mae:.4f}\")\n",
    "print(f\"R²  : {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de552924",
   "metadata": {},
   "source": [
    "## Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3cede0d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['FA4', 'Pandemic_1', 'Pandemic_2', 'Country_US', 'Country_JP', 'Country_KR', 'Mid_Balanced', 'Later_Viral', 'wk2_AudiencePerShow', 'Show_Change']\n",
      "['Total_Weeks']\n"
     ]
    }
   ],
   "source": [
    "# lasso 모델은 원핫인코딩 할 때 drop_first=True로 더미변수를 만들거나, 다중공선성을 제거해야함 \n",
    "# 기준 변수를 하나씩 제거해서 완전한 선형 종속성이 생기는 것을 방지\n",
    "\n",
    "# 1. 타겟 (Y) 컬럼 목록 정의\n",
    "target_columns = ['Total_Weeks']\n",
    "\n",
    "# 2. X (특성 데이터) 생성: 타겟 컬럼들을 제외한 나머지\n",
    "X = df_train_encoded[[\"FA4\", \"Pandemic_1\", \"Pandemic_2\", \"Country_US\",\t\"Country_JP\",\"Country_KR\", \n",
    "                      'Mid_Balanced','Later_Viral','wk2_AudiencePerShow','Show_Change']]\n",
    "\n",
    "# 3. Y (타겟 데이터) 생성: 타겟 컬럼들만 선택\n",
    "y = df_train_encoded[target_columns]\n",
    "\n",
    "# 결과 확인\n",
    "print(X.columns.tolist())\n",
    "print(y.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2e4f7f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c7d54667",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1643"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fe432c1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b02033f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optuna로 파라미터 조절\n",
    "import optuna\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ca9fa679",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "42aa8f1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-05 13:35:42,164] A new study created in memory with name: no-name-8ed4876c-eb2c-4b8c-b318-968b9af76308\n",
      "[I 2025-11-05 13:35:42,190] Trial 0 finished with value: 4.4185537302311175 and parameters: {'alpha': 1.3688871974889898}. Best is trial 0 with value: 4.4185537302311175.\n",
      "[I 2025-11-05 13:35:42,210] Trial 1 finished with value: 3.76311231512326 and parameters: {'alpha': 0.02861477090125919}. Best is trial 1 with value: 3.76311231512326.\n",
      "[I 2025-11-05 13:35:42,235] Trial 2 finished with value: 3.761522958051515 and parameters: {'alpha': 0.002788489241379628}. Best is trial 2 with value: 3.761522958051515.\n",
      "[I 2025-11-05 13:35:42,265] Trial 3 finished with value: 4.942541093841159 and parameters: {'alpha': 2.8745910074800585}. Best is trial 2 with value: 3.761522958051515.\n",
      "[I 2025-11-05 13:35:42,291] Trial 4 finished with value: 4.942541093841159 and parameters: {'alpha': 3.4059533146764527}. Best is trial 2 with value: 3.761522958051515.\n",
      "[I 2025-11-05 13:35:42,328] Trial 5 finished with value: 4.942541093841159 and parameters: {'alpha': 3.145043238319593}. Best is trial 2 with value: 3.761522958051515.\n",
      "[I 2025-11-05 13:35:42,351] Trial 6 finished with value: 3.867987770903851 and parameters: {'alpha': 0.43316348269425603}. Best is trial 2 with value: 3.761522958051515.\n",
      "[I 2025-11-05 13:35:42,377] Trial 7 finished with value: 3.761412369412203 and parameters: {'alpha': 1.664585896160081e-05}. Best is trial 7 with value: 3.761412369412203.\n",
      "[I 2025-11-05 13:35:42,393] Trial 8 finished with value: 3.7620629642657533 and parameters: {'alpha': 0.015433361427374398}. Best is trial 7 with value: 3.761412369412203.\n",
      "[I 2025-11-05 13:35:42,420] Trial 9 finished with value: 3.761425123637031 and parameters: {'alpha': 0.0003995005909934077}. Best is trial 7 with value: 3.761412369412203.\n",
      "[I 2025-11-05 13:35:42,442] Trial 10 finished with value: 3.761412237556434 and parameters: {'alpha': 1.2565833616976008e-05}. Best is trial 10 with value: 3.761412237556434.\n",
      "[I 2025-11-05 13:35:42,468] Trial 11 finished with value: 3.7614122190101336 and parameters: {'alpha': 1.2019440199167665e-05}. Best is trial 11 with value: 3.7614122190101336.\n",
      "[I 2025-11-05 13:35:42,498] Trial 12 finished with value: 3.7614121687940325 and parameters: {'alpha': 1.0539785843155189e-05}. Best is trial 12 with value: 3.7614121687940325.\n",
      "[I 2025-11-05 13:35:42,531] Trial 13 finished with value: 3.7614177381163847 and parameters: {'alpha': 0.0001822790988465304}. Best is trial 12 with value: 3.7614121687940325.\n",
      "[I 2025-11-05 13:35:42,564] Trial 14 finished with value: 3.761414865236515 and parameters: {'alpha': 9.360510897244e-05}. Best is trial 12 with value: 3.7614121687940325.\n",
      "[I 2025-11-05 13:35:42,591] Trial 15 finished with value: 3.761450983809683 and parameters: {'alpha': 0.0011124513978415004}. Best is trial 12 with value: 3.7614121687940325.\n",
      "[I 2025-11-05 13:35:42,625] Trial 16 finished with value: 3.7614132825374362 and parameters: {'alpha': 4.518417196960436e-05}. Best is trial 12 with value: 3.7614121687940325.\n",
      "[I 2025-11-05 13:35:42,641] Trial 17 finished with value: 3.78010275669737 and parameters: {'alpha': 0.11044564616352717}. Best is trial 12 with value: 3.7614121687940325.\n",
      "[I 2025-11-05 13:35:42,679] Trial 18 finished with value: 3.7615105741129113 and parameters: {'alpha': 0.0025079811626515834}. Best is trial 12 with value: 3.7614121687940325.\n",
      "[I 2025-11-05 13:35:42,704] Trial 19 finished with value: 3.761412169592687 and parameters: {'alpha': 1.0563321469834571e-05}. Best is trial 12 with value: 3.7614121687940325.\n",
      "[I 2025-11-05 13:35:42,728] Trial 20 finished with value: 3.7614133160517405 and parameters: {'alpha': 4.616640357059822e-05}. Best is trial 12 with value: 3.7614121687940325.\n",
      "[I 2025-11-05 13:35:42,751] Trial 21 finished with value: 3.7614121594238177 and parameters: {'alpha': 1.0263647503122503e-05}. Best is trial 21 with value: 3.7614121594238177.\n",
      "[I 2025-11-05 13:35:42,776] Trial 22 finished with value: 3.7614208697837697 and parameters: {'alpha': 0.00027717804484144614}. Best is trial 21 with value: 3.7614121594238177.\n",
      "[I 2025-11-05 13:35:42,800] Trial 23 finished with value: 3.761413073181019 and parameters: {'alpha': 3.8355854276137387e-05}. Best is trial 21 with value: 3.7614121594238177.\n",
      "[I 2025-11-05 13:35:42,827] Trial 24 finished with value: 3.76141527815862 and parameters: {'alpha': 0.00010762461157896031}. Best is trial 21 with value: 3.7614121594238177.\n",
      "[I 2025-11-05 13:35:42,856] Trial 25 finished with value: 3.7614374380814217 and parameters: {'alpha': 0.00073432202165833}. Best is trial 21 with value: 3.7614121594238177.\n",
      "[I 2025-11-05 13:35:42,880] Trial 26 finished with value: 3.761412764734415 and parameters: {'alpha': 2.8684719332962192e-05}. Best is trial 21 with value: 3.7614121594238177.\n",
      "[I 2025-11-05 13:35:42,910] Trial 27 finished with value: 3.7614146088230695 and parameters: {'alpha': 8.614178549858992e-05}. Best is trial 21 with value: 3.7614121594238177.\n",
      "[I 2025-11-05 13:35:42,936] Trial 28 finished with value: 3.761412178363995 and parameters: {'alpha': 1.0821798380820626e-05}. Best is trial 21 with value: 3.7614121594238177.\n",
      "[I 2025-11-05 13:35:42,965] Trial 29 finished with value: 3.761526726557796 and parameters: {'alpha': 0.0028654678904302317}. Best is trial 21 with value: 3.7614121594238177.\n",
      "[I 2025-11-05 13:35:42,997] Trial 30 finished with value: 3.7614127729313473 and parameters: {'alpha': 2.9211813281369924e-05}. Best is trial 21 with value: 3.7614121594238177.\n",
      "[I 2025-11-05 13:35:43,016] Trial 31 finished with value: 3.7614121625164776 and parameters: {'alpha': 1.0354788900176785e-05}. Best is trial 21 with value: 3.7614121594238177.\n",
      "[I 2025-11-05 13:35:43,050] Trial 32 finished with value: 3.7614121582494655 and parameters: {'alpha': 1.0229038706530609e-05}. Best is trial 32 with value: 3.7614121582494655.\n",
      "[I 2025-11-05 13:35:43,081] Trial 33 finished with value: 3.761414149125715 and parameters: {'alpha': 7.194395932603393e-05}. Best is trial 32 with value: 3.7614121582494655.\n",
      "[I 2025-11-05 13:35:43,102] Trial 34 finished with value: 3.7614127788136202 and parameters: {'alpha': 2.9384651546520446e-05}. Best is trial 32 with value: 3.7614121582494655.\n",
      "[I 2025-11-05 13:35:43,149] Trial 35 finished with value: 4.942541093841159 and parameters: {'alpha': 9.180391587071316}. Best is trial 32 with value: 3.7614121582494655.\n",
      "[I 2025-11-05 13:35:43,184] Trial 36 finished with value: 3.761418574988025 and parameters: {'alpha': 0.00021161951166891012}. Best is trial 32 with value: 3.7614121582494655.\n",
      "[I 2025-11-05 13:35:43,203] Trial 37 finished with value: 3.7614125116784436 and parameters: {'alpha': 2.0915529216094686e-05}. Best is trial 32 with value: 3.7614121582494655.\n",
      "[I 2025-11-05 13:35:43,215] Trial 38 finished with value: 3.8248418016968353 and parameters: {'alpha': 0.27180808684422486}. Best is trial 32 with value: 3.7614121582494655.\n",
      "[I 2025-11-05 13:35:43,238] Trial 39 finished with value: 3.761416645636168 and parameters: {'alpha': 0.00014862739809238848}. Best is trial 32 with value: 3.7614121582494655.\n",
      "[I 2025-11-05 13:35:43,257] Trial 40 finished with value: 3.7614293592436616 and parameters: {'alpha': 0.0005263799116385192}. Best is trial 32 with value: 3.7614121582494655.\n",
      "[I 2025-11-05 13:35:43,285] Trial 41 finished with value: 3.761412228193069 and parameters: {'alpha': 1.228998494420841e-05}. Best is trial 32 with value: 3.7614121582494655.\n",
      "[I 2025-11-05 13:35:43,307] Trial 42 finished with value: 3.761412428242447 and parameters: {'alpha': 1.8460269606849293e-05}. Best is trial 32 with value: 3.7614121582494655.\n",
      "[I 2025-11-05 13:35:43,328] Trial 43 finished with value: 3.7614133891605106 and parameters: {'alpha': 4.857182154132288e-05}. Best is trial 32 with value: 3.7614121582494655.\n",
      "[I 2025-11-05 13:35:43,356] Trial 44 finished with value: 3.7614121746989553 and parameters: {'alpha': 1.0713796598211411e-05}. Best is trial 32 with value: 3.7614121582494655.\n",
      "[I 2025-11-05 13:35:43,372] Trial 45 finished with value: 3.766251232439463 and parameters: {'alpha': 0.0502627049879461}. Best is trial 32 with value: 3.7614121582494655.\n",
      "[I 2025-11-05 13:35:43,394] Trial 46 finished with value: 3.7614125033473096 and parameters: {'alpha': 2.0670412558633005e-05}. Best is trial 32 with value: 3.7614121582494655.\n",
      "[I 2025-11-05 13:35:43,413] Trial 47 finished with value: 3.7614136925192425 and parameters: {'alpha': 5.7900039709477824e-05}. Best is trial 32 with value: 3.7614121582494655.\n",
      "[I 2025-11-05 13:35:43,435] Trial 48 finished with value: 3.761754704194094 and parameters: {'alpha': 0.009084429827974198}. Best is trial 32 with value: 3.7614121582494655.\n",
      "[I 2025-11-05 13:35:43,457] Trial 49 finished with value: 3.761412471503739 and parameters: {'alpha': 1.973343176213978e-05}. Best is trial 32 with value: 3.7614121582494655.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RMSE: 3.7614121582494655\n",
      "Best Params: {'alpha': 1.0229038706530609e-05}\n",
      "\n",
      " 최종 성능 평가\n",
      "RMSE: 4.8188\n",
      "MAE : 2.7501\n",
      "R²  : 0.4075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\uni\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    alpha = trial.suggest_float(\"alpha\", 1e-5, 10.0, log=True)\n",
    "\n",
    "    model = Lasso(alpha=alpha, random_state=42, max_iter=1000)\n",
    "\n",
    "    # 교차검증으로 안정적인 RMSE 계산\n",
    "    rmse = -cross_val_score(model, X_train_scaled, y_train,\n",
    "                            scoring=\"neg_root_mean_squared_error\",\n",
    "                            cv=5).mean()\n",
    "    return rmse\n",
    "\n",
    "# --------------------------\n",
    "# Optuna 실행\n",
    "# --------------------------\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=50, timeout=120)  # 시간이나 시도 횟수 조정 가능\n",
    "\n",
    "print(\"Best RMSE:\", study.best_value)\n",
    "print(\"Best Params:\", study.best_params)\n",
    "\n",
    "# --------------------------\n",
    "# 최적 모델로 평가\n",
    "# --------------------------\n",
    "best_alpha = study.best_params[\"alpha\"]\n",
    "best_model = Lasso(alpha=best_alpha, random_state=42, max_iter=10000)\n",
    "best_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred = best_model.predict(X_test_scaled)\n",
    "\n",
    "rmse = mean_squared_error(y_val, y_pred, squared=False)\n",
    "mae = mean_absolute_error(y_val, y_pred)\n",
    "r2 = r2_score(y_val, y_pred)\n",
    "\n",
    "print(\"\\n 최종 성능 평가\")\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "print(f\"MAE : {mae:.4f}\")\n",
    "print(f\"R²  : {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66da68a",
   "metadata": {},
   "source": [
    "그냥 변수 넣고 빼고 반복해서 돌려보자 성능이 너무 안좋다..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7506b5ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['FA4', 'Pandemic_0', 'Pandemic_1', 'Pandemic_2', 'Country_Other', 'Country_US', 'Country_JP', 'Country_KR', 'Early_Explosion', 'Mid_Balanced', 'Later_Viral', 'opening_AudienceStd', 'wk1_Audience', 'wk2_Audience', 'opening_Ho_Retention', 'wk1_Holiday_ShowMean', 'wk2_Holiday_ShowMean', 'wk1_Holiday_AudienceMean', 'wk2_Holiday_AudienceMean']\n",
      "['Total_Weeks']\n"
     ]
    }
   ],
   "source": [
    "# 학습 데이터셋 만들기\n",
    "\n",
    "# 1. 타겟 (Y) 컬럼 목록 정의\n",
    "target_columns = ['Total_Weeks']\n",
    "\n",
    "# 2. X (특성 데이터) 생성: 타겟 컬럼들을 제외한 나머지\n",
    "X = df_train_encoded[[\"FA4\", \"Pandemic_0\", \"Pandemic_1\", \"Pandemic_2\", \"Country_Other\",\"Country_US\", \"Country_JP\",\"Country_KR\", \n",
    "                     'Early_Explosion', 'Mid_Balanced','Later_Viral','opening_AudienceStd','wk1_Audience','wk2_Audience',\n",
    "                     'opening_Ho_Retention','wk1_Holiday_ShowMean','wk2_Holiday_ShowMean','wk1_Holiday_AudienceMean',\n",
    "                     'wk2_Holiday_AudienceMean']]\n",
    "\n",
    "# 3. Y (타겟 데이터) 생성: 타겟 컬럼들만 선택\n",
    "y = df_train_encoded[target_columns]\n",
    "\n",
    "# 결과 확인\n",
    "print(X.columns.tolist())\n",
    "print(y.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40780924",
   "metadata": {},
   "source": [
    "X = df_train_encoded[[\"FA4\", \"Pandemic_0\", \"Pandemic_1\", \"Pandemic_2\", \"Country_Other\",\"Country_US\", \"Country_JP\",\"Country_KR\", \n",
    "                     'Early_Explosion', 'Mid_Balanced','Later_Viral','opening_AudienceStd','wk2_Holiday_AudienceMean','wk2_Holiday_ShowMean',\n",
    "                     'wk1_Audience', 'wk1_AudiencePerShow',\t'wk2_Audience',\t'wk2_AudiencePerShow', 'Show_Change', 'opening_Ho_Retention',\n",
    "                     'wk1_Holiday_AudienceMean','wk1_Holiday_ShowMean']]  \n",
    "                     -rmse:4.3 r^2:0.51"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2bb50c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8d248a10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-05 15:57:11,586] A new study created in memory with name: no-name-36d4cfd2-c67b-4aac-a97f-0577b5055670\n",
      "[I 2025-11-05 15:57:12,285] Trial 0 finished with value: 4.509456377028925 and parameters: {'max_depth': 3, 'learning_rate': 0.16316489805132997, 'n_estimators': 728, 'subsample': 0.5000104756989756, 'colsample_bytree': 0.7113586094730276, 'min_child_weight': 8, 'reg_alpha': 8.486825067443275, 'reg_lambda': 8.61389668079485}. Best is trial 0 with value: 4.509456377028925.\n",
      "[I 2025-11-05 15:57:13,500] Trial 1 finished with value: 4.724083968040289 and parameters: {'max_depth': 10, 'learning_rate': 0.2912461552917846, 'n_estimators': 886, 'subsample': 0.8744685805261311, 'colsample_bytree': 0.9486640566632187, 'min_child_weight': 2, 'reg_alpha': 5.776608570402527, 'reg_lambda': 2.460211244782082}. Best is trial 0 with value: 4.509456377028925.\n",
      "[I 2025-11-05 15:57:13,616] Trial 2 finished with value: 4.442907634790867 and parameters: {'max_depth': 3, 'learning_rate': 0.14355692509122003, 'n_estimators': 138, 'subsample': 0.5792863904019465, 'colsample_bytree': 0.9425598661716825, 'min_child_weight': 6, 'reg_alpha': 0.11830413684379355, 'reg_lambda': 9.260189825203163}. Best is trial 2 with value: 4.442907634790867.\n",
      "[I 2025-11-05 15:57:14,856] Trial 3 finished with value: 4.56558960894548 and parameters: {'max_depth': 10, 'learning_rate': 0.02589814529495533, 'n_estimators': 746, 'subsample': 0.8276290068057384, 'colsample_bytree': 0.6045529834071115, 'min_child_weight': 8, 'reg_alpha': 5.768904528719739, 'reg_lambda': 2.824656084269863}. Best is trial 2 with value: 4.442907634790867.\n",
      "[I 2025-11-05 15:57:16,004] Trial 4 finished with value: 4.659815328166383 and parameters: {'max_depth': 10, 'learning_rate': 0.13834873343695375, 'n_estimators': 795, 'subsample': 0.6968227945510723, 'colsample_bytree': 0.948382857153606, 'min_child_weight': 7, 'reg_alpha': 5.679928682212928, 'reg_lambda': 1.936817566698523}. Best is trial 2 with value: 4.442907634790867.\n",
      "[I 2025-11-05 15:57:16,474] Trial 5 finished with value: 4.501216444005262 and parameters: {'max_depth': 4, 'learning_rate': 0.11087073362907081, 'n_estimators': 566, 'subsample': 0.7053196996288349, 'colsample_bytree': 0.9326907923664289, 'min_child_weight': 6, 'reg_alpha': 8.436444542427585, 'reg_lambda': 7.534256889772578}. Best is trial 2 with value: 4.442907634790867.\n",
      "[I 2025-11-05 15:57:16,812] Trial 6 finished with value: 4.704042944103941 and parameters: {'max_depth': 9, 'learning_rate': 0.2065842465836183, 'n_estimators': 217, 'subsample': 0.6110314898462388, 'colsample_bytree': 0.8393157768854322, 'min_child_weight': 4, 'reg_alpha': 9.075135380015917, 'reg_lambda': 0.3922275828152589}. Best is trial 2 with value: 4.442907634790867.\n",
      "[I 2025-11-05 15:57:17,987] Trial 7 finished with value: 4.594229034950241 and parameters: {'max_depth': 8, 'learning_rate': 0.19258114484963793, 'n_estimators': 820, 'subsample': 0.7142548284605454, 'colsample_bytree': 0.8872082653394364, 'min_child_weight': 2, 'reg_alpha': 2.2595841339373406, 'reg_lambda': 9.00600305821637}. Best is trial 2 with value: 4.442907634790867.\n",
      "[I 2025-11-05 15:57:18,295] Trial 8 finished with value: 4.589200912142561 and parameters: {'max_depth': 10, 'learning_rate': 0.10092983183160253, 'n_estimators': 183, 'subsample': 0.7266440019724594, 'colsample_bytree': 0.5868027424656241, 'min_child_weight': 9, 'reg_alpha': 0.644847974964605, 'reg_lambda': 6.505441905034386}. Best is trial 2 with value: 4.442907634790867.\n",
      "[I 2025-11-05 15:57:18,710] Trial 9 finished with value: 4.622365337400145 and parameters: {'max_depth': 6, 'learning_rate': 0.19570133159754344, 'n_estimators': 386, 'subsample': 0.5649599834715544, 'colsample_bytree': 0.6474116094387456, 'min_child_weight': 4, 'reg_alpha': 5.289110020541994, 'reg_lambda': 9.336610300885388}. Best is trial 2 with value: 4.442907634790867.\n",
      "[I 2025-11-05 15:57:19,093] Trial 10 finished with value: 4.464148187496568 and parameters: {'max_depth': 5, 'learning_rate': 0.04722668708306549, 'n_estimators': 402, 'subsample': 0.988972282335129, 'colsample_bytree': 0.8119299939213387, 'min_child_weight': 10, 'reg_alpha': 2.6334318976060396, 'reg_lambda': 5.02674167529821}. Best is trial 2 with value: 4.442907634790867.\n",
      "[I 2025-11-05 15:57:19,519] Trial 11 finished with value: 4.533363893970711 and parameters: {'max_depth': 5, 'learning_rate': 0.024907088062715965, 'n_estimators': 429, 'subsample': 0.9666639993234418, 'colsample_bytree': 0.7935728759096076, 'min_child_weight': 10, 'reg_alpha': 0.1966287890019034, 'reg_lambda': 4.690380842044252}. Best is trial 2 with value: 4.442907634790867.\n",
      "[I 2025-11-05 15:57:19,663] Trial 12 finished with value: 4.500692930343787 and parameters: {'max_depth': 3, 'learning_rate': 0.07036114740871265, 'n_estimators': 136, 'subsample': 0.99884617682954, 'colsample_bytree': 0.7830071895916776, 'min_child_weight': 5, 'reg_alpha': 2.721188806323996, 'reg_lambda': 5.325509643210072}. Best is trial 2 with value: 4.442907634790867.\n",
      "[I 2025-11-05 15:57:20,000] Trial 13 finished with value: 4.587862377788046 and parameters: {'max_depth': 5, 'learning_rate': 0.2552635890971706, 'n_estimators': 325, 'subsample': 0.818404003014796, 'colsample_bytree': 0.8521644874954419, 'min_child_weight': 10, 'reg_alpha': 2.6862664508080716, 'reg_lambda': 5.014329288102708}. Best is trial 2 with value: 4.442907634790867.\n",
      "[I 2025-11-05 15:57:20,741] Trial 14 finished with value: 4.599782480514459 and parameters: {'max_depth': 7, 'learning_rate': 0.07680046385292696, 'n_estimators': 563, 'subsample': 0.6218673215692071, 'colsample_bytree': 0.9998739166657774, 'min_child_weight': 6, 'reg_alpha': 1.5388960797909297, 'reg_lambda': 6.726095709921331}. Best is trial 2 with value: 4.442907634790867.\n",
      "[I 2025-11-05 15:57:20,999] Trial 15 finished with value: 4.643090886817763 and parameters: {'max_depth': 4, 'learning_rate': 0.011004130006535433, 'n_estimators': 287, 'subsample': 0.9182249365839216, 'colsample_bytree': 0.5192386675653649, 'min_child_weight': 1, 'reg_alpha': 3.9112952621074006, 'reg_lambda': 9.94945670964059}. Best is trial 2 with value: 4.442907634790867.\n",
      "[I 2025-11-05 15:57:21,457] Trial 16 finished with value: 4.538813731542089 and parameters: {'max_depth': 5, 'learning_rate': 0.058681410418598284, 'n_estimators': 475, 'subsample': 0.7904601312265706, 'colsample_bytree': 0.7095160361773882, 'min_child_weight': 8, 'reg_alpha': 3.800570282314127, 'reg_lambda': 7.796813292009558}. Best is trial 2 with value: 4.442907634790867.\n",
      "[I 2025-11-05 15:57:21,585] Trial 17 finished with value: 4.490082228050026 and parameters: {'max_depth': 4, 'learning_rate': 0.1423081737608415, 'n_estimators': 105, 'subsample': 0.5069852205790748, 'colsample_bytree': 0.8854894375029447, 'min_child_weight': 5, 'reg_alpha': 1.5981226871377954, 'reg_lambda': 3.3652904737735345}. Best is trial 2 with value: 4.442907634790867.\n",
      "[I 2025-11-05 15:57:22,242] Trial 18 finished with value: 4.670363052485537 and parameters: {'max_depth': 6, 'learning_rate': 0.10100359391978839, 'n_estimators': 636, 'subsample': 0.6468435960310668, 'colsample_bytree': 0.7602311532509495, 'min_child_weight': 9, 'reg_alpha': 0.07303931925370533, 'reg_lambda': 3.9882128131632184}. Best is trial 2 with value: 4.442907634790867.\n",
      "[I 2025-11-05 15:57:22,480] Trial 19 finished with value: 4.575385374895437 and parameters: {'max_depth': 3, 'learning_rate': 0.22465699086404167, 'n_estimators': 276, 'subsample': 0.9118790398758242, 'colsample_bytree': 0.9908986832490384, 'min_child_weight': 3, 'reg_alpha': 4.007232699611204, 'reg_lambda': 0.8034353073317568}. Best is trial 2 with value: 4.442907634790867.\n",
      "[I 2025-11-05 15:57:23,093] Trial 20 finished with value: 4.58535162576201 and parameters: {'max_depth': 7, 'learning_rate': 0.1672497045130349, 'n_estimators': 497, 'subsample': 0.5553090456889126, 'colsample_bytree': 0.8440207508288653, 'min_child_weight': 7, 'reg_alpha': 6.914668475829642, 'reg_lambda': 6.845701721200662}. Best is trial 2 with value: 4.442907634790867.\n",
      "[I 2025-11-05 15:57:23,254] Trial 21 finished with value: 4.490324500180026 and parameters: {'max_depth': 4, 'learning_rate': 0.12823363790381442, 'n_estimators': 137, 'subsample': 0.5198925272025032, 'colsample_bytree': 0.9002345230247646, 'min_child_weight': 5, 'reg_alpha': 1.3393345264522831, 'reg_lambda': 3.5601393838014435}. Best is trial 2 with value: 4.442907634790867.\n",
      "[I 2025-11-05 15:57:23,396] Trial 22 finished with value: 4.387954492741978 and parameters: {'max_depth': 4, 'learning_rate': 0.14737086712454847, 'n_estimators': 114, 'subsample': 0.5653742055874902, 'colsample_bytree': 0.8919021371556647, 'min_child_weight': 4, 'reg_alpha': 1.3064740216288446, 'reg_lambda': 3.9095499272754726}. Best is trial 22 with value: 4.387954492741978.\n",
      "[I 2025-11-05 15:57:23,628] Trial 23 finished with value: 4.45783141141537 and parameters: {'max_depth': 5, 'learning_rate': 0.04982478452689802, 'n_estimators': 202, 'subsample': 0.5869248393593188, 'colsample_bytree': 0.7986023289708867, 'min_child_weight': 4, 'reg_alpha': 0.8825884330268516, 'reg_lambda': 6.0858753554356735}. Best is trial 22 with value: 4.387954492741978.\n",
      "[I 2025-11-05 15:57:23,821] Trial 24 finished with value: 4.447457384432052 and parameters: {'max_depth': 3, 'learning_rate': 0.16577157348467025, 'n_estimators': 223, 'subsample': 0.5735293320349191, 'colsample_bytree': 0.7209693074980226, 'min_child_weight': 4, 'reg_alpha': 0.8576952607821562, 'reg_lambda': 5.794053279427907}. Best is trial 22 with value: 4.387954492741978.\n",
      "[I 2025-11-05 15:57:24,009] Trial 25 finished with value: 4.495639850079924 and parameters: {'max_depth': 3, 'learning_rate': 0.16329585358030405, 'n_estimators': 246, 'subsample': 0.674544160358871, 'colsample_bytree': 0.7125443716550242, 'min_child_weight': 3, 'reg_alpha': 1.856732083073433, 'reg_lambda': 7.939135228184403}. Best is trial 22 with value: 4.387954492741978.\n",
      "[I 2025-11-05 15:57:24,287] Trial 26 finished with value: 4.559300551828883 and parameters: {'max_depth': 3, 'learning_rate': 0.2353841570278095, 'n_estimators': 338, 'subsample': 0.546767372336471, 'colsample_bytree': 0.6589632385938289, 'min_child_weight': 3, 'reg_alpha': 0.04070500886644725, 'reg_lambda': 1.7278048878372534}. Best is trial 22 with value: 4.387954492741978.\n",
      "[I 2025-11-05 15:57:24,423] Trial 27 finished with value: 4.416342122356265 and parameters: {'max_depth': 4, 'learning_rate': 0.18176961550799886, 'n_estimators': 101, 'subsample': 0.6492070090799396, 'colsample_bytree': 0.7510225573501782, 'min_child_weight': 6, 'reg_alpha': 0.934115047556981, 'reg_lambda': 5.763171073595609}. Best is trial 22 with value: 4.387954492741978.\n",
      "[I 2025-11-05 15:57:24,557] Trial 28 finished with value: 4.425019019213632 and parameters: {'max_depth': 4, 'learning_rate': 0.18029695123184108, 'n_estimators': 101, 'subsample': 0.6524487536640201, 'colsample_bytree': 0.9669395055767945, 'min_child_weight': 6, 'reg_alpha': 3.1949649424621063, 'reg_lambda': 4.41530587604415}. Best is trial 22 with value: 4.387954492741978.\n",
      "[I 2025-11-05 15:57:24,724] Trial 29 finished with value: 4.621837596903257 and parameters: {'max_depth': 6, 'learning_rate': 0.18500948119473745, 'n_estimators': 102, 'subsample': 0.6521758756537243, 'colsample_bytree': 0.9762380866159863, 'min_child_weight': 7, 'reg_alpha': 3.2666550715944407, 'reg_lambda': 4.458063786947473}. Best is trial 22 with value: 4.387954492741978.\n",
      "[I 2025-11-05 15:57:25,596] Trial 30 finished with value: 4.620736919479947 and parameters: {'max_depth': 4, 'learning_rate': 0.26317042625527753, 'n_estimators': 998, 'subsample': 0.7488040412953052, 'colsample_bytree': 0.917611635469343, 'min_child_weight': 6, 'reg_alpha': 4.829884441806469, 'reg_lambda': 4.210759708506026}. Best is trial 22 with value: 4.387954492741978.\n",
      "[I 2025-11-05 15:57:25,767] Trial 31 finished with value: 4.399109253493836 and parameters: {'max_depth': 4, 'learning_rate': 0.12038018490106658, 'n_estimators': 163, 'subsample': 0.6067519317303004, 'colsample_bytree': 0.864839193150819, 'min_child_weight': 6, 'reg_alpha': 1.0867743275008737, 'reg_lambda': 3.2612003310637774}. Best is trial 22 with value: 4.387954492741978.\n",
      "[I 2025-11-05 15:57:25,956] Trial 32 finished with value: 4.44055745129393 and parameters: {'max_depth': 4, 'learning_rate': 0.11754370616591925, 'n_estimators': 166, 'subsample': 0.6240943902484319, 'colsample_bytree': 0.8668436831859212, 'min_child_weight': 7, 'reg_alpha': 2.0866461152875693, 'reg_lambda': 3.0732356010429505}. Best is trial 22 with value: 4.387954492741978.\n",
      "[I 2025-11-05 15:57:26,088] Trial 33 finished with value: 4.490310466940031 and parameters: {'max_depth': 4, 'learning_rate': 0.15149373291624071, 'n_estimators': 101, 'subsample': 0.6684517305303717, 'colsample_bytree': 0.9607359332878064, 'min_child_weight': 5, 'reg_alpha': 1.1105971031264152, 'reg_lambda': 2.3102959294940537}. Best is trial 22 with value: 4.387954492741978.\n",
      "[I 2025-11-05 15:57:26,296] Trial 34 finished with value: 4.479382993003275 and parameters: {'max_depth': 5, 'learning_rate': 0.17835975033853962, 'n_estimators': 168, 'subsample': 0.6073589954206954, 'colsample_bytree': 0.9151098002763883, 'min_child_weight': 6, 'reg_alpha': 4.564572285483997, 'reg_lambda': 3.883400521430532}. Best is trial 22 with value: 4.387954492741978.\n",
      "[I 2025-11-05 15:57:26,591] Trial 35 finished with value: 4.525263570601735 and parameters: {'max_depth': 4, 'learning_rate': 0.21952167219213264, 'n_estimators': 282, 'subsample': 0.637816522865225, 'colsample_bytree': 0.954834234832767, 'min_child_weight': 7, 'reg_alpha': 3.138784647608244, 'reg_lambda': 5.411240986349918}. Best is trial 22 with value: 4.387954492741978.\n",
      "[I 2025-11-05 15:57:27,372] Trial 36 finished with value: 4.583341386077939 and parameters: {'max_depth': 6, 'learning_rate': 0.129951448209983, 'n_estimators': 671, 'subsample': 0.6822856256569452, 'colsample_bytree': 0.7436455792948273, 'min_child_weight': 6, 'reg_alpha': 6.813128457293565, 'reg_lambda': 2.6066492076791548}. Best is trial 22 with value: 4.387954492741978.\n",
      "[I 2025-11-05 15:57:27,623] Trial 37 finished with value: 4.368651405141783 and parameters: {'max_depth': 5, 'learning_rate': 0.08829509612153293, 'n_estimators': 236, 'subsample': 0.5376167434640182, 'colsample_bytree': 0.8278864045914436, 'min_child_weight': 8, 'reg_alpha': 2.0943940224436597, 'reg_lambda': 1.742864142872057}. Best is trial 37 with value: 4.368651405141783.\n",
      "[I 2025-11-05 15:57:27,962] Trial 38 finished with value: 4.479803607814465 and parameters: {'max_depth': 5, 'learning_rate': 0.08785578105505537, 'n_estimators': 342, 'subsample': 0.5317065710621901, 'colsample_bytree': 0.8152237872339145, 'min_child_weight': 8, 'reg_alpha': 0.57782647295716, 'reg_lambda': 1.3191556704703122}. Best is trial 37 with value: 4.368651405141783.\n",
      "[I 2025-11-05 15:57:28,169] Trial 39 finished with value: 4.355315592310572 and parameters: {'max_depth': 3, 'learning_rate': 0.11632130198766118, 'n_estimators': 224, 'subsample': 0.5953782083988163, 'colsample_bytree': 0.8259397214540729, 'min_child_weight': 9, 'reg_alpha': 2.2171950181420383, 'reg_lambda': 0.19266783635925688}. Best is trial 39 with value: 4.355315592310572.\n",
      "[I 2025-11-05 15:57:28,397] Trial 40 finished with value: 4.406367543058204 and parameters: {'max_depth': 3, 'learning_rate': 0.11388402865077837, 'n_estimators': 255, 'subsample': 0.5871365372802432, 'colsample_bytree': 0.8634419163696965, 'min_child_weight': 9, 'reg_alpha': 2.2883177831980075, 'reg_lambda': 0.06931439624920356}. Best is trial 39 with value: 4.355315592310572.\n",
      "[I 2025-11-05 15:57:28,593] Trial 41 finished with value: 4.3561678390867815 and parameters: {'max_depth': 3, 'learning_rate': 0.11487046836117155, 'n_estimators': 238, 'subsample': 0.5922648275721423, 'colsample_bytree': 0.8258834214335771, 'min_child_weight': 9, 'reg_alpha': 2.2104245808708285, 'reg_lambda': 0.23832125072280497}. Best is trial 39 with value: 4.355315592310572.\n",
      "[I 2025-11-05 15:57:28,773] Trial 42 finished with value: 4.451096257235349 and parameters: {'max_depth': 3, 'learning_rate': 0.10028577824929918, 'n_estimators': 213, 'subsample': 0.536448791152261, 'colsample_bytree': 0.8821091853685422, 'min_child_weight': 9, 'reg_alpha': 1.8790448079259783, 'reg_lambda': 0.9028355811438131}. Best is trial 39 with value: 4.355315592310572.\n",
      "[I 2025-11-05 15:57:28,931] Trial 43 finished with value: 4.412771494070764 and parameters: {'max_depth': 3, 'learning_rate': 0.08648561081667838, 'n_estimators': 173, 'subsample': 0.597393382407866, 'colsample_bytree': 0.8305375455517565, 'min_child_weight': 8, 'reg_alpha': 1.4441451326334342, 'reg_lambda': 1.4819217840877574}. Best is trial 39 with value: 4.355315592310572.\n",
      "[I 2025-11-05 15:57:29,214] Trial 44 finished with value: 4.502068115837462 and parameters: {'max_depth': 4, 'learning_rate': 0.12431120596363301, 'n_estimators': 305, 'subsample': 0.5043545700080954, 'colsample_bytree': 0.7769739269400192, 'min_child_weight': 9, 'reg_alpha': 2.419225129474551, 'reg_lambda': 2.051439271954724}. Best is trial 39 with value: 4.355315592310572.\n",
      "[I 2025-11-05 15:57:29,487] Trial 45 finished with value: 4.441704413770645 and parameters: {'max_depth': 3, 'learning_rate': 0.14854059439312006, 'n_estimators': 364, 'subsample': 0.5660871660700235, 'colsample_bytree': 0.82314737704723, 'min_child_weight': 10, 'reg_alpha': 2.8923512768964894, 'reg_lambda': 0.9153613953619978}. Best is trial 39 with value: 4.355315592310572.\n",
      "[I 2025-11-05 15:57:29,673] Trial 46 finished with value: 4.3575087032871975 and parameters: {'max_depth': 3, 'learning_rate': 0.10303519683780116, 'n_estimators': 226, 'subsample': 0.5404935131385029, 'colsample_bytree': 0.858573135171658, 'min_child_weight': 8, 'reg_alpha': 0.5168887756003613, 'reg_lambda': 0.06029081033794337}. Best is trial 39 with value: 4.355315592310572.\n",
      "[I 2025-11-05 15:57:29,970] Trial 47 finished with value: 4.407909503639834 and parameters: {'max_depth': 3, 'learning_rate': 0.10077967013695352, 'n_estimators': 398, 'subsample': 0.5515524031098632, 'colsample_bytree': 0.9277506543093217, 'min_child_weight': 8, 'reg_alpha': 0.5446951959663477, 'reg_lambda': 0.1931354095555517}. Best is trial 39 with value: 4.355315592310572.\n",
      "[I 2025-11-05 15:57:30,570] Trial 48 finished with value: 4.578267089639665 and parameters: {'max_depth': 8, 'learning_rate': 0.07093325731847352, 'n_estimators': 442, 'subsample': 0.5335580190526489, 'colsample_bytree': 0.8986693628512896, 'min_child_weight': 9, 'reg_alpha': 3.656474382269534, 'reg_lambda': 0.6863872764975238}. Best is trial 39 with value: 4.355315592310572.\n",
      "[I 2025-11-05 15:57:30,776] Trial 49 finished with value: 4.325817673263636 and parameters: {'max_depth': 3, 'learning_rate': 0.13537855717294683, 'n_estimators': 249, 'subsample': 0.576918374853744, 'colsample_bytree': 0.8154083320108116, 'min_child_weight': 10, 'reg_alpha': 1.8646438768135667, 'reg_lambda': 1.333581941369193}. Best is trial 49 with value: 4.325817673263636.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RMSE: 4.3258\n",
      "Best Parameters:\n",
      "  max_depth: 3\n",
      "  learning_rate: 0.13537855717294683\n",
      "  n_estimators: 249\n",
      "  subsample: 0.576918374853744\n",
      "  colsample_bytree: 0.8154083320108116\n",
      "  min_child_weight: 10\n",
      "  reg_alpha: 1.8646438768135667\n",
      "  reg_lambda: 1.333581941369193\n",
      "MAE: 2.4585, R²: 0.5225\n"
     ]
    }
   ],
   "source": [
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 1e-8, 10),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 1e-8, 10),\n",
    "        'random_state': 42,\n",
    "        'tree_method': 'hist'  \n",
    "    }\n",
    "\n",
    "    model = XGBRegressor(**params)\n",
    "    model.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=False)\n",
    "\n",
    "    y_pred = model.predict(X_val)\n",
    "\n",
    "    # 여러 지표 계산\n",
    "    rmse_val = rmse(y_val, y_pred)\n",
    "    mae_val = mean_absolute_error(y_val, y_pred)\n",
    "    r2_val = r2_score(y_val, y_pred)\n",
    "\n",
    "    # 참고용 출력 (튜닝 과정에서 로그로 볼 수 있음)\n",
    "    trial.set_user_attr(\"MAE\", mae_val)\n",
    "    trial.set_user_attr(\"R2\", r2_val)\n",
    "\n",
    "    # 최적화 기준은 RMSE (낮을수록 좋음)\n",
    "    return rmse_val\n",
    "\n",
    "# Optuna 실행\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# 결과 출력\n",
    "best_trial = study.best_trial\n",
    "print(f\"Best RMSE: {best_trial.value:.4f}\")\n",
    "print(\"Best Parameters:\")\n",
    "for key, value in best_trial.params.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "print(f\"MAE: {best_trial.user_attrs['MAE']:.4f}, R²: {best_trial.user_attrs['R2']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "71d4471b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-05 15:53:21,637] A new study created in memory with name: no-name-0e1ce1c9-5be4-4e10-ace0-63afccfe0ce3\n",
      "[I 2025-11-05 15:53:22,267] Trial 0 finished with value: 4.5919607397207525 and parameters: {'iterations': 983, 'depth': 4, 'learning_rate': 0.021047482531425833, 'l2_leaf_reg': 14.001541567085253, 'border_count': 230, 'bagging_temperature': 0.3308884979784501, 'random_strength': 1.6788936872919575}. Best is trial 0 with value: 4.5919607397207525.\n",
      "[I 2025-11-05 15:53:23,072] Trial 1 finished with value: 4.525242831143951 and parameters: {'iterations': 779, 'depth': 5, 'learning_rate': 0.014118972195744369, 'l2_leaf_reg': 4.812168258859659, 'border_count': 54, 'bagging_temperature': 0.6569063504863751, 'random_strength': 7.301212666131683}. Best is trial 1 with value: 4.525242831143951.\n",
      "[I 2025-11-05 15:53:23,561] Trial 2 finished with value: 4.482902958127093 and parameters: {'iterations': 966, 'depth': 4, 'learning_rate': 0.02991906045519048, 'l2_leaf_reg': 2.0148625466331054, 'border_count': 236, 'bagging_temperature': 0.5225510759392922, 'random_strength': 0.17606860075347294}. Best is trial 2 with value: 4.482902958127093.\n",
      "[I 2025-11-05 15:53:28,430] Trial 3 finished with value: 4.61513190109819 and parameters: {'iterations': 546, 'depth': 10, 'learning_rate': 0.04124557187852238, 'l2_leaf_reg': 14.357005763060068, 'border_count': 111, 'bagging_temperature': 0.3667194795915534, 'random_strength': 1.6907720379052291}. Best is trial 2 with value: 4.482902958127093.\n",
      "[I 2025-11-05 15:53:29,050] Trial 4 finished with value: 4.550514325519741 and parameters: {'iterations': 858, 'depth': 7, 'learning_rate': 0.19283537881836993, 'l2_leaf_reg': 8.646280022170446, 'border_count': 104, 'bagging_temperature': 0.6365901424802923, 'random_strength': 6.572980739975597}. Best is trial 2 with value: 4.482902958127093.\n",
      "[I 2025-11-05 15:53:29,329] Trial 5 finished with value: 4.5492345863392645 and parameters: {'iterations': 783, 'depth': 6, 'learning_rate': 0.19657527917828743, 'l2_leaf_reg': 10.637131602818839, 'border_count': 212, 'bagging_temperature': 0.5448438961438127, 'random_strength': 6.7678193957937}. Best is trial 2 with value: 4.482902958127093.\n",
      "[I 2025-11-05 15:53:29,997] Trial 6 finished with value: 4.431216371213205 and parameters: {'iterations': 871, 'depth': 7, 'learning_rate': 0.16208096935021138, 'l2_leaf_reg': 2.334710192846444, 'border_count': 232, 'bagging_temperature': 0.7459196972597442, 'random_strength': 8.35242691819723}. Best is trial 6 with value: 4.431216371213205.\n",
      "[I 2025-11-05 15:53:31,897] Trial 7 finished with value: 4.510125052191398 and parameters: {'iterations': 616, 'depth': 8, 'learning_rate': 0.09087621887581333, 'l2_leaf_reg': 12.330436166296687, 'border_count': 167, 'bagging_temperature': 0.04151057476612918, 'random_strength': 0.5354496759518622}. Best is trial 6 with value: 4.431216371213205.\n",
      "[I 2025-11-05 15:53:35,601] Trial 8 finished with value: 4.576503551722711 and parameters: {'iterations': 643, 'depth': 10, 'learning_rate': 0.2938891551082914, 'l2_leaf_reg': 11.246221381852802, 'border_count': 212, 'bagging_temperature': 0.3697744173520512, 'random_strength': 3.9214891888641885}. Best is trial 6 with value: 4.431216371213205.\n",
      "[I 2025-11-05 15:53:36,562] Trial 9 finished with value: 4.502739767879697 and parameters: {'iterations': 583, 'depth': 7, 'learning_rate': 0.022041089672392322, 'l2_leaf_reg': 1.9823268786901664, 'border_count': 120, 'bagging_temperature': 0.4393084660705002, 'random_strength': 6.02251575331846}. Best is trial 6 with value: 4.431216371213205.\n",
      "[I 2025-11-05 15:53:37,498] Trial 10 finished with value: 4.562664648208091 and parameters: {'iterations': 884, 'depth': 8, 'learning_rate': 0.13728392567062545, 'l2_leaf_reg': 5.881836000121249, 'border_count': 173, 'bagging_temperature': 0.9990057633582023, 'random_strength': 9.198349742035585}. Best is trial 6 with value: 4.431216371213205.\n",
      "[I 2025-11-05 15:53:37,750] Trial 11 finished with value: 4.520235770025673 and parameters: {'iterations': 995, 'depth': 4, 'learning_rate': 0.11766928182321233, 'l2_leaf_reg': 1.6990995976166694, 'border_count': 249, 'bagging_temperature': 0.8373232417867968, 'random_strength': 9.974575722883065}. Best is trial 6 with value: 4.431216371213205.\n",
      "[I 2025-11-05 15:53:37,985] Trial 12 finished with value: 4.560565155451399 and parameters: {'iterations': 897, 'depth': 5, 'learning_rate': 0.20567885718185133, 'l2_leaf_reg': 3.975821747376208, 'border_count': 254, 'bagging_temperature': 0.828116289017173, 'random_strength': 4.112266883007205}. Best is trial 6 with value: 4.431216371213205.\n",
      "[I 2025-11-05 15:53:40,782] Trial 13 finished with value: 4.557942662757251 and parameters: {'iterations': 935, 'depth': 9, 'learning_rate': 0.08061762535705419, 'l2_leaf_reg': 7.1140676396164855, 'border_count': 186, 'bagging_temperature': 0.13366959410929746, 'random_strength': 7.941206898838677}. Best is trial 6 with value: 4.431216371213205.\n",
      "[I 2025-11-05 15:53:41,070] Trial 14 finished with value: 4.54827191880115 and parameters: {'iterations': 831, 'depth': 6, 'learning_rate': 0.25468184524041315, 'l2_leaf_reg': 3.031570977325268, 'border_count': 202, 'bagging_temperature': 0.7434142305958455, 'random_strength': 4.982333379951845}. Best is trial 6 with value: 4.431216371213205.\n",
      "[I 2025-11-05 15:53:41,276] Trial 15 finished with value: 4.499058994144176 and parameters: {'iterations': 711, 'depth': 5, 'learning_rate': 0.16217556083345988, 'l2_leaf_reg': 1.7918715983819453, 'border_count': 149, 'bagging_temperature': 0.5446849593978843, 'random_strength': 2.9148913592400305}. Best is trial 6 with value: 4.431216371213205.\n",
      "[I 2025-11-05 15:53:41,922] Trial 16 finished with value: 4.4916900189062305 and parameters: {'iterations': 931, 'depth': 6, 'learning_rate': 0.07104340458574591, 'l2_leaf_reg': 6.049600962571066, 'border_count': 230, 'bagging_temperature': 0.22933587260264182, 'random_strength': 0.06852626670001719}. Best is trial 6 with value: 4.431216371213205.\n",
      "[I 2025-11-05 15:53:42,352] Trial 17 finished with value: 4.5233561176259 and parameters: {'iterations': 715, 'depth': 8, 'learning_rate': 0.11626007729366375, 'l2_leaf_reg': 3.865239516428006, 'border_count': 58, 'bagging_temperature': 0.9384297365597526, 'random_strength': 8.63818910599851}. Best is trial 6 with value: 4.431216371213205.\n",
      "[I 2025-11-05 15:53:42,617] Trial 18 finished with value: 4.4588313416462295 and parameters: {'iterations': 814, 'depth': 4, 'learning_rate': 0.16048743949472172, 'l2_leaf_reg': 8.900992391589346, 'border_count': 143, 'bagging_temperature': 0.6932522497086407, 'random_strength': 5.558227740409528}. Best is trial 6 with value: 4.431216371213205.\n",
      "[I 2025-11-05 15:53:43,381] Trial 19 finished with value: 4.551569731182691 and parameters: {'iterations': 821, 'depth': 9, 'learning_rate': 0.2347762378952929, 'l2_leaf_reg': 8.840843699266406, 'border_count': 100, 'bagging_temperature': 0.7129621761813298, 'random_strength': 5.684779394157366}. Best is trial 6 with value: 4.431216371213205.\n",
      "[I 2025-11-05 15:53:43,814] Trial 20 finished with value: 4.459500961578123 and parameters: {'iterations': 719, 'depth': 6, 'learning_rate': 0.16432576531990123, 'l2_leaf_reg': 9.617696110090344, 'border_count': 140, 'bagging_temperature': 0.84159847154184, 'random_strength': 7.8820235047329605}. Best is trial 6 with value: 4.431216371213205.\n",
      "[I 2025-11-05 15:53:44,152] Trial 21 finished with value: 4.467545620733278 and parameters: {'iterations': 687, 'depth': 6, 'learning_rate': 0.15993927973264932, 'l2_leaf_reg': 9.486474194122977, 'border_count': 138, 'bagging_temperature': 0.8294785875410439, 'random_strength': 7.928461052730044}. Best is trial 6 with value: 4.431216371213205.\n",
      "[I 2025-11-05 15:53:44,569] Trial 22 finished with value: 4.477640205040499 and parameters: {'iterations': 749, 'depth': 7, 'learning_rate': 0.18160562019117746, 'l2_leaf_reg': 7.388730801929917, 'border_count': 80, 'bagging_temperature': 0.9137910757842849, 'random_strength': 8.87369047548145}. Best is trial 6 with value: 4.431216371213205.\n",
      "[I 2025-11-05 15:53:44,880] Trial 23 finished with value: 4.5598847387860975 and parameters: {'iterations': 811, 'depth': 5, 'learning_rate': 0.22086776672952368, 'l2_leaf_reg': 10.27453463754389, 'border_count': 141, 'bagging_temperature': 0.7066936485455062, 'random_strength': 7.559803386744115}. Best is trial 6 with value: 4.431216371213205.\n",
      "[I 2025-11-05 15:53:45,304] Trial 24 finished with value: 4.51722137225854 and parameters: {'iterations': 768, 'depth': 6, 'learning_rate': 0.13149143661059917, 'l2_leaf_reg': 12.324498069366593, 'border_count': 158, 'bagging_temperature': 0.6149792171739311, 'random_strength': 5.205940391884783}. Best is trial 6 with value: 4.431216371213205.\n",
      "[I 2025-11-05 15:53:45,688] Trial 25 finished with value: 4.555115691374417 and parameters: {'iterations': 671, 'depth': 7, 'learning_rate': 0.17275487791620595, 'l2_leaf_reg': 7.748405398801433, 'border_count': 132, 'bagging_temperature': 0.7805441164460576, 'random_strength': 9.379123948037005}. Best is trial 6 with value: 4.431216371213205.\n",
      "[I 2025-11-05 15:53:46,034] Trial 26 finished with value: 4.429354041223227 and parameters: {'iterations': 863, 'depth': 4, 'learning_rate': 0.14716462084649826, 'l2_leaf_reg': 6.388303359202973, 'border_count': 85, 'bagging_temperature': 0.8963469784977413, 'random_strength': 8.335426234574886}. Best is trial 26 with value: 4.429354041223227.\n",
      "[I 2025-11-05 15:53:46,269] Trial 27 finished with value: 4.344367801090081 and parameters: {'iterations': 870, 'depth': 4, 'learning_rate': 0.25526711701829663, 'l2_leaf_reg': 6.5543226804293315, 'border_count': 36, 'bagging_temperature': 0.9000898198500402, 'random_strength': 6.903134508048282}. Best is trial 27 with value: 4.344367801090081.\n",
      "[I 2025-11-05 15:53:46,477] Trial 28 finished with value: 4.410742980493292 and parameters: {'iterations': 872, 'depth': 4, 'learning_rate': 0.2747070523440152, 'l2_leaf_reg': 6.09776115114676, 'border_count': 73, 'bagging_temperature': 0.9915506541616357, 'random_strength': 6.876980821881934}. Best is trial 27 with value: 4.344367801090081.\n",
      "[I 2025-11-05 15:53:46,652] Trial 29 finished with value: 4.429450510522519 and parameters: {'iterations': 923, 'depth': 4, 'learning_rate': 0.29712022544838973, 'l2_leaf_reg': 6.096646041703901, 'border_count': 39, 'bagging_temperature': 0.985576195143151, 'random_strength': 6.9886730763433516}. Best is trial 27 with value: 4.344367801090081.\n",
      "[I 2025-11-05 15:53:46,812] Trial 30 finished with value: 4.472021786285861 and parameters: {'iterations': 960, 'depth': 4, 'learning_rate': 0.2718813916131938, 'l2_leaf_reg': 6.675108096987913, 'border_count': 78, 'bagging_temperature': 0.9251674827375187, 'random_strength': 6.066465450342285}. Best is trial 27 with value: 4.344367801090081.\n",
      "[I 2025-11-05 15:53:47,087] Trial 31 finished with value: 4.4007422902874485 and parameters: {'iterations': 852, 'depth': 4, 'learning_rate': 0.29095991282713324, 'l2_leaf_reg': 5.385911422424959, 'border_count': 32, 'bagging_temperature': 0.9964873573598926, 'random_strength': 6.921790079991907}. Best is trial 27 with value: 4.344367801090081.\n",
      "[I 2025-11-05 15:53:47,338] Trial 32 finished with value: 4.440410962578785 and parameters: {'iterations': 851, 'depth': 5, 'learning_rate': 0.2577591426790584, 'l2_leaf_reg': 5.395195725770095, 'border_count': 32, 'bagging_temperature': 0.8955525754334847, 'random_strength': 6.617650841086532}. Best is trial 27 with value: 4.344367801090081.\n",
      "[I 2025-11-05 15:53:47,544] Trial 33 finished with value: 4.381989193060209 and parameters: {'iterations': 911, 'depth': 4, 'learning_rate': 0.2750632794060783, 'l2_leaf_reg': 4.216389704962168, 'border_count': 59, 'bagging_temperature': 0.9999728794589594, 'random_strength': 7.1717350273882055}. Best is trial 27 with value: 4.344367801090081.\n",
      "[I 2025-11-05 15:53:47,772] Trial 34 finished with value: 4.36551119919904 and parameters: {'iterations': 904, 'depth': 4, 'learning_rate': 0.2748392889386424, 'l2_leaf_reg': 4.625880262483804, 'border_count': 55, 'bagging_temperature': 0.98178023695223, 'random_strength': 7.266763237594454}. Best is trial 27 with value: 4.344367801090081.\n",
      "[I 2025-11-05 15:53:48,036] Trial 35 finished with value: 4.371785179415425 and parameters: {'iterations': 902, 'depth': 5, 'learning_rate': 0.2340385863744588, 'l2_leaf_reg': 4.57916899005294, 'border_count': 51, 'bagging_temperature': 0.9530296080873288, 'random_strength': 7.463069014877815}. Best is trial 27 with value: 4.344367801090081.\n",
      "[I 2025-11-05 15:53:48,305] Trial 36 finished with value: 4.287705161959511 and parameters: {'iterations': 905, 'depth': 5, 'learning_rate': 0.23486244517249405, 'l2_leaf_reg': 4.342072180612699, 'border_count': 60, 'bagging_temperature': 0.875725464762179, 'random_strength': 7.45320153234948}. Best is trial 36 with value: 4.287705161959511.\n",
      "[I 2025-11-05 15:53:48,483] Trial 37 finished with value: 4.508085695718722 and parameters: {'iterations': 960, 'depth': 5, 'learning_rate': 0.23153338434031676, 'l2_leaf_reg': 3.2264098095135365, 'border_count': 45, 'bagging_temperature': 0.8766995803356139, 'random_strength': 6.172518779217404}. Best is trial 36 with value: 4.287705161959511.\n",
      "[I 2025-11-05 15:53:48,814] Trial 38 finished with value: 4.398091718979259 and parameters: {'iterations': 973, 'depth': 5, 'learning_rate': 0.24739529927547385, 'l2_leaf_reg': 4.76016059517332, 'border_count': 51, 'bagging_temperature': 0.7858708815140512, 'random_strength': 7.458449258463713}. Best is trial 36 with value: 4.287705161959511.\n",
      "[I 2025-11-05 15:53:48,996] Trial 39 finished with value: 4.34102404637106 and parameters: {'iterations': 903, 'depth': 5, 'learning_rate': 0.2122040177191544, 'l2_leaf_reg': 2.9377222669861807, 'border_count': 65, 'bagging_temperature': 0.5936662296542505, 'random_strength': 4.481604801802069}. Best is trial 36 with value: 4.287705161959511.\n",
      "[I 2025-11-05 15:53:49,170] Trial 40 finished with value: 4.4193486507090975 and parameters: {'iterations': 787, 'depth': 5, 'learning_rate': 0.20609883707227147, 'l2_leaf_reg': 1.0981812792695602, 'border_count': 69, 'bagging_temperature': 0.6118560166063867, 'random_strength': 4.392987339103043}. Best is trial 36 with value: 4.287705161959511.\n",
      "[I 2025-11-05 15:53:49,400] Trial 41 finished with value: 4.504979899254056 and parameters: {'iterations': 898, 'depth': 5, 'learning_rate': 0.21944184244153814, 'l2_leaf_reg': 2.881923813257049, 'border_count': 95, 'bagging_temperature': 0.9505052364786432, 'random_strength': 2.7245192632064037}. Best is trial 36 with value: 4.287705161959511.\n",
      "[I 2025-11-05 15:53:49,586] Trial 42 finished with value: 4.421623612709709 and parameters: {'iterations': 941, 'depth': 5, 'learning_rate': 0.2387608871137643, 'l2_leaf_reg': 4.605672460621265, 'border_count': 65, 'bagging_temperature': 0.454061363649889, 'random_strength': 3.1308871989656955}. Best is trial 36 with value: 4.287705161959511.\n",
      "[I 2025-11-05 15:53:49,834] Trial 43 finished with value: 4.3736079284114755 and parameters: {'iterations': 902, 'depth': 4, 'learning_rate': 0.26593163103138745, 'l2_leaf_reg': 5.2748373303343, 'border_count': 49, 'bagging_temperature': 0.7853832008672501, 'random_strength': 4.604004636610092}. Best is trial 36 with value: 4.287705161959511.\n",
      "[I 2025-11-05 15:53:50,028] Trial 44 finished with value: 4.531649767414342 and parameters: {'iterations': 839, 'depth': 5, 'learning_rate': 0.21946928850687258, 'l2_leaf_reg': 3.548319015785295, 'border_count': 89, 'bagging_temperature': 0.8751996805708685, 'random_strength': 3.4489509784314083}. Best is trial 36 with value: 4.287705161959511.\n",
      "[I 2025-11-05 15:53:50,315] Trial 45 finished with value: 4.464892370516886 and parameters: {'iterations': 515, 'depth': 6, 'learning_rate': 0.19161242811086243, 'l2_leaf_reg': 2.552395923091709, 'border_count': 112, 'bagging_temperature': 0.313179504560905, 'random_strength': 6.381713971114852}. Best is trial 36 with value: 4.287705161959511.\n",
      "[I 2025-11-05 15:53:50,452] Trial 46 finished with value: 4.420986989711552 and parameters: {'iterations': 878, 'depth': 4, 'learning_rate': 0.2458230261470026, 'l2_leaf_reg': 4.4740811343349876, 'border_count': 43, 'bagging_temperature': 0.9516269379127834, 'random_strength': 2.4084073540642255}. Best is trial 36 with value: 4.287705161959511.\n",
      "[I 2025-11-05 15:53:50,687] Trial 47 finished with value: 4.450692783635502 and parameters: {'iterations': 991, 'depth': 5, 'learning_rate': 0.28252275776086266, 'l2_leaf_reg': 3.718413486195557, 'border_count': 60, 'bagging_temperature': 0.8694443486997321, 'random_strength': 8.364530471570793}. Best is trial 36 with value: 4.287705161959511.\n",
      "[I 2025-11-05 15:53:50,909] Trial 48 finished with value: 4.401026311851041 and parameters: {'iterations': 886, 'depth': 4, 'learning_rate': 0.20700285793575593, 'l2_leaf_reg': 5.269643791508164, 'border_count': 68, 'bagging_temperature': 0.6554409355930826, 'random_strength': 5.577168958292907}. Best is trial 36 with value: 4.287705161959511.\n",
      "[I 2025-11-05 15:53:51,150] Trial 49 finished with value: 4.442711146239879 and parameters: {'iterations': 948, 'depth': 5, 'learning_rate': 0.26207122579809006, 'l2_leaf_reg': 14.898935613846387, 'border_count': 38, 'bagging_temperature': 0.76977137825932, 'random_strength': 9.855572453893114}. Best is trial 36 with value: 4.287705161959511.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RMSE: 4.2877\n",
      "Best Parameters:\n",
      "  iterations: 905\n",
      "  depth: 5\n",
      "  learning_rate: 0.23486244517249405\n",
      "  l2_leaf_reg: 4.342072180612699\n",
      "  border_count: 60\n",
      "  bagging_temperature: 0.875725464762179\n",
      "  random_strength: 7.45320153234948\n",
      "MAE: 2.4449, R²: 0.5309\n"
     ]
    }
   ],
   "source": [
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "# Optuna objective 함수\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'iterations': trial.suggest_int('iterations', 500, 1000),\n",
    "        'depth': trial.suggest_int('depth', 4, 10),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "        'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1, 15),\n",
    "        'border_count': trial.suggest_int('border_count', 32, 255),\n",
    "        'bagging_temperature': trial.suggest_float('bagging_temperature', 0.0, 1.0),\n",
    "        'random_strength': trial.suggest_float('random_strength', 1e-9, 10),\n",
    "        'random_seed': 42,\n",
    "        'verbose': False,\n",
    "        'thread_count': -1\n",
    "    }\n",
    "\n",
    "    model = CatBoostRegressor(**params)\n",
    "    model.fit(X_train, y_train, eval_set=(X_val, y_val), early_stopping_rounds=50)\n",
    "    \n",
    "    y_pred = model.predict(X_val)\n",
    "    \n",
    "    # 여러 지표 계산\n",
    "    rmse_val = rmse(y_val, y_pred)\n",
    "    mae_val = mean_absolute_error(y_val, y_pred)\n",
    "    r2_val = r2_score(y_val, y_pred)\n",
    "\n",
    "    # 참고용 출력 (튜닝 과정에서 로그로 볼 수 있음)\n",
    "    trial.set_user_attr(\"MAE\", mae_val)\n",
    "    trial.set_user_attr(\"R2\", r2_val)\n",
    "\n",
    "    return rmse(y_val, y_pred)\n",
    "\n",
    "# Optuna 실행\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# 결과 출력\n",
    "best_trial = study.best_trial\n",
    "print(f\"Best RMSE: {best_trial.value:.4f}\")\n",
    "print(\"Best Parameters:\")\n",
    "for key, value in best_trial.params.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "print(f\"MAE: {best_trial.user_attrs['MAE']:.4f}, R²: {best_trial.user_attrs['R2']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f63a57",
   "metadata": {},
   "source": [
    "## 테스트해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f4352a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test= df_test_encoded[[\"FA4\", \"Pandemic_0\", \"Pandemic_1\", \"Pandemic_2\", \"Country_Other\",\"Country_US\", \"Country_JP\",\"Country_KR\", \n",
    "                         'Early_Explosion', 'Mid_Balanced','Later_Viral','opening_AudienceStd','wk1_Audience','wk2_Audience',\n",
    "                         'opening_Ho_Retention','wk1_Holiday_ShowMean','wk2_Holiday_ShowMean','wk1_Holiday_AudienceMean',\n",
    "                         'wk2_Holiday_AudienceMean']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b946dffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 4.5599000\ttotal: 1.19ms\tremaining: 1.07s\n",
      "1:\tlearn: 4.3966753\ttotal: 2.7ms\tremaining: 1.22s\n",
      "2:\tlearn: 4.1788613\ttotal: 3.49ms\tremaining: 1.05s\n",
      "3:\tlearn: 4.0051376\ttotal: 4.35ms\tremaining: 980ms\n",
      "4:\tlearn: 3.8590492\ttotal: 5.15ms\tremaining: 926ms\n",
      "5:\tlearn: 3.7938330\ttotal: 5.71ms\tremaining: 856ms\n",
      "6:\tlearn: 3.7562570\ttotal: 6.23ms\tremaining: 799ms\n",
      "7:\tlearn: 3.7410242\ttotal: 7.07ms\tremaining: 793ms\n",
      "8:\tlearn: 3.7114049\ttotal: 8.24ms\tremaining: 820ms\n",
      "9:\tlearn: 3.6817897\ttotal: 9.16ms\tremaining: 820ms\n",
      "10:\tlearn: 3.6607411\ttotal: 10.1ms\tremaining: 821ms\n",
      "11:\tlearn: 3.6270661\ttotal: 10.9ms\tremaining: 812ms\n",
      "12:\tlearn: 3.5969152\ttotal: 11.8ms\tremaining: 813ms\n",
      "13:\tlearn: 3.5615844\ttotal: 12.8ms\tremaining: 817ms\n",
      "14:\tlearn: 3.5300290\ttotal: 13.6ms\tremaining: 808ms\n",
      "15:\tlearn: 3.5191766\ttotal: 14.5ms\tremaining: 804ms\n",
      "16:\tlearn: 3.5138037\ttotal: 15ms\tremaining: 783ms\n",
      "17:\tlearn: 3.4945231\ttotal: 15.9ms\tremaining: 781ms\n",
      "18:\tlearn: 3.4662697\ttotal: 16.7ms\tremaining: 779ms\n",
      "19:\tlearn: 3.4599946\ttotal: 17.4ms\tremaining: 771ms\n",
      "20:\tlearn: 3.4345629\ttotal: 18.2ms\tremaining: 767ms\n",
      "21:\tlearn: 3.4238895\ttotal: 19ms\tremaining: 763ms\n",
      "22:\tlearn: 3.4058598\ttotal: 20ms\tremaining: 765ms\n",
      "23:\tlearn: 3.3996846\ttotal: 20.8ms\tremaining: 764ms\n",
      "24:\tlearn: 3.3840159\ttotal: 21.9ms\tremaining: 771ms\n",
      "25:\tlearn: 3.3763841\ttotal: 23.3ms\tremaining: 788ms\n",
      "26:\tlearn: 3.3664187\ttotal: 24.3ms\tremaining: 791ms\n",
      "27:\tlearn: 3.3589070\ttotal: 25.1ms\tremaining: 786ms\n",
      "28:\tlearn: 3.3555425\ttotal: 25.9ms\tremaining: 783ms\n",
      "29:\tlearn: 3.3521592\ttotal: 26.9ms\tremaining: 784ms\n",
      "30:\tlearn: 3.3480245\ttotal: 27.6ms\tremaining: 779ms\n",
      "31:\tlearn: 3.3340247\ttotal: 28.3ms\tremaining: 771ms\n",
      "32:\tlearn: 3.3213451\ttotal: 29.1ms\tremaining: 768ms\n",
      "33:\tlearn: 3.3118607\ttotal: 29.8ms\tremaining: 764ms\n",
      "34:\tlearn: 3.3066094\ttotal: 30.8ms\tremaining: 765ms\n",
      "35:\tlearn: 3.2862109\ttotal: 31.6ms\tremaining: 763ms\n",
      "36:\tlearn: 3.2787797\ttotal: 32.4ms\tremaining: 759ms\n",
      "37:\tlearn: 3.2720888\ttotal: 33.1ms\tremaining: 755ms\n",
      "38:\tlearn: 3.2591548\ttotal: 34ms\tremaining: 754ms\n",
      "39:\tlearn: 3.2447296\ttotal: 34.8ms\tremaining: 752ms\n",
      "40:\tlearn: 3.2357309\ttotal: 35.8ms\tremaining: 755ms\n",
      "41:\tlearn: 3.2217566\ttotal: 37ms\tremaining: 760ms\n",
      "42:\tlearn: 3.2083097\ttotal: 38.1ms\tremaining: 764ms\n",
      "43:\tlearn: 3.1955921\ttotal: 41ms\tremaining: 802ms\n",
      "44:\tlearn: 3.1729553\ttotal: 41.9ms\tremaining: 801ms\n",
      "45:\tlearn: 3.1575312\ttotal: 42.8ms\tremaining: 798ms\n",
      "46:\tlearn: 3.1403343\ttotal: 44.3ms\tremaining: 810ms\n",
      "47:\tlearn: 3.1279443\ttotal: 45.4ms\tremaining: 810ms\n",
      "48:\tlearn: 3.1087763\ttotal: 46.2ms\tremaining: 807ms\n",
      "49:\tlearn: 3.0956664\ttotal: 47.2ms\tremaining: 808ms\n",
      "50:\tlearn: 3.0840843\ttotal: 48.4ms\tremaining: 810ms\n",
      "51:\tlearn: 3.0735270\ttotal: 49.2ms\tremaining: 808ms\n",
      "52:\tlearn: 3.0581791\ttotal: 50.1ms\tremaining: 805ms\n",
      "53:\tlearn: 3.0501304\ttotal: 50.9ms\tremaining: 802ms\n",
      "54:\tlearn: 3.0380784\ttotal: 51.8ms\tremaining: 800ms\n",
      "55:\tlearn: 3.0277183\ttotal: 52.7ms\tremaining: 799ms\n",
      "56:\tlearn: 3.0143426\ttotal: 53.7ms\tremaining: 798ms\n",
      "57:\tlearn: 3.0024770\ttotal: 54.6ms\tremaining: 798ms\n",
      "58:\tlearn: 2.9891745\ttotal: 55.5ms\tremaining: 795ms\n",
      "59:\tlearn: 2.9747000\ttotal: 56.4ms\tremaining: 794ms\n",
      "60:\tlearn: 2.9544945\ttotal: 57.2ms\tremaining: 792ms\n",
      "61:\tlearn: 2.9384907\ttotal: 58.1ms\tremaining: 790ms\n",
      "62:\tlearn: 2.9210882\ttotal: 58.9ms\tremaining: 787ms\n",
      "63:\tlearn: 2.9134707\ttotal: 59.7ms\tremaining: 784ms\n",
      "64:\tlearn: 2.9025323\ttotal: 60.4ms\tremaining: 780ms\n",
      "65:\tlearn: 2.8927575\ttotal: 61.1ms\tremaining: 777ms\n",
      "66:\tlearn: 2.8835118\ttotal: 62ms\tremaining: 775ms\n",
      "67:\tlearn: 2.8752407\ttotal: 62.9ms\tremaining: 774ms\n",
      "68:\tlearn: 2.8670899\ttotal: 63.6ms\tremaining: 771ms\n",
      "69:\tlearn: 2.8485354\ttotal: 64.5ms\tremaining: 769ms\n",
      "70:\tlearn: 2.8360336\ttotal: 65.3ms\tremaining: 767ms\n",
      "71:\tlearn: 2.8277890\ttotal: 66.1ms\tremaining: 765ms\n",
      "72:\tlearn: 2.8204708\ttotal: 67.1ms\tremaining: 765ms\n",
      "73:\tlearn: 2.8040322\ttotal: 68.1ms\tremaining: 765ms\n",
      "74:\tlearn: 2.7997811\ttotal: 69ms\tremaining: 764ms\n",
      "75:\tlearn: 2.7910468\ttotal: 69.8ms\tremaining: 761ms\n",
      "76:\tlearn: 2.7819973\ttotal: 70.7ms\tremaining: 760ms\n",
      "77:\tlearn: 2.7739579\ttotal: 71.5ms\tremaining: 758ms\n",
      "78:\tlearn: 2.7661029\ttotal: 72.2ms\tremaining: 755ms\n",
      "79:\tlearn: 2.7588998\ttotal: 73ms\tremaining: 753ms\n",
      "80:\tlearn: 2.7485060\ttotal: 73.9ms\tremaining: 752ms\n",
      "81:\tlearn: 2.7419920\ttotal: 74.7ms\tremaining: 749ms\n",
      "82:\tlearn: 2.7389911\ttotal: 75.6ms\tremaining: 748ms\n",
      "83:\tlearn: 2.7258653\ttotal: 76.5ms\tremaining: 748ms\n",
      "84:\tlearn: 2.7186645\ttotal: 77.3ms\tremaining: 745ms\n",
      "85:\tlearn: 2.7137325\ttotal: 77.9ms\tremaining: 742ms\n",
      "86:\tlearn: 2.7041652\ttotal: 78.7ms\tremaining: 740ms\n",
      "87:\tlearn: 2.6949547\ttotal: 79.5ms\tremaining: 738ms\n",
      "88:\tlearn: 2.6871741\ttotal: 80.2ms\tremaining: 735ms\n",
      "89:\tlearn: 2.6794231\ttotal: 81ms\tremaining: 734ms\n",
      "90:\tlearn: 2.6746580\ttotal: 82ms\tremaining: 733ms\n",
      "91:\tlearn: 2.6647230\ttotal: 82.9ms\tremaining: 732ms\n",
      "92:\tlearn: 2.6591114\ttotal: 83.9ms\tremaining: 732ms\n",
      "93:\tlearn: 2.6487718\ttotal: 84.8ms\tremaining: 731ms\n",
      "94:\tlearn: 2.6400003\ttotal: 85.8ms\tremaining: 732ms\n",
      "95:\tlearn: 2.6385045\ttotal: 86.7ms\tremaining: 731ms\n",
      "96:\tlearn: 2.6352545\ttotal: 87.6ms\tremaining: 730ms\n",
      "97:\tlearn: 2.6287367\ttotal: 88.5ms\tremaining: 729ms\n",
      "98:\tlearn: 2.6168103\ttotal: 89.2ms\tremaining: 726ms\n",
      "99:\tlearn: 2.6144423\ttotal: 89.9ms\tremaining: 724ms\n",
      "100:\tlearn: 2.6057929\ttotal: 90.7ms\tremaining: 722ms\n",
      "101:\tlearn: 2.6033964\ttotal: 91.4ms\tremaining: 720ms\n",
      "102:\tlearn: 2.5927478\ttotal: 92.3ms\tremaining: 718ms\n",
      "103:\tlearn: 2.5868978\ttotal: 93.1ms\tremaining: 717ms\n",
      "104:\tlearn: 2.5816916\ttotal: 94ms\tremaining: 716ms\n",
      "105:\tlearn: 2.5713290\ttotal: 94.7ms\tremaining: 714ms\n",
      "106:\tlearn: 2.5635384\ttotal: 95.5ms\tremaining: 713ms\n",
      "107:\tlearn: 2.5578316\ttotal: 96.3ms\tremaining: 710ms\n",
      "108:\tlearn: 2.5513955\ttotal: 97.1ms\tremaining: 709ms\n",
      "109:\tlearn: 2.5457382\ttotal: 97.9ms\tremaining: 707ms\n",
      "110:\tlearn: 2.5375411\ttotal: 98.8ms\tremaining: 707ms\n",
      "111:\tlearn: 2.5314829\ttotal: 99.6ms\tremaining: 705ms\n",
      "112:\tlearn: 2.5240522\ttotal: 101ms\tremaining: 705ms\n",
      "113:\tlearn: 2.5194067\ttotal: 101ms\tremaining: 704ms\n",
      "114:\tlearn: 2.5139613\ttotal: 102ms\tremaining: 703ms\n",
      "115:\tlearn: 2.5091269\ttotal: 103ms\tremaining: 703ms\n",
      "116:\tlearn: 2.4999989\ttotal: 104ms\tremaining: 701ms\n",
      "117:\tlearn: 2.4928053\ttotal: 105ms\tremaining: 699ms\n",
      "118:\tlearn: 2.4831132\ttotal: 106ms\tremaining: 697ms\n",
      "119:\tlearn: 2.4817653\ttotal: 106ms\tremaining: 695ms\n",
      "120:\tlearn: 2.4758014\ttotal: 107ms\tremaining: 693ms\n",
      "121:\tlearn: 2.4696021\ttotal: 108ms\tremaining: 692ms\n",
      "122:\tlearn: 2.4673521\ttotal: 109ms\tremaining: 691ms\n",
      "123:\tlearn: 2.4644063\ttotal: 110ms\tremaining: 690ms\n",
      "124:\tlearn: 2.4590677\ttotal: 110ms\tremaining: 688ms\n",
      "125:\tlearn: 2.4561496\ttotal: 111ms\tremaining: 687ms\n",
      "126:\tlearn: 2.4486434\ttotal: 112ms\tremaining: 686ms\n",
      "127:\tlearn: 2.4423696\ttotal: 113ms\tremaining: 684ms\n",
      "128:\tlearn: 2.4348911\ttotal: 114ms\tremaining: 683ms\n",
      "129:\tlearn: 2.4262682\ttotal: 114ms\tremaining: 682ms\n",
      "130:\tlearn: 2.4220079\ttotal: 115ms\tremaining: 681ms\n",
      "131:\tlearn: 2.4158411\ttotal: 116ms\tremaining: 681ms\n",
      "132:\tlearn: 2.4114450\ttotal: 117ms\tremaining: 680ms\n",
      "133:\tlearn: 2.4034028\ttotal: 118ms\tremaining: 680ms\n",
      "134:\tlearn: 2.3986185\ttotal: 119ms\tremaining: 679ms\n",
      "135:\tlearn: 2.3943661\ttotal: 120ms\tremaining: 677ms\n",
      "136:\tlearn: 2.3864006\ttotal: 121ms\tremaining: 677ms\n",
      "137:\tlearn: 2.3818656\ttotal: 122ms\tremaining: 676ms\n",
      "138:\tlearn: 2.3772258\ttotal: 122ms\tremaining: 675ms\n",
      "139:\tlearn: 2.3698476\ttotal: 123ms\tremaining: 674ms\n",
      "140:\tlearn: 2.3642414\ttotal: 124ms\tremaining: 672ms\n",
      "141:\tlearn: 2.3563154\ttotal: 125ms\tremaining: 670ms\n",
      "142:\tlearn: 2.3529629\ttotal: 126ms\tremaining: 669ms\n",
      "143:\tlearn: 2.3495804\ttotal: 126ms\tremaining: 668ms\n",
      "144:\tlearn: 2.3464898\ttotal: 127ms\tremaining: 667ms\n",
      "145:\tlearn: 2.3357273\ttotal: 128ms\tremaining: 666ms\n",
      "146:\tlearn: 2.3304442\ttotal: 129ms\tremaining: 665ms\n",
      "147:\tlearn: 2.3219378\ttotal: 130ms\tremaining: 664ms\n",
      "148:\tlearn: 2.3203929\ttotal: 131ms\tremaining: 663ms\n",
      "149:\tlearn: 2.3132455\ttotal: 131ms\tremaining: 662ms\n",
      "150:\tlearn: 2.3073049\ttotal: 132ms\tremaining: 660ms\n",
      "151:\tlearn: 2.3049449\ttotal: 133ms\tremaining: 659ms\n",
      "152:\tlearn: 2.2972346\ttotal: 134ms\tremaining: 658ms\n",
      "153:\tlearn: 2.2923584\ttotal: 135ms\tremaining: 656ms\n",
      "154:\tlearn: 2.2867430\ttotal: 135ms\tremaining: 654ms\n",
      "155:\tlearn: 2.2815027\ttotal: 136ms\tremaining: 653ms\n",
      "156:\tlearn: 2.2762889\ttotal: 137ms\tremaining: 652ms\n",
      "157:\tlearn: 2.2722938\ttotal: 137ms\tremaining: 650ms\n",
      "158:\tlearn: 2.2670846\ttotal: 138ms\tremaining: 649ms\n",
      "159:\tlearn: 2.2594840\ttotal: 139ms\tremaining: 648ms\n",
      "160:\tlearn: 2.2520531\ttotal: 140ms\tremaining: 647ms\n",
      "161:\tlearn: 2.2427775\ttotal: 141ms\tremaining: 646ms\n",
      "162:\tlearn: 2.2370356\ttotal: 142ms\tremaining: 645ms\n",
      "163:\tlearn: 2.2336525\ttotal: 142ms\tremaining: 644ms\n",
      "164:\tlearn: 2.2282198\ttotal: 143ms\tremaining: 642ms\n",
      "165:\tlearn: 2.2236122\ttotal: 144ms\tremaining: 641ms\n",
      "166:\tlearn: 2.2198949\ttotal: 145ms\tremaining: 639ms\n",
      "167:\tlearn: 2.2166910\ttotal: 145ms\tremaining: 638ms\n",
      "168:\tlearn: 2.2090799\ttotal: 146ms\tremaining: 637ms\n",
      "169:\tlearn: 2.2023945\ttotal: 147ms\tremaining: 635ms\n",
      "170:\tlearn: 2.1981917\ttotal: 148ms\tremaining: 634ms\n",
      "171:\tlearn: 2.1922562\ttotal: 148ms\tremaining: 633ms\n",
      "172:\tlearn: 2.1860728\ttotal: 149ms\tremaining: 632ms\n",
      "173:\tlearn: 2.1828223\ttotal: 150ms\tremaining: 630ms\n",
      "174:\tlearn: 2.1763639\ttotal: 151ms\tremaining: 629ms\n",
      "175:\tlearn: 2.1702284\ttotal: 151ms\tremaining: 627ms\n",
      "176:\tlearn: 2.1664180\ttotal: 152ms\tremaining: 626ms\n",
      "177:\tlearn: 2.1617261\ttotal: 153ms\tremaining: 625ms\n",
      "178:\tlearn: 2.1572219\ttotal: 154ms\tremaining: 624ms\n",
      "179:\tlearn: 2.1510694\ttotal: 155ms\tremaining: 622ms\n",
      "180:\tlearn: 2.1464636\ttotal: 155ms\tremaining: 621ms\n",
      "181:\tlearn: 2.1423109\ttotal: 156ms\tremaining: 620ms\n",
      "182:\tlearn: 2.1405522\ttotal: 157ms\tremaining: 619ms\n",
      "183:\tlearn: 2.1374461\ttotal: 158ms\tremaining: 618ms\n",
      "184:\tlearn: 2.1270996\ttotal: 159ms\tremaining: 618ms\n",
      "185:\tlearn: 2.1257284\ttotal: 160ms\tremaining: 617ms\n",
      "186:\tlearn: 2.1214916\ttotal: 160ms\tremaining: 616ms\n",
      "187:\tlearn: 2.1147891\ttotal: 161ms\tremaining: 615ms\n",
      "188:\tlearn: 2.1091777\ttotal: 162ms\tremaining: 614ms\n",
      "189:\tlearn: 2.1061470\ttotal: 163ms\tremaining: 612ms\n",
      "190:\tlearn: 2.0992424\ttotal: 164ms\tremaining: 612ms\n",
      "191:\tlearn: 2.0961869\ttotal: 164ms\tremaining: 610ms\n",
      "192:\tlearn: 2.0929322\ttotal: 165ms\tremaining: 609ms\n",
      "193:\tlearn: 2.0884890\ttotal: 166ms\tremaining: 608ms\n",
      "194:\tlearn: 2.0856126\ttotal: 167ms\tremaining: 607ms\n",
      "195:\tlearn: 2.0799661\ttotal: 167ms\tremaining: 606ms\n",
      "196:\tlearn: 2.0760174\ttotal: 168ms\tremaining: 605ms\n",
      "197:\tlearn: 2.0730073\ttotal: 169ms\tremaining: 603ms\n",
      "198:\tlearn: 2.0696840\ttotal: 170ms\tremaining: 602ms\n",
      "199:\tlearn: 2.0635677\ttotal: 171ms\tremaining: 601ms\n",
      "200:\tlearn: 2.0608656\ttotal: 171ms\tremaining: 600ms\n",
      "201:\tlearn: 2.0549745\ttotal: 172ms\tremaining: 600ms\n",
      "202:\tlearn: 2.0511789\ttotal: 173ms\tremaining: 600ms\n",
      "203:\tlearn: 2.0478091\ttotal: 174ms\tremaining: 599ms\n",
      "204:\tlearn: 2.0464177\ttotal: 175ms\tremaining: 598ms\n",
      "205:\tlearn: 2.0412601\ttotal: 176ms\tremaining: 597ms\n",
      "206:\tlearn: 2.0399923\ttotal: 177ms\tremaining: 596ms\n",
      "207:\tlearn: 2.0346695\ttotal: 178ms\tremaining: 595ms\n",
      "208:\tlearn: 2.0319534\ttotal: 178ms\tremaining: 594ms\n",
      "209:\tlearn: 2.0275817\ttotal: 179ms\tremaining: 593ms\n",
      "210:\tlearn: 2.0231703\ttotal: 180ms\tremaining: 592ms\n",
      "211:\tlearn: 2.0196338\ttotal: 181ms\tremaining: 591ms\n",
      "212:\tlearn: 2.0165048\ttotal: 182ms\tremaining: 590ms\n",
      "213:\tlearn: 2.0128008\ttotal: 182ms\tremaining: 589ms\n",
      "214:\tlearn: 2.0073675\ttotal: 183ms\tremaining: 588ms\n",
      "215:\tlearn: 2.0045034\ttotal: 184ms\tremaining: 587ms\n",
      "216:\tlearn: 1.9994213\ttotal: 186ms\tremaining: 589ms\n",
      "217:\tlearn: 1.9952610\ttotal: 187ms\tremaining: 589ms\n",
      "218:\tlearn: 1.9924413\ttotal: 188ms\tremaining: 589ms\n",
      "219:\tlearn: 1.9911879\ttotal: 189ms\tremaining: 588ms\n",
      "220:\tlearn: 1.9857329\ttotal: 190ms\tremaining: 588ms\n",
      "221:\tlearn: 1.9799323\ttotal: 191ms\tremaining: 587ms\n",
      "222:\tlearn: 1.9760729\ttotal: 192ms\tremaining: 586ms\n",
      "223:\tlearn: 1.9752592\ttotal: 192ms\tremaining: 585ms\n",
      "224:\tlearn: 1.9705605\ttotal: 193ms\tremaining: 584ms\n",
      "225:\tlearn: 1.9668098\ttotal: 194ms\tremaining: 583ms\n",
      "226:\tlearn: 1.9622707\ttotal: 195ms\tremaining: 582ms\n",
      "227:\tlearn: 1.9591874\ttotal: 196ms\tremaining: 581ms\n",
      "228:\tlearn: 1.9522113\ttotal: 196ms\tremaining: 580ms\n",
      "229:\tlearn: 1.9497556\ttotal: 197ms\tremaining: 579ms\n",
      "230:\tlearn: 1.9477392\ttotal: 198ms\tremaining: 578ms\n",
      "231:\tlearn: 1.9432310\ttotal: 199ms\tremaining: 577ms\n",
      "232:\tlearn: 1.9422022\ttotal: 200ms\tremaining: 576ms\n",
      "233:\tlearn: 1.9396839\ttotal: 201ms\tremaining: 575ms\n",
      "234:\tlearn: 1.9369522\ttotal: 202ms\tremaining: 575ms\n",
      "235:\tlearn: 1.9321171\ttotal: 203ms\tremaining: 575ms\n",
      "236:\tlearn: 1.9262772\ttotal: 204ms\tremaining: 574ms\n",
      "237:\tlearn: 1.9224142\ttotal: 205ms\tremaining: 573ms\n",
      "238:\tlearn: 1.9193599\ttotal: 205ms\tremaining: 572ms\n",
      "239:\tlearn: 1.9114460\ttotal: 206ms\tremaining: 572ms\n",
      "240:\tlearn: 1.9090547\ttotal: 207ms\tremaining: 571ms\n",
      "241:\tlearn: 1.9051732\ttotal: 208ms\tremaining: 571ms\n",
      "242:\tlearn: 1.9018729\ttotal: 209ms\tremaining: 571ms\n",
      "243:\tlearn: 1.8987702\ttotal: 211ms\tremaining: 570ms\n",
      "244:\tlearn: 1.8977683\ttotal: 211ms\tremaining: 570ms\n",
      "245:\tlearn: 1.8930313\ttotal: 212ms\tremaining: 569ms\n",
      "246:\tlearn: 1.8912752\ttotal: 213ms\tremaining: 568ms\n",
      "247:\tlearn: 1.8865703\ttotal: 214ms\tremaining: 567ms\n",
      "248:\tlearn: 1.8821577\ttotal: 215ms\tremaining: 566ms\n",
      "249:\tlearn: 1.8800597\ttotal: 216ms\tremaining: 565ms\n",
      "250:\tlearn: 1.8766443\ttotal: 216ms\tremaining: 564ms\n",
      "251:\tlearn: 1.8736888\ttotal: 217ms\tremaining: 563ms\n",
      "252:\tlearn: 1.8681076\ttotal: 218ms\tremaining: 562ms\n",
      "253:\tlearn: 1.8644078\ttotal: 219ms\tremaining: 562ms\n",
      "254:\tlearn: 1.8604083\ttotal: 220ms\tremaining: 562ms\n",
      "255:\tlearn: 1.8577127\ttotal: 221ms\tremaining: 561ms\n",
      "256:\tlearn: 1.8527322\ttotal: 222ms\tremaining: 560ms\n",
      "257:\tlearn: 1.8497290\ttotal: 223ms\tremaining: 559ms\n",
      "258:\tlearn: 1.8442449\ttotal: 224ms\tremaining: 558ms\n",
      "259:\tlearn: 1.8391886\ttotal: 225ms\tremaining: 557ms\n",
      "260:\tlearn: 1.8364523\ttotal: 225ms\tremaining: 556ms\n",
      "261:\tlearn: 1.8336218\ttotal: 226ms\tremaining: 555ms\n",
      "262:\tlearn: 1.8310213\ttotal: 227ms\tremaining: 554ms\n",
      "263:\tlearn: 1.8283927\ttotal: 228ms\tremaining: 554ms\n",
      "264:\tlearn: 1.8236091\ttotal: 229ms\tremaining: 553ms\n",
      "265:\tlearn: 1.8193539\ttotal: 230ms\tremaining: 551ms\n",
      "266:\tlearn: 1.8176307\ttotal: 230ms\tremaining: 550ms\n",
      "267:\tlearn: 1.8148776\ttotal: 231ms\tremaining: 549ms\n",
      "268:\tlearn: 1.8126365\ttotal: 232ms\tremaining: 549ms\n",
      "269:\tlearn: 1.8117436\ttotal: 233ms\tremaining: 548ms\n",
      "270:\tlearn: 1.8094275\ttotal: 234ms\tremaining: 547ms\n",
      "271:\tlearn: 1.8062785\ttotal: 235ms\tremaining: 546ms\n",
      "272:\tlearn: 1.8027863\ttotal: 236ms\tremaining: 546ms\n",
      "273:\tlearn: 1.8008497\ttotal: 237ms\tremaining: 545ms\n",
      "274:\tlearn: 1.7987893\ttotal: 238ms\tremaining: 544ms\n",
      "275:\tlearn: 1.7962751\ttotal: 238ms\tremaining: 543ms\n",
      "276:\tlearn: 1.7914307\ttotal: 239ms\tremaining: 542ms\n",
      "277:\tlearn: 1.7882196\ttotal: 240ms\tremaining: 541ms\n",
      "278:\tlearn: 1.7848444\ttotal: 241ms\tremaining: 540ms\n",
      "279:\tlearn: 1.7835256\ttotal: 242ms\tremaining: 539ms\n",
      "280:\tlearn: 1.7808173\ttotal: 242ms\tremaining: 538ms\n",
      "281:\tlearn: 1.7772532\ttotal: 243ms\tremaining: 537ms\n",
      "282:\tlearn: 1.7718164\ttotal: 244ms\tremaining: 536ms\n",
      "283:\tlearn: 1.7702797\ttotal: 245ms\tremaining: 535ms\n",
      "284:\tlearn: 1.7664613\ttotal: 246ms\tremaining: 534ms\n",
      "285:\tlearn: 1.7636462\ttotal: 247ms\tremaining: 534ms\n",
      "286:\tlearn: 1.7598950\ttotal: 247ms\tremaining: 533ms\n",
      "287:\tlearn: 1.7539351\ttotal: 248ms\tremaining: 532ms\n",
      "288:\tlearn: 1.7516140\ttotal: 249ms\tremaining: 531ms\n",
      "289:\tlearn: 1.7474522\ttotal: 250ms\tremaining: 530ms\n",
      "290:\tlearn: 1.7447071\ttotal: 251ms\tremaining: 529ms\n",
      "291:\tlearn: 1.7421689\ttotal: 252ms\tremaining: 528ms\n",
      "292:\tlearn: 1.7378876\ttotal: 252ms\tremaining: 527ms\n",
      "293:\tlearn: 1.7341437\ttotal: 253ms\tremaining: 526ms\n",
      "294:\tlearn: 1.7301614\ttotal: 254ms\tremaining: 525ms\n",
      "295:\tlearn: 1.7283698\ttotal: 255ms\tremaining: 524ms\n",
      "296:\tlearn: 1.7243930\ttotal: 256ms\tremaining: 523ms\n",
      "297:\tlearn: 1.7219729\ttotal: 256ms\tremaining: 522ms\n",
      "298:\tlearn: 1.7199878\ttotal: 257ms\tremaining: 521ms\n",
      "299:\tlearn: 1.7155660\ttotal: 258ms\tremaining: 520ms\n",
      "300:\tlearn: 1.7134885\ttotal: 259ms\tremaining: 519ms\n",
      "301:\tlearn: 1.7107392\ttotal: 260ms\tremaining: 518ms\n",
      "302:\tlearn: 1.7073325\ttotal: 260ms\tremaining: 517ms\n",
      "303:\tlearn: 1.7056392\ttotal: 261ms\tremaining: 516ms\n",
      "304:\tlearn: 1.7019668\ttotal: 262ms\tremaining: 515ms\n",
      "305:\tlearn: 1.6999005\ttotal: 263ms\tremaining: 514ms\n",
      "306:\tlearn: 1.6973924\ttotal: 264ms\tremaining: 513ms\n",
      "307:\tlearn: 1.6950247\ttotal: 265ms\tremaining: 513ms\n",
      "308:\tlearn: 1.6940814\ttotal: 265ms\tremaining: 512ms\n",
      "309:\tlearn: 1.6901718\ttotal: 266ms\tremaining: 511ms\n",
      "310:\tlearn: 1.6849961\ttotal: 267ms\tremaining: 510ms\n",
      "311:\tlearn: 1.6828857\ttotal: 268ms\tremaining: 509ms\n",
      "312:\tlearn: 1.6808234\ttotal: 269ms\tremaining: 508ms\n",
      "313:\tlearn: 1.6784022\ttotal: 269ms\tremaining: 507ms\n",
      "314:\tlearn: 1.6745122\ttotal: 270ms\tremaining: 506ms\n",
      "315:\tlearn: 1.6700440\ttotal: 271ms\tremaining: 505ms\n",
      "316:\tlearn: 1.6679520\ttotal: 272ms\tremaining: 504ms\n",
      "317:\tlearn: 1.6652830\ttotal: 273ms\tremaining: 503ms\n",
      "318:\tlearn: 1.6640850\ttotal: 274ms\tremaining: 502ms\n",
      "319:\tlearn: 1.6615493\ttotal: 274ms\tremaining: 501ms\n",
      "320:\tlearn: 1.6563583\ttotal: 275ms\tremaining: 500ms\n",
      "321:\tlearn: 1.6533398\ttotal: 276ms\tremaining: 499ms\n",
      "322:\tlearn: 1.6498785\ttotal: 277ms\tremaining: 499ms\n",
      "323:\tlearn: 1.6467935\ttotal: 278ms\tremaining: 498ms\n",
      "324:\tlearn: 1.6462147\ttotal: 278ms\tremaining: 497ms\n",
      "325:\tlearn: 1.6421095\ttotal: 279ms\tremaining: 496ms\n",
      "326:\tlearn: 1.6388601\ttotal: 280ms\tremaining: 495ms\n",
      "327:\tlearn: 1.6355603\ttotal: 281ms\tremaining: 494ms\n",
      "328:\tlearn: 1.6315840\ttotal: 282ms\tremaining: 493ms\n",
      "329:\tlearn: 1.6285971\ttotal: 283ms\tremaining: 492ms\n",
      "330:\tlearn: 1.6243588\ttotal: 283ms\tremaining: 492ms\n",
      "331:\tlearn: 1.6188158\ttotal: 284ms\tremaining: 491ms\n",
      "332:\tlearn: 1.6143891\ttotal: 285ms\tremaining: 489ms\n",
      "333:\tlearn: 1.6124986\ttotal: 286ms\tremaining: 488ms\n",
      "334:\tlearn: 1.6099791\ttotal: 287ms\tremaining: 487ms\n",
      "335:\tlearn: 1.6073247\ttotal: 287ms\tremaining: 487ms\n",
      "336:\tlearn: 1.6049262\ttotal: 288ms\tremaining: 485ms\n",
      "337:\tlearn: 1.5993688\ttotal: 289ms\tremaining: 485ms\n",
      "338:\tlearn: 1.5984612\ttotal: 290ms\tremaining: 484ms\n",
      "339:\tlearn: 1.5955517\ttotal: 291ms\tremaining: 483ms\n",
      "340:\tlearn: 1.5919911\ttotal: 291ms\tremaining: 482ms\n",
      "341:\tlearn: 1.5903843\ttotal: 292ms\tremaining: 481ms\n",
      "342:\tlearn: 1.5885742\ttotal: 293ms\tremaining: 480ms\n",
      "343:\tlearn: 1.5846755\ttotal: 294ms\tremaining: 479ms\n",
      "344:\tlearn: 1.5829309\ttotal: 295ms\tremaining: 479ms\n",
      "345:\tlearn: 1.5821214\ttotal: 296ms\tremaining: 478ms\n",
      "346:\tlearn: 1.5798076\ttotal: 297ms\tremaining: 477ms\n",
      "347:\tlearn: 1.5779174\ttotal: 297ms\tremaining: 476ms\n",
      "348:\tlearn: 1.5739182\ttotal: 298ms\tremaining: 475ms\n",
      "349:\tlearn: 1.5711172\ttotal: 299ms\tremaining: 474ms\n",
      "350:\tlearn: 1.5665473\ttotal: 300ms\tremaining: 473ms\n",
      "351:\tlearn: 1.5652574\ttotal: 300ms\tremaining: 472ms\n",
      "352:\tlearn: 1.5623996\ttotal: 301ms\tremaining: 471ms\n",
      "353:\tlearn: 1.5604559\ttotal: 302ms\tremaining: 471ms\n",
      "354:\tlearn: 1.5577646\ttotal: 303ms\tremaining: 470ms\n",
      "355:\tlearn: 1.5556694\ttotal: 304ms\tremaining: 469ms\n",
      "356:\tlearn: 1.5528390\ttotal: 305ms\tremaining: 468ms\n",
      "357:\tlearn: 1.5506627\ttotal: 306ms\tremaining: 467ms\n",
      "358:\tlearn: 1.5476625\ttotal: 307ms\tremaining: 467ms\n",
      "359:\tlearn: 1.5430292\ttotal: 308ms\tremaining: 466ms\n",
      "360:\tlearn: 1.5405938\ttotal: 309ms\tremaining: 465ms\n",
      "361:\tlearn: 1.5384461\ttotal: 310ms\tremaining: 464ms\n",
      "362:\tlearn: 1.5366871\ttotal: 310ms\tremaining: 463ms\n",
      "363:\tlearn: 1.5334052\ttotal: 311ms\tremaining: 463ms\n",
      "364:\tlearn: 1.5294527\ttotal: 312ms\tremaining: 461ms\n",
      "365:\tlearn: 1.5270031\ttotal: 313ms\tremaining: 460ms\n",
      "366:\tlearn: 1.5236979\ttotal: 313ms\tremaining: 460ms\n",
      "367:\tlearn: 1.5227969\ttotal: 314ms\tremaining: 459ms\n",
      "368:\tlearn: 1.5210770\ttotal: 315ms\tremaining: 458ms\n",
      "369:\tlearn: 1.5184427\ttotal: 316ms\tremaining: 457ms\n",
      "370:\tlearn: 1.5166812\ttotal: 317ms\tremaining: 456ms\n",
      "371:\tlearn: 1.5147692\ttotal: 317ms\tremaining: 455ms\n",
      "372:\tlearn: 1.5130855\ttotal: 318ms\tremaining: 454ms\n",
      "373:\tlearn: 1.5090069\ttotal: 319ms\tremaining: 453ms\n",
      "374:\tlearn: 1.5055295\ttotal: 320ms\tremaining: 452ms\n",
      "375:\tlearn: 1.5026217\ttotal: 320ms\tremaining: 451ms\n",
      "376:\tlearn: 1.4999368\ttotal: 321ms\tremaining: 450ms\n",
      "377:\tlearn: 1.4981667\ttotal: 322ms\tremaining: 449ms\n",
      "378:\tlearn: 1.4949635\ttotal: 323ms\tremaining: 448ms\n",
      "379:\tlearn: 1.4931549\ttotal: 324ms\tremaining: 447ms\n",
      "380:\tlearn: 1.4912038\ttotal: 325ms\tremaining: 447ms\n",
      "381:\tlearn: 1.4892317\ttotal: 326ms\tremaining: 446ms\n",
      "382:\tlearn: 1.4873533\ttotal: 326ms\tremaining: 445ms\n",
      "383:\tlearn: 1.4860015\ttotal: 327ms\tremaining: 444ms\n",
      "384:\tlearn: 1.4832220\ttotal: 328ms\tremaining: 443ms\n",
      "385:\tlearn: 1.4805867\ttotal: 329ms\tremaining: 442ms\n",
      "386:\tlearn: 1.4777096\ttotal: 329ms\tremaining: 441ms\n",
      "387:\tlearn: 1.4762587\ttotal: 330ms\tremaining: 440ms\n",
      "388:\tlearn: 1.4743026\ttotal: 331ms\tremaining: 439ms\n",
      "389:\tlearn: 1.4715405\ttotal: 332ms\tremaining: 438ms\n",
      "390:\tlearn: 1.4708343\ttotal: 333ms\tremaining: 437ms\n",
      "391:\tlearn: 1.4697699\ttotal: 333ms\tremaining: 436ms\n",
      "392:\tlearn: 1.4630410\ttotal: 334ms\tremaining: 435ms\n",
      "393:\tlearn: 1.4613055\ttotal: 335ms\tremaining: 434ms\n",
      "394:\tlearn: 1.4563021\ttotal: 336ms\tremaining: 433ms\n",
      "395:\tlearn: 1.4548136\ttotal: 337ms\tremaining: 433ms\n",
      "396:\tlearn: 1.4514736\ttotal: 337ms\tremaining: 432ms\n",
      "397:\tlearn: 1.4503563\ttotal: 338ms\tremaining: 431ms\n",
      "398:\tlearn: 1.4496410\ttotal: 339ms\tremaining: 430ms\n",
      "399:\tlearn: 1.4461854\ttotal: 340ms\tremaining: 429ms\n",
      "400:\tlearn: 1.4445344\ttotal: 341ms\tremaining: 428ms\n",
      "401:\tlearn: 1.4434382\ttotal: 342ms\tremaining: 427ms\n",
      "402:\tlearn: 1.4402603\ttotal: 342ms\tremaining: 427ms\n",
      "403:\tlearn: 1.4380349\ttotal: 343ms\tremaining: 426ms\n",
      "404:\tlearn: 1.4336015\ttotal: 344ms\tremaining: 425ms\n",
      "405:\tlearn: 1.4327461\ttotal: 345ms\tremaining: 424ms\n",
      "406:\tlearn: 1.4292802\ttotal: 346ms\tremaining: 423ms\n",
      "407:\tlearn: 1.4270197\ttotal: 346ms\tremaining: 422ms\n",
      "408:\tlearn: 1.4253710\ttotal: 347ms\tremaining: 421ms\n",
      "409:\tlearn: 1.4240173\ttotal: 348ms\tremaining: 420ms\n",
      "410:\tlearn: 1.4198920\ttotal: 349ms\tremaining: 419ms\n",
      "411:\tlearn: 1.4174502\ttotal: 349ms\tremaining: 418ms\n",
      "412:\tlearn: 1.4140966\ttotal: 350ms\tremaining: 417ms\n",
      "413:\tlearn: 1.4118293\ttotal: 351ms\tremaining: 416ms\n",
      "414:\tlearn: 1.4097666\ttotal: 352ms\tremaining: 415ms\n",
      "415:\tlearn: 1.4077542\ttotal: 352ms\tremaining: 414ms\n",
      "416:\tlearn: 1.4050275\ttotal: 353ms\tremaining: 413ms\n",
      "417:\tlearn: 1.4033395\ttotal: 354ms\tremaining: 412ms\n",
      "418:\tlearn: 1.4015374\ttotal: 355ms\tremaining: 411ms\n",
      "419:\tlearn: 1.3987598\ttotal: 355ms\tremaining: 410ms\n",
      "420:\tlearn: 1.3963989\ttotal: 356ms\tremaining: 409ms\n",
      "421:\tlearn: 1.3943238\ttotal: 357ms\tremaining: 409ms\n",
      "422:\tlearn: 1.3931340\ttotal: 358ms\tremaining: 408ms\n",
      "423:\tlearn: 1.3897994\ttotal: 359ms\tremaining: 407ms\n",
      "424:\tlearn: 1.3865646\ttotal: 359ms\tremaining: 406ms\n",
      "425:\tlearn: 1.3834973\ttotal: 360ms\tremaining: 405ms\n",
      "426:\tlearn: 1.3805742\ttotal: 361ms\tremaining: 404ms\n",
      "427:\tlearn: 1.3795595\ttotal: 362ms\tremaining: 403ms\n",
      "428:\tlearn: 1.3763304\ttotal: 363ms\tremaining: 402ms\n",
      "429:\tlearn: 1.3755045\ttotal: 363ms\tremaining: 401ms\n",
      "430:\tlearn: 1.3722138\ttotal: 364ms\tremaining: 400ms\n",
      "431:\tlearn: 1.3700056\ttotal: 365ms\tremaining: 399ms\n",
      "432:\tlearn: 1.3669757\ttotal: 365ms\tremaining: 398ms\n",
      "433:\tlearn: 1.3641056\ttotal: 366ms\tremaining: 397ms\n",
      "434:\tlearn: 1.3631781\ttotal: 367ms\tremaining: 397ms\n",
      "435:\tlearn: 1.3619418\ttotal: 368ms\tremaining: 396ms\n",
      "436:\tlearn: 1.3608577\ttotal: 369ms\tremaining: 395ms\n",
      "437:\tlearn: 1.3583291\ttotal: 369ms\tremaining: 394ms\n",
      "438:\tlearn: 1.3566152\ttotal: 370ms\tremaining: 393ms\n",
      "439:\tlearn: 1.3555896\ttotal: 371ms\tremaining: 392ms\n",
      "440:\tlearn: 1.3547963\ttotal: 372ms\tremaining: 391ms\n",
      "441:\tlearn: 1.3531062\ttotal: 373ms\tremaining: 391ms\n",
      "442:\tlearn: 1.3500688\ttotal: 374ms\tremaining: 390ms\n",
      "443:\tlearn: 1.3467811\ttotal: 375ms\tremaining: 389ms\n",
      "444:\tlearn: 1.3439364\ttotal: 376ms\tremaining: 389ms\n",
      "445:\tlearn: 1.3422559\ttotal: 377ms\tremaining: 388ms\n",
      "446:\tlearn: 1.3409790\ttotal: 378ms\tremaining: 387ms\n",
      "447:\tlearn: 1.3392970\ttotal: 378ms\tremaining: 386ms\n",
      "448:\tlearn: 1.3369233\ttotal: 379ms\tremaining: 385ms\n",
      "449:\tlearn: 1.3345617\ttotal: 380ms\tremaining: 384ms\n",
      "450:\tlearn: 1.3336983\ttotal: 381ms\tremaining: 383ms\n",
      "451:\tlearn: 1.3305109\ttotal: 382ms\tremaining: 383ms\n",
      "452:\tlearn: 1.3295190\ttotal: 383ms\tremaining: 382ms\n",
      "453:\tlearn: 1.3283845\ttotal: 383ms\tremaining: 381ms\n",
      "454:\tlearn: 1.3239879\ttotal: 384ms\tremaining: 380ms\n",
      "455:\tlearn: 1.3216203\ttotal: 385ms\tremaining: 379ms\n",
      "456:\tlearn: 1.3190590\ttotal: 386ms\tremaining: 378ms\n",
      "457:\tlearn: 1.3165341\ttotal: 386ms\tremaining: 377ms\n",
      "458:\tlearn: 1.3155081\ttotal: 387ms\tremaining: 376ms\n",
      "459:\tlearn: 1.3142407\ttotal: 388ms\tremaining: 375ms\n",
      "460:\tlearn: 1.3118788\ttotal: 389ms\tremaining: 374ms\n",
      "461:\tlearn: 1.3088539\ttotal: 389ms\tremaining: 373ms\n",
      "462:\tlearn: 1.3056027\ttotal: 390ms\tremaining: 373ms\n",
      "463:\tlearn: 1.3046371\ttotal: 391ms\tremaining: 372ms\n",
      "464:\tlearn: 1.3016448\ttotal: 392ms\tremaining: 371ms\n",
      "465:\tlearn: 1.2996154\ttotal: 393ms\tremaining: 370ms\n",
      "466:\tlearn: 1.2966726\ttotal: 394ms\tremaining: 370ms\n",
      "467:\tlearn: 1.2940691\ttotal: 395ms\tremaining: 369ms\n",
      "468:\tlearn: 1.2913496\ttotal: 396ms\tremaining: 368ms\n",
      "469:\tlearn: 1.2890757\ttotal: 397ms\tremaining: 367ms\n",
      "470:\tlearn: 1.2870097\ttotal: 398ms\tremaining: 366ms\n",
      "471:\tlearn: 1.2854029\ttotal: 399ms\tremaining: 366ms\n",
      "472:\tlearn: 1.2830040\ttotal: 400ms\tremaining: 365ms\n",
      "473:\tlearn: 1.2801163\ttotal: 401ms\tremaining: 365ms\n",
      "474:\tlearn: 1.2764216\ttotal: 402ms\tremaining: 364ms\n",
      "475:\tlearn: 1.2744012\ttotal: 403ms\tremaining: 363ms\n",
      "476:\tlearn: 1.2720054\ttotal: 403ms\tremaining: 362ms\n",
      "477:\tlearn: 1.2692239\ttotal: 404ms\tremaining: 361ms\n",
      "478:\tlearn: 1.2665176\ttotal: 405ms\tremaining: 360ms\n",
      "479:\tlearn: 1.2648147\ttotal: 406ms\tremaining: 359ms\n",
      "480:\tlearn: 1.2631588\ttotal: 407ms\tremaining: 358ms\n",
      "481:\tlearn: 1.2611753\ttotal: 407ms\tremaining: 358ms\n",
      "482:\tlearn: 1.2595178\ttotal: 408ms\tremaining: 357ms\n",
      "483:\tlearn: 1.2579494\ttotal: 409ms\tremaining: 356ms\n",
      "484:\tlearn: 1.2547304\ttotal: 410ms\tremaining: 355ms\n",
      "485:\tlearn: 1.2540087\ttotal: 411ms\tremaining: 354ms\n",
      "486:\tlearn: 1.2518136\ttotal: 411ms\tremaining: 353ms\n",
      "487:\tlearn: 1.2489606\ttotal: 412ms\tremaining: 352ms\n",
      "488:\tlearn: 1.2475799\ttotal: 413ms\tremaining: 351ms\n",
      "489:\tlearn: 1.2450441\ttotal: 414ms\tremaining: 351ms\n",
      "490:\tlearn: 1.2442482\ttotal: 415ms\tremaining: 350ms\n",
      "491:\tlearn: 1.2424368\ttotal: 416ms\tremaining: 349ms\n",
      "492:\tlearn: 1.2397154\ttotal: 417ms\tremaining: 348ms\n",
      "493:\tlearn: 1.2353101\ttotal: 418ms\tremaining: 348ms\n",
      "494:\tlearn: 1.2336476\ttotal: 418ms\tremaining: 347ms\n",
      "495:\tlearn: 1.2312793\ttotal: 419ms\tremaining: 346ms\n",
      "496:\tlearn: 1.2275381\ttotal: 420ms\tremaining: 345ms\n",
      "497:\tlearn: 1.2255353\ttotal: 421ms\tremaining: 344ms\n",
      "498:\tlearn: 1.2234708\ttotal: 422ms\tremaining: 343ms\n",
      "499:\tlearn: 1.2208314\ttotal: 423ms\tremaining: 342ms\n",
      "500:\tlearn: 1.2198550\ttotal: 423ms\tremaining: 341ms\n",
      "501:\tlearn: 1.2166459\ttotal: 424ms\tremaining: 340ms\n",
      "502:\tlearn: 1.2140818\ttotal: 425ms\tremaining: 340ms\n",
      "503:\tlearn: 1.2122670\ttotal: 426ms\tremaining: 339ms\n",
      "504:\tlearn: 1.2107186\ttotal: 426ms\tremaining: 338ms\n",
      "505:\tlearn: 1.2089920\ttotal: 427ms\tremaining: 337ms\n",
      "506:\tlearn: 1.2071257\ttotal: 428ms\tremaining: 336ms\n",
      "507:\tlearn: 1.2044847\ttotal: 429ms\tremaining: 335ms\n",
      "508:\tlearn: 1.2032228\ttotal: 430ms\tremaining: 334ms\n",
      "509:\tlearn: 1.2019592\ttotal: 431ms\tremaining: 334ms\n",
      "510:\tlearn: 1.1983384\ttotal: 431ms\tremaining: 333ms\n",
      "511:\tlearn: 1.1961489\ttotal: 432ms\tremaining: 332ms\n",
      "512:\tlearn: 1.1933360\ttotal: 433ms\tremaining: 331ms\n",
      "513:\tlearn: 1.1907908\ttotal: 434ms\tremaining: 330ms\n",
      "514:\tlearn: 1.1876401\ttotal: 435ms\tremaining: 329ms\n",
      "515:\tlearn: 1.1839289\ttotal: 436ms\tremaining: 328ms\n",
      "516:\tlearn: 1.1815892\ttotal: 436ms\tremaining: 328ms\n",
      "517:\tlearn: 1.1790494\ttotal: 437ms\tremaining: 327ms\n",
      "518:\tlearn: 1.1756818\ttotal: 438ms\tremaining: 326ms\n",
      "519:\tlearn: 1.1729811\ttotal: 439ms\tremaining: 325ms\n",
      "520:\tlearn: 1.1722872\ttotal: 440ms\tremaining: 324ms\n",
      "521:\tlearn: 1.1704179\ttotal: 441ms\tremaining: 323ms\n",
      "522:\tlearn: 1.1667982\ttotal: 441ms\tremaining: 322ms\n",
      "523:\tlearn: 1.1649705\ttotal: 442ms\tremaining: 322ms\n",
      "524:\tlearn: 1.1641438\ttotal: 443ms\tremaining: 321ms\n",
      "525:\tlearn: 1.1630426\ttotal: 444ms\tremaining: 320ms\n",
      "526:\tlearn: 1.1618395\ttotal: 445ms\tremaining: 319ms\n",
      "527:\tlearn: 1.1602110\ttotal: 446ms\tremaining: 318ms\n",
      "528:\tlearn: 1.1591771\ttotal: 446ms\tremaining: 317ms\n",
      "529:\tlearn: 1.1571263\ttotal: 447ms\tremaining: 316ms\n",
      "530:\tlearn: 1.1562162\ttotal: 448ms\tremaining: 316ms\n",
      "531:\tlearn: 1.1550993\ttotal: 449ms\tremaining: 315ms\n",
      "532:\tlearn: 1.1534354\ttotal: 450ms\tremaining: 314ms\n",
      "533:\tlearn: 1.1521358\ttotal: 450ms\tremaining: 313ms\n",
      "534:\tlearn: 1.1502911\ttotal: 451ms\tremaining: 312ms\n",
      "535:\tlearn: 1.1476651\ttotal: 452ms\tremaining: 311ms\n",
      "536:\tlearn: 1.1466839\ttotal: 453ms\tremaining: 310ms\n",
      "537:\tlearn: 1.1454841\ttotal: 454ms\tremaining: 309ms\n",
      "538:\tlearn: 1.1447070\ttotal: 454ms\tremaining: 309ms\n",
      "539:\tlearn: 1.1430408\ttotal: 455ms\tremaining: 308ms\n",
      "540:\tlearn: 1.1418403\ttotal: 456ms\tremaining: 307ms\n",
      "541:\tlearn: 1.1392488\ttotal: 457ms\tremaining: 306ms\n",
      "542:\tlearn: 1.1363460\ttotal: 457ms\tremaining: 305ms\n",
      "543:\tlearn: 1.1345625\ttotal: 458ms\tremaining: 304ms\n",
      "544:\tlearn: 1.1335045\ttotal: 459ms\tremaining: 303ms\n",
      "545:\tlearn: 1.1306053\ttotal: 460ms\tremaining: 302ms\n",
      "546:\tlearn: 1.1284160\ttotal: 461ms\tremaining: 301ms\n",
      "547:\tlearn: 1.1270911\ttotal: 461ms\tremaining: 301ms\n",
      "548:\tlearn: 1.1248503\ttotal: 462ms\tremaining: 300ms\n",
      "549:\tlearn: 1.1229220\ttotal: 463ms\tremaining: 299ms\n",
      "550:\tlearn: 1.1208674\ttotal: 464ms\tremaining: 298ms\n",
      "551:\tlearn: 1.1187318\ttotal: 465ms\tremaining: 297ms\n",
      "552:\tlearn: 1.1158467\ttotal: 465ms\tremaining: 296ms\n",
      "553:\tlearn: 1.1135996\ttotal: 466ms\tremaining: 295ms\n",
      "554:\tlearn: 1.1126255\ttotal: 467ms\tremaining: 295ms\n",
      "555:\tlearn: 1.1111146\ttotal: 468ms\tremaining: 294ms\n",
      "556:\tlearn: 1.1092313\ttotal: 469ms\tremaining: 293ms\n",
      "557:\tlearn: 1.1070352\ttotal: 470ms\tremaining: 292ms\n",
      "558:\tlearn: 1.1055794\ttotal: 470ms\tremaining: 291ms\n",
      "559:\tlearn: 1.1039866\ttotal: 471ms\tremaining: 290ms\n",
      "560:\tlearn: 1.1029741\ttotal: 472ms\tremaining: 289ms\n",
      "561:\tlearn: 1.1017849\ttotal: 473ms\tremaining: 289ms\n",
      "562:\tlearn: 1.0992300\ttotal: 474ms\tremaining: 288ms\n",
      "563:\tlearn: 1.0980168\ttotal: 474ms\tremaining: 287ms\n",
      "564:\tlearn: 1.0942965\ttotal: 475ms\tremaining: 286ms\n",
      "565:\tlearn: 1.0927406\ttotal: 476ms\tremaining: 285ms\n",
      "566:\tlearn: 1.0916712\ttotal: 476ms\tremaining: 284ms\n",
      "567:\tlearn: 1.0899866\ttotal: 477ms\tremaining: 283ms\n",
      "568:\tlearn: 1.0883798\ttotal: 478ms\tremaining: 282ms\n",
      "569:\tlearn: 1.0863262\ttotal: 479ms\tremaining: 282ms\n",
      "570:\tlearn: 1.0851409\ttotal: 480ms\tremaining: 281ms\n",
      "571:\tlearn: 1.0846675\ttotal: 481ms\tremaining: 280ms\n",
      "572:\tlearn: 1.0825316\ttotal: 481ms\tremaining: 279ms\n",
      "573:\tlearn: 1.0804626\ttotal: 482ms\tremaining: 278ms\n",
      "574:\tlearn: 1.0788119\ttotal: 483ms\tremaining: 277ms\n",
      "575:\tlearn: 1.0763018\ttotal: 484ms\tremaining: 276ms\n",
      "576:\tlearn: 1.0741922\ttotal: 485ms\tremaining: 276ms\n",
      "577:\tlearn: 1.0735342\ttotal: 486ms\tremaining: 275ms\n",
      "578:\tlearn: 1.0725496\ttotal: 486ms\tremaining: 274ms\n",
      "579:\tlearn: 1.0719063\ttotal: 487ms\tremaining: 273ms\n",
      "580:\tlearn: 1.0702810\ttotal: 488ms\tremaining: 272ms\n",
      "581:\tlearn: 1.0685162\ttotal: 489ms\tremaining: 271ms\n",
      "582:\tlearn: 1.0677863\ttotal: 490ms\tremaining: 271ms\n",
      "583:\tlearn: 1.0663603\ttotal: 491ms\tremaining: 270ms\n",
      "584:\tlearn: 1.0650321\ttotal: 491ms\tremaining: 269ms\n",
      "585:\tlearn: 1.0636486\ttotal: 492ms\tremaining: 268ms\n",
      "586:\tlearn: 1.0615833\ttotal: 493ms\tremaining: 267ms\n",
      "587:\tlearn: 1.0608369\ttotal: 494ms\tremaining: 266ms\n",
      "588:\tlearn: 1.0594156\ttotal: 495ms\tremaining: 265ms\n",
      "589:\tlearn: 1.0580267\ttotal: 496ms\tremaining: 265ms\n",
      "590:\tlearn: 1.0560279\ttotal: 496ms\tremaining: 264ms\n",
      "591:\tlearn: 1.0537668\ttotal: 497ms\tremaining: 263ms\n",
      "592:\tlearn: 1.0519580\ttotal: 498ms\tremaining: 262ms\n",
      "593:\tlearn: 1.0500456\ttotal: 498ms\tremaining: 261ms\n",
      "594:\tlearn: 1.0493230\ttotal: 499ms\tremaining: 260ms\n",
      "595:\tlearn: 1.0483129\ttotal: 500ms\tremaining: 259ms\n",
      "596:\tlearn: 1.0473406\ttotal: 501ms\tremaining: 258ms\n",
      "597:\tlearn: 1.0450712\ttotal: 502ms\tremaining: 258ms\n",
      "598:\tlearn: 1.0432712\ttotal: 502ms\tremaining: 257ms\n",
      "599:\tlearn: 1.0421883\ttotal: 503ms\tremaining: 256ms\n",
      "600:\tlearn: 1.0405586\ttotal: 504ms\tremaining: 255ms\n",
      "601:\tlearn: 1.0389405\ttotal: 505ms\tremaining: 254ms\n",
      "602:\tlearn: 1.0377882\ttotal: 506ms\tremaining: 253ms\n",
      "603:\tlearn: 1.0362564\ttotal: 507ms\tremaining: 253ms\n",
      "604:\tlearn: 1.0351661\ttotal: 508ms\tremaining: 252ms\n",
      "605:\tlearn: 1.0333067\ttotal: 508ms\tremaining: 251ms\n",
      "606:\tlearn: 1.0317224\ttotal: 509ms\tremaining: 250ms\n",
      "607:\tlearn: 1.0308059\ttotal: 510ms\tremaining: 249ms\n",
      "608:\tlearn: 1.0281544\ttotal: 511ms\tremaining: 248ms\n",
      "609:\tlearn: 1.0261396\ttotal: 512ms\tremaining: 247ms\n",
      "610:\tlearn: 1.0230923\ttotal: 513ms\tremaining: 247ms\n",
      "611:\tlearn: 1.0209417\ttotal: 513ms\tremaining: 246ms\n",
      "612:\tlearn: 1.0191538\ttotal: 514ms\tremaining: 245ms\n",
      "613:\tlearn: 1.0174270\ttotal: 515ms\tremaining: 244ms\n",
      "614:\tlearn: 1.0164108\ttotal: 516ms\tremaining: 243ms\n",
      "615:\tlearn: 1.0148721\ttotal: 516ms\tremaining: 242ms\n",
      "616:\tlearn: 1.0132273\ttotal: 517ms\tremaining: 241ms\n",
      "617:\tlearn: 1.0117938\ttotal: 518ms\tremaining: 241ms\n",
      "618:\tlearn: 1.0107472\ttotal: 519ms\tremaining: 240ms\n",
      "619:\tlearn: 1.0093172\ttotal: 520ms\tremaining: 239ms\n",
      "620:\tlearn: 1.0081848\ttotal: 521ms\tremaining: 238ms\n",
      "621:\tlearn: 1.0057840\ttotal: 521ms\tremaining: 237ms\n",
      "622:\tlearn: 1.0049581\ttotal: 522ms\tremaining: 236ms\n",
      "623:\tlearn: 1.0033217\ttotal: 523ms\tremaining: 235ms\n",
      "624:\tlearn: 1.0020493\ttotal: 524ms\tremaining: 235ms\n",
      "625:\tlearn: 1.0013761\ttotal: 524ms\tremaining: 234ms\n",
      "626:\tlearn: 0.9979885\ttotal: 525ms\tremaining: 233ms\n",
      "627:\tlearn: 0.9960830\ttotal: 526ms\tremaining: 232ms\n",
      "628:\tlearn: 0.9949135\ttotal: 527ms\tremaining: 231ms\n",
      "629:\tlearn: 0.9924120\ttotal: 527ms\tremaining: 230ms\n",
      "630:\tlearn: 0.9910035\ttotal: 528ms\tremaining: 229ms\n",
      "631:\tlearn: 0.9898392\ttotal: 529ms\tremaining: 228ms\n",
      "632:\tlearn: 0.9878753\ttotal: 530ms\tremaining: 228ms\n",
      "633:\tlearn: 0.9866929\ttotal: 530ms\tremaining: 227ms\n",
      "634:\tlearn: 0.9861590\ttotal: 531ms\tremaining: 226ms\n",
      "635:\tlearn: 0.9841591\ttotal: 532ms\tremaining: 225ms\n",
      "636:\tlearn: 0.9832491\ttotal: 533ms\tremaining: 224ms\n",
      "637:\tlearn: 0.9824340\ttotal: 534ms\tremaining: 223ms\n",
      "638:\tlearn: 0.9812847\ttotal: 534ms\tremaining: 222ms\n",
      "639:\tlearn: 0.9795308\ttotal: 535ms\tremaining: 222ms\n",
      "640:\tlearn: 0.9782691\ttotal: 536ms\tremaining: 221ms\n",
      "641:\tlearn: 0.9762771\ttotal: 537ms\tremaining: 220ms\n",
      "642:\tlearn: 0.9735821\ttotal: 537ms\tremaining: 219ms\n",
      "643:\tlearn: 0.9720997\ttotal: 538ms\tremaining: 218ms\n",
      "644:\tlearn: 0.9709763\ttotal: 539ms\tremaining: 217ms\n",
      "645:\tlearn: 0.9699364\ttotal: 540ms\tremaining: 216ms\n",
      "646:\tlearn: 0.9681899\ttotal: 541ms\tremaining: 216ms\n",
      "647:\tlearn: 0.9672434\ttotal: 541ms\tremaining: 215ms\n",
      "648:\tlearn: 0.9653258\ttotal: 542ms\tremaining: 214ms\n",
      "649:\tlearn: 0.9633338\ttotal: 543ms\tremaining: 213ms\n",
      "650:\tlearn: 0.9622817\ttotal: 544ms\tremaining: 212ms\n",
      "651:\tlearn: 0.9615629\ttotal: 544ms\tremaining: 211ms\n",
      "652:\tlearn: 0.9600968\ttotal: 545ms\tremaining: 210ms\n",
      "653:\tlearn: 0.9591810\ttotal: 546ms\tremaining: 210ms\n",
      "654:\tlearn: 0.9584183\ttotal: 547ms\tremaining: 209ms\n",
      "655:\tlearn: 0.9578225\ttotal: 548ms\tremaining: 208ms\n",
      "656:\tlearn: 0.9571922\ttotal: 548ms\tremaining: 207ms\n",
      "657:\tlearn: 0.9564352\ttotal: 549ms\tremaining: 206ms\n",
      "658:\tlearn: 0.9555174\ttotal: 550ms\tremaining: 205ms\n",
      "659:\tlearn: 0.9543369\ttotal: 551ms\tremaining: 204ms\n",
      "660:\tlearn: 0.9529238\ttotal: 551ms\tremaining: 204ms\n",
      "661:\tlearn: 0.9512962\ttotal: 552ms\tremaining: 203ms\n",
      "662:\tlearn: 0.9498173\ttotal: 553ms\tremaining: 202ms\n",
      "663:\tlearn: 0.9471539\ttotal: 553ms\tremaining: 201ms\n",
      "664:\tlearn: 0.9452079\ttotal: 554ms\tremaining: 200ms\n",
      "665:\tlearn: 0.9429099\ttotal: 555ms\tremaining: 199ms\n",
      "666:\tlearn: 0.9419950\ttotal: 556ms\tremaining: 198ms\n",
      "667:\tlearn: 0.9400312\ttotal: 556ms\tremaining: 197ms\n",
      "668:\tlearn: 0.9391768\ttotal: 558ms\tremaining: 197ms\n",
      "669:\tlearn: 0.9380051\ttotal: 559ms\tremaining: 196ms\n",
      "670:\tlearn: 0.9367166\ttotal: 560ms\tremaining: 195ms\n",
      "671:\tlearn: 0.9355887\ttotal: 561ms\tremaining: 195ms\n",
      "672:\tlearn: 0.9342623\ttotal: 562ms\tremaining: 194ms\n",
      "673:\tlearn: 0.9327219\ttotal: 563ms\tremaining: 193ms\n",
      "674:\tlearn: 0.9323370\ttotal: 563ms\tremaining: 192ms\n",
      "675:\tlearn: 0.9314015\ttotal: 564ms\tremaining: 191ms\n",
      "676:\tlearn: 0.9303026\ttotal: 565ms\tremaining: 190ms\n",
      "677:\tlearn: 0.9295604\ttotal: 566ms\tremaining: 189ms\n",
      "678:\tlearn: 0.9279239\ttotal: 567ms\tremaining: 189ms\n",
      "679:\tlearn: 0.9273618\ttotal: 567ms\tremaining: 188ms\n",
      "680:\tlearn: 0.9259975\ttotal: 568ms\tremaining: 187ms\n",
      "681:\tlearn: 0.9244345\ttotal: 569ms\tremaining: 186ms\n",
      "682:\tlearn: 0.9237287\ttotal: 570ms\tremaining: 185ms\n",
      "683:\tlearn: 0.9229466\ttotal: 570ms\tremaining: 184ms\n",
      "684:\tlearn: 0.9210845\ttotal: 571ms\tremaining: 183ms\n",
      "685:\tlearn: 0.9193859\ttotal: 572ms\tremaining: 183ms\n",
      "686:\tlearn: 0.9172769\ttotal: 572ms\tremaining: 182ms\n",
      "687:\tlearn: 0.9166151\ttotal: 573ms\tremaining: 181ms\n",
      "688:\tlearn: 0.9150454\ttotal: 574ms\tremaining: 180ms\n",
      "689:\tlearn: 0.9138569\ttotal: 575ms\tremaining: 179ms\n",
      "690:\tlearn: 0.9124205\ttotal: 576ms\tremaining: 178ms\n",
      "691:\tlearn: 0.9104575\ttotal: 576ms\tremaining: 177ms\n",
      "692:\tlearn: 0.9092031\ttotal: 577ms\tremaining: 177ms\n",
      "693:\tlearn: 0.9076745\ttotal: 578ms\tremaining: 176ms\n",
      "694:\tlearn: 0.9064573\ttotal: 579ms\tremaining: 175ms\n",
      "695:\tlearn: 0.9051279\ttotal: 580ms\tremaining: 174ms\n",
      "696:\tlearn: 0.9031741\ttotal: 581ms\tremaining: 173ms\n",
      "697:\tlearn: 0.9021923\ttotal: 582ms\tremaining: 172ms\n",
      "698:\tlearn: 0.9004999\ttotal: 582ms\tremaining: 172ms\n",
      "699:\tlearn: 0.8994538\ttotal: 583ms\tremaining: 171ms\n",
      "700:\tlearn: 0.8969161\ttotal: 584ms\tremaining: 170ms\n",
      "701:\tlearn: 0.8961986\ttotal: 585ms\tremaining: 169ms\n",
      "702:\tlearn: 0.8953708\ttotal: 586ms\tremaining: 168ms\n",
      "703:\tlearn: 0.8944556\ttotal: 587ms\tremaining: 167ms\n",
      "704:\tlearn: 0.8933612\ttotal: 587ms\tremaining: 167ms\n",
      "705:\tlearn: 0.8918837\ttotal: 588ms\tremaining: 166ms\n",
      "706:\tlearn: 0.8904901\ttotal: 589ms\tremaining: 165ms\n",
      "707:\tlearn: 0.8897620\ttotal: 590ms\tremaining: 164ms\n",
      "708:\tlearn: 0.8886013\ttotal: 591ms\tremaining: 163ms\n",
      "709:\tlearn: 0.8876219\ttotal: 592ms\tremaining: 163ms\n",
      "710:\tlearn: 0.8861939\ttotal: 593ms\tremaining: 162ms\n",
      "711:\tlearn: 0.8857473\ttotal: 594ms\tremaining: 161ms\n",
      "712:\tlearn: 0.8845454\ttotal: 595ms\tremaining: 160ms\n",
      "713:\tlearn: 0.8839791\ttotal: 596ms\tremaining: 160ms\n",
      "714:\tlearn: 0.8831299\ttotal: 597ms\tremaining: 159ms\n",
      "715:\tlearn: 0.8817154\ttotal: 598ms\tremaining: 158ms\n",
      "716:\tlearn: 0.8802462\ttotal: 599ms\tremaining: 157ms\n",
      "717:\tlearn: 0.8786317\ttotal: 600ms\tremaining: 156ms\n",
      "718:\tlearn: 0.8779757\ttotal: 601ms\tremaining: 155ms\n",
      "719:\tlearn: 0.8758775\ttotal: 601ms\tremaining: 155ms\n",
      "720:\tlearn: 0.8751255\ttotal: 602ms\tremaining: 154ms\n",
      "721:\tlearn: 0.8741719\ttotal: 603ms\tremaining: 153ms\n",
      "722:\tlearn: 0.8734761\ttotal: 604ms\tremaining: 152ms\n",
      "723:\tlearn: 0.8724518\ttotal: 605ms\tremaining: 151ms\n",
      "724:\tlearn: 0.8710212\ttotal: 606ms\tremaining: 150ms\n",
      "725:\tlearn: 0.8703089\ttotal: 607ms\tremaining: 150ms\n",
      "726:\tlearn: 0.8699244\ttotal: 607ms\tremaining: 149ms\n",
      "727:\tlearn: 0.8685583\ttotal: 608ms\tremaining: 148ms\n",
      "728:\tlearn: 0.8665824\ttotal: 609ms\tremaining: 147ms\n",
      "729:\tlearn: 0.8658727\ttotal: 610ms\tremaining: 146ms\n",
      "730:\tlearn: 0.8648511\ttotal: 611ms\tremaining: 145ms\n",
      "731:\tlearn: 0.8631702\ttotal: 611ms\tremaining: 145ms\n",
      "732:\tlearn: 0.8621653\ttotal: 612ms\tremaining: 144ms\n",
      "733:\tlearn: 0.8607640\ttotal: 613ms\tremaining: 143ms\n",
      "734:\tlearn: 0.8595340\ttotal: 614ms\tremaining: 142ms\n",
      "735:\tlearn: 0.8586604\ttotal: 615ms\tremaining: 141ms\n",
      "736:\tlearn: 0.8572553\ttotal: 616ms\tremaining: 140ms\n",
      "737:\tlearn: 0.8569473\ttotal: 617ms\tremaining: 140ms\n",
      "738:\tlearn: 0.8560421\ttotal: 618ms\tremaining: 139ms\n",
      "739:\tlearn: 0.8542471\ttotal: 619ms\tremaining: 138ms\n",
      "740:\tlearn: 0.8529525\ttotal: 620ms\tremaining: 137ms\n",
      "741:\tlearn: 0.8513357\ttotal: 620ms\tremaining: 136ms\n",
      "742:\tlearn: 0.8503344\ttotal: 621ms\tremaining: 135ms\n",
      "743:\tlearn: 0.8497741\ttotal: 622ms\tremaining: 135ms\n",
      "744:\tlearn: 0.8491599\ttotal: 623ms\tremaining: 134ms\n",
      "745:\tlearn: 0.8471901\ttotal: 624ms\tremaining: 133ms\n",
      "746:\tlearn: 0.8466046\ttotal: 624ms\tremaining: 132ms\n",
      "747:\tlearn: 0.8454612\ttotal: 625ms\tremaining: 131ms\n",
      "748:\tlearn: 0.8427291\ttotal: 626ms\tremaining: 130ms\n",
      "749:\tlearn: 0.8419947\ttotal: 627ms\tremaining: 130ms\n",
      "750:\tlearn: 0.8411068\ttotal: 627ms\tremaining: 129ms\n",
      "751:\tlearn: 0.8396889\ttotal: 628ms\tremaining: 128ms\n",
      "752:\tlearn: 0.8389829\ttotal: 629ms\tremaining: 127ms\n",
      "753:\tlearn: 0.8381581\ttotal: 630ms\tremaining: 126ms\n",
      "754:\tlearn: 0.8371017\ttotal: 631ms\tremaining: 125ms\n",
      "755:\tlearn: 0.8358926\ttotal: 632ms\tremaining: 125ms\n",
      "756:\tlearn: 0.8326822\ttotal: 633ms\tremaining: 124ms\n",
      "757:\tlearn: 0.8313619\ttotal: 634ms\tremaining: 123ms\n",
      "758:\tlearn: 0.8300569\ttotal: 635ms\tremaining: 122ms\n",
      "759:\tlearn: 0.8293257\ttotal: 636ms\tremaining: 121ms\n",
      "760:\tlearn: 0.8288750\ttotal: 636ms\tremaining: 120ms\n",
      "761:\tlearn: 0.8274613\ttotal: 637ms\tremaining: 120ms\n",
      "762:\tlearn: 0.8252371\ttotal: 638ms\tremaining: 119ms\n",
      "763:\tlearn: 0.8249030\ttotal: 639ms\tremaining: 118ms\n",
      "764:\tlearn: 0.8235220\ttotal: 640ms\tremaining: 117ms\n",
      "765:\tlearn: 0.8231784\ttotal: 640ms\tremaining: 116ms\n",
      "766:\tlearn: 0.8213701\ttotal: 641ms\tremaining: 115ms\n",
      "767:\tlearn: 0.8206137\ttotal: 642ms\tremaining: 115ms\n",
      "768:\tlearn: 0.8195738\ttotal: 643ms\tremaining: 114ms\n",
      "769:\tlearn: 0.8185299\ttotal: 644ms\tremaining: 113ms\n",
      "770:\tlearn: 0.8176718\ttotal: 645ms\tremaining: 112ms\n",
      "771:\tlearn: 0.8163643\ttotal: 645ms\tremaining: 111ms\n",
      "772:\tlearn: 0.8146564\ttotal: 646ms\tremaining: 110ms\n",
      "773:\tlearn: 0.8132271\ttotal: 647ms\tremaining: 110ms\n",
      "774:\tlearn: 0.8119492\ttotal: 648ms\tremaining: 109ms\n",
      "775:\tlearn: 0.8105643\ttotal: 649ms\tremaining: 108ms\n",
      "776:\tlearn: 0.8098033\ttotal: 650ms\tremaining: 107ms\n",
      "777:\tlearn: 0.8091207\ttotal: 650ms\tremaining: 106ms\n",
      "778:\tlearn: 0.8082058\ttotal: 651ms\tremaining: 105ms\n",
      "779:\tlearn: 0.8077311\ttotal: 652ms\tremaining: 104ms\n",
      "780:\tlearn: 0.8065426\ttotal: 653ms\tremaining: 104ms\n",
      "781:\tlearn: 0.8056429\ttotal: 654ms\tremaining: 103ms\n",
      "782:\tlearn: 0.8047686\ttotal: 654ms\tremaining: 102ms\n",
      "783:\tlearn: 0.8038614\ttotal: 655ms\tremaining: 101ms\n",
      "784:\tlearn: 0.8025699\ttotal: 656ms\tremaining: 100ms\n",
      "785:\tlearn: 0.8014867\ttotal: 657ms\tremaining: 99.4ms\n",
      "786:\tlearn: 0.8004814\ttotal: 657ms\tremaining: 98.6ms\n",
      "787:\tlearn: 0.7995832\ttotal: 658ms\tremaining: 97.7ms\n",
      "788:\tlearn: 0.7989939\ttotal: 659ms\tremaining: 96.9ms\n",
      "789:\tlearn: 0.7981679\ttotal: 660ms\tremaining: 96.1ms\n",
      "790:\tlearn: 0.7965006\ttotal: 661ms\tremaining: 95.3ms\n",
      "791:\tlearn: 0.7956434\ttotal: 662ms\tremaining: 94.4ms\n",
      "792:\tlearn: 0.7941540\ttotal: 663ms\tremaining: 93.6ms\n",
      "793:\tlearn: 0.7925985\ttotal: 664ms\tremaining: 92.8ms\n",
      "794:\tlearn: 0.7915623\ttotal: 665ms\tremaining: 92ms\n",
      "795:\tlearn: 0.7911766\ttotal: 665ms\tremaining: 91.1ms\n",
      "796:\tlearn: 0.7898238\ttotal: 666ms\tremaining: 90.3ms\n",
      "797:\tlearn: 0.7886790\ttotal: 667ms\tremaining: 89.5ms\n",
      "798:\tlearn: 0.7878089\ttotal: 668ms\tremaining: 88.6ms\n",
      "799:\tlearn: 0.7870879\ttotal: 669ms\tremaining: 87.8ms\n",
      "800:\tlearn: 0.7864919\ttotal: 670ms\tremaining: 86.9ms\n",
      "801:\tlearn: 0.7843003\ttotal: 670ms\tremaining: 86.1ms\n",
      "802:\tlearn: 0.7832939\ttotal: 671ms\tremaining: 85.3ms\n",
      "803:\tlearn: 0.7827977\ttotal: 672ms\tremaining: 84.4ms\n",
      "804:\tlearn: 0.7824286\ttotal: 673ms\tremaining: 83.6ms\n",
      "805:\tlearn: 0.7815494\ttotal: 674ms\tremaining: 82.7ms\n",
      "806:\tlearn: 0.7810359\ttotal: 674ms\tremaining: 81.9ms\n",
      "807:\tlearn: 0.7803910\ttotal: 675ms\tremaining: 81ms\n",
      "808:\tlearn: 0.7797451\ttotal: 676ms\tremaining: 80.2ms\n",
      "809:\tlearn: 0.7784613\ttotal: 677ms\tremaining: 79.4ms\n",
      "810:\tlearn: 0.7766461\ttotal: 677ms\tremaining: 78.5ms\n",
      "811:\tlearn: 0.7762746\ttotal: 678ms\tremaining: 77.7ms\n",
      "812:\tlearn: 0.7742140\ttotal: 679ms\tremaining: 76.9ms\n",
      "813:\tlearn: 0.7727230\ttotal: 680ms\tremaining: 76ms\n",
      "814:\tlearn: 0.7721999\ttotal: 681ms\tremaining: 75.2ms\n",
      "815:\tlearn: 0.7717608\ttotal: 682ms\tremaining: 74.4ms\n",
      "816:\tlearn: 0.7711895\ttotal: 682ms\tremaining: 73.5ms\n",
      "817:\tlearn: 0.7695157\ttotal: 683ms\tremaining: 72.7ms\n",
      "818:\tlearn: 0.7690228\ttotal: 684ms\tremaining: 71.8ms\n",
      "819:\tlearn: 0.7668987\ttotal: 685ms\tremaining: 71ms\n",
      "820:\tlearn: 0.7665263\ttotal: 685ms\tremaining: 70.1ms\n",
      "821:\tlearn: 0.7649278\ttotal: 686ms\tremaining: 69.3ms\n",
      "822:\tlearn: 0.7635578\ttotal: 687ms\tremaining: 68.4ms\n",
      "823:\tlearn: 0.7617583\ttotal: 688ms\tremaining: 67.6ms\n",
      "824:\tlearn: 0.7602299\ttotal: 689ms\tremaining: 66.8ms\n",
      "825:\tlearn: 0.7596909\ttotal: 689ms\tremaining: 65.9ms\n",
      "826:\tlearn: 0.7580129\ttotal: 690ms\tremaining: 65.1ms\n",
      "827:\tlearn: 0.7563816\ttotal: 691ms\tremaining: 64.3ms\n",
      "828:\tlearn: 0.7555478\ttotal: 692ms\tremaining: 63.4ms\n",
      "829:\tlearn: 0.7544874\ttotal: 693ms\tremaining: 62.6ms\n",
      "830:\tlearn: 0.7527720\ttotal: 693ms\tremaining: 61.8ms\n",
      "831:\tlearn: 0.7522693\ttotal: 694ms\tremaining: 60.9ms\n",
      "832:\tlearn: 0.7509434\ttotal: 695ms\tremaining: 60.1ms\n",
      "833:\tlearn: 0.7500555\ttotal: 696ms\tremaining: 59.2ms\n",
      "834:\tlearn: 0.7494598\ttotal: 697ms\tremaining: 58.4ms\n",
      "835:\tlearn: 0.7484906\ttotal: 697ms\tremaining: 57.6ms\n",
      "836:\tlearn: 0.7466674\ttotal: 698ms\tremaining: 56.7ms\n",
      "837:\tlearn: 0.7459583\ttotal: 699ms\tremaining: 55.9ms\n",
      "838:\tlearn: 0.7442352\ttotal: 700ms\tremaining: 55.1ms\n",
      "839:\tlearn: 0.7432624\ttotal: 701ms\tremaining: 54.2ms\n",
      "840:\tlearn: 0.7422336\ttotal: 701ms\tremaining: 53.4ms\n",
      "841:\tlearn: 0.7416177\ttotal: 702ms\tremaining: 52.5ms\n",
      "842:\tlearn: 0.7411820\ttotal: 703ms\tremaining: 51.7ms\n",
      "843:\tlearn: 0.7398379\ttotal: 704ms\tremaining: 50.9ms\n",
      "844:\tlearn: 0.7381852\ttotal: 705ms\tremaining: 50.1ms\n",
      "845:\tlearn: 0.7366878\ttotal: 706ms\tremaining: 49.2ms\n",
      "846:\tlearn: 0.7355997\ttotal: 707ms\tremaining: 48.4ms\n",
      "847:\tlearn: 0.7339246\ttotal: 708ms\tremaining: 47.6ms\n",
      "848:\tlearn: 0.7330851\ttotal: 708ms\tremaining: 46.7ms\n",
      "849:\tlearn: 0.7321754\ttotal: 709ms\tremaining: 45.9ms\n",
      "850:\tlearn: 0.7316170\ttotal: 710ms\tremaining: 45.1ms\n",
      "851:\tlearn: 0.7306897\ttotal: 711ms\tremaining: 44.2ms\n",
      "852:\tlearn: 0.7296617\ttotal: 712ms\tremaining: 43.4ms\n",
      "853:\tlearn: 0.7288434\ttotal: 713ms\tremaining: 42.6ms\n",
      "854:\tlearn: 0.7277377\ttotal: 713ms\tremaining: 41.7ms\n",
      "855:\tlearn: 0.7265753\ttotal: 714ms\tremaining: 40.9ms\n",
      "856:\tlearn: 0.7261397\ttotal: 715ms\tremaining: 40ms\n",
      "857:\tlearn: 0.7255384\ttotal: 716ms\tremaining: 39.2ms\n",
      "858:\tlearn: 0.7242104\ttotal: 717ms\tremaining: 38.4ms\n",
      "859:\tlearn: 0.7230118\ttotal: 717ms\tremaining: 37.5ms\n",
      "860:\tlearn: 0.7223408\ttotal: 718ms\tremaining: 36.7ms\n",
      "861:\tlearn: 0.7216537\ttotal: 719ms\tremaining: 35.9ms\n",
      "862:\tlearn: 0.7213423\ttotal: 720ms\tremaining: 35ms\n",
      "863:\tlearn: 0.7209219\ttotal: 721ms\tremaining: 34.2ms\n",
      "864:\tlearn: 0.7199974\ttotal: 721ms\tremaining: 33.4ms\n",
      "865:\tlearn: 0.7189908\ttotal: 722ms\tremaining: 32.5ms\n",
      "866:\tlearn: 0.7173646\ttotal: 723ms\tremaining: 31.7ms\n",
      "867:\tlearn: 0.7166399\ttotal: 724ms\tremaining: 30.9ms\n",
      "868:\tlearn: 0.7150703\ttotal: 725ms\tremaining: 30ms\n",
      "869:\tlearn: 0.7137208\ttotal: 726ms\tremaining: 29.2ms\n",
      "870:\tlearn: 0.7125802\ttotal: 726ms\tremaining: 28.4ms\n",
      "871:\tlearn: 0.7112611\ttotal: 727ms\tremaining: 27.5ms\n",
      "872:\tlearn: 0.7107675\ttotal: 728ms\tremaining: 26.7ms\n",
      "873:\tlearn: 0.7102342\ttotal: 729ms\tremaining: 25.8ms\n",
      "874:\tlearn: 0.7091095\ttotal: 730ms\tremaining: 25ms\n",
      "875:\tlearn: 0.7077299\ttotal: 730ms\tremaining: 24.2ms\n",
      "876:\tlearn: 0.7068953\ttotal: 731ms\tremaining: 23.3ms\n",
      "877:\tlearn: 0.7063266\ttotal: 732ms\tremaining: 22.5ms\n",
      "878:\tlearn: 0.7058319\ttotal: 733ms\tremaining: 21.7ms\n",
      "879:\tlearn: 0.7038283\ttotal: 734ms\tremaining: 20.8ms\n",
      "880:\tlearn: 0.7028983\ttotal: 734ms\tremaining: 20ms\n",
      "881:\tlearn: 0.7023647\ttotal: 735ms\tremaining: 19.2ms\n",
      "882:\tlearn: 0.7015398\ttotal: 736ms\tremaining: 18.3ms\n",
      "883:\tlearn: 0.7002302\ttotal: 737ms\tremaining: 17.5ms\n",
      "884:\tlearn: 0.6997563\ttotal: 738ms\tremaining: 16.7ms\n",
      "885:\tlearn: 0.6986414\ttotal: 740ms\tremaining: 15.9ms\n",
      "886:\tlearn: 0.6981189\ttotal: 742ms\tremaining: 15ms\n",
      "887:\tlearn: 0.6968054\ttotal: 743ms\tremaining: 14.2ms\n",
      "888:\tlearn: 0.6958512\ttotal: 744ms\tremaining: 13.4ms\n",
      "889:\tlearn: 0.6952128\ttotal: 744ms\tremaining: 12.5ms\n",
      "890:\tlearn: 0.6947026\ttotal: 745ms\tremaining: 11.7ms\n",
      "891:\tlearn: 0.6939774\ttotal: 746ms\tremaining: 10.9ms\n",
      "892:\tlearn: 0.6934359\ttotal: 747ms\tremaining: 10ms\n",
      "893:\tlearn: 0.6932200\ttotal: 748ms\tremaining: 9.2ms\n",
      "894:\tlearn: 0.6923296\ttotal: 748ms\tremaining: 8.36ms\n",
      "895:\tlearn: 0.6918320\ttotal: 749ms\tremaining: 7.53ms\n",
      "896:\tlearn: 0.6911554\ttotal: 750ms\tremaining: 6.69ms\n",
      "897:\tlearn: 0.6895043\ttotal: 751ms\tremaining: 5.86ms\n",
      "898:\tlearn: 0.6881582\ttotal: 752ms\tremaining: 5.02ms\n",
      "899:\tlearn: 0.6877643\ttotal: 753ms\tremaining: 4.18ms\n",
      "900:\tlearn: 0.6853424\ttotal: 754ms\tremaining: 3.35ms\n",
      "901:\tlearn: 0.6846901\ttotal: 755ms\tremaining: 2.51ms\n",
      "902:\tlearn: 0.6840272\ttotal: 756ms\tremaining: 1.68ms\n",
      "903:\tlearn: 0.6835366\ttotal: 757ms\tremaining: 837us\n",
      "904:\tlearn: 0.6833696\ttotal: 758ms\tremaining: 0us\n"
     ]
    }
   ],
   "source": [
    "best_params = {\n",
    "    'iterations': 905,\n",
    "    'depth': 5,\n",
    "    'learning_rate': 0.23486244517249405,\n",
    "    'l2_leaf_reg': 4.342072180612699,\n",
    "    'border_count': 60,\n",
    "    'bagging_temperature': 0.875725464762179,\n",
    "    'random_strength': 7.45320153234948\n",
    "}\n",
    "\n",
    "final_model = CatBoostRegressor(**best_params)\n",
    "final_model.fit(X_train, y_train)\n",
    "\n",
    "df_test_encoded['Total_weeks_predict'] = final_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "70057c5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total_Weeks</th>\n",
       "      <th>Total_weeks_predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2054</th>\n",
       "      <td>10</td>\n",
       "      <td>8.014422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2055</th>\n",
       "      <td>7</td>\n",
       "      <td>5.051800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2056</th>\n",
       "      <td>5</td>\n",
       "      <td>8.659341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2057</th>\n",
       "      <td>6</td>\n",
       "      <td>10.175994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2058</th>\n",
       "      <td>4</td>\n",
       "      <td>6.854192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2059</th>\n",
       "      <td>11</td>\n",
       "      <td>11.600640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2060</th>\n",
       "      <td>5</td>\n",
       "      <td>4.844764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2061</th>\n",
       "      <td>13</td>\n",
       "      <td>10.879719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2062</th>\n",
       "      <td>4</td>\n",
       "      <td>6.032510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2063</th>\n",
       "      <td>4</td>\n",
       "      <td>15.871185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2064</th>\n",
       "      <td>5</td>\n",
       "      <td>10.399626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2065</th>\n",
       "      <td>6</td>\n",
       "      <td>4.345331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2066</th>\n",
       "      <td>7</td>\n",
       "      <td>7.262938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2067</th>\n",
       "      <td>4</td>\n",
       "      <td>5.991001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2068</th>\n",
       "      <td>7</td>\n",
       "      <td>5.607912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2069</th>\n",
       "      <td>7</td>\n",
       "      <td>7.091089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2070</th>\n",
       "      <td>5</td>\n",
       "      <td>5.778854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2071</th>\n",
       "      <td>16</td>\n",
       "      <td>16.310370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2072</th>\n",
       "      <td>8</td>\n",
       "      <td>7.042545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2073</th>\n",
       "      <td>6</td>\n",
       "      <td>5.851639</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Total_Weeks  Total_weeks_predict\n",
       "2054           10             8.014422\n",
       "2055            7             5.051800\n",
       "2056            5             8.659341\n",
       "2057            6            10.175994\n",
       "2058            4             6.854192\n",
       "2059           11            11.600640\n",
       "2060            5             4.844764\n",
       "2061           13            10.879719\n",
       "2062            4             6.032510\n",
       "2063            4            15.871185\n",
       "2064            5            10.399626\n",
       "2065            6             4.345331\n",
       "2066            7             7.262938\n",
       "2067            4             5.991001\n",
       "2068            7             5.607912\n",
       "2069            7             7.091089\n",
       "2070            5             5.778854\n",
       "2071           16            16.310370\n",
       "2072            8             7.042545\n",
       "2073            6             5.851639"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_encoded[['Total_Weeks','Total_weeks_predict']].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "239611fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Total_Weeks  Total_weeks_predict  Diff  Abs_Diff\n",
      "2054           10             8.014422     2         2\n",
      "2055            7             5.051800     2         2\n",
      "2056            5             8.659341    -4         4\n",
      "2057            6            10.175994    -4         4\n",
      "2058            4             6.854192    -3         3\n",
      "2059           11            11.600640    -1         1\n",
      "2060            5             4.844764     0         0\n",
      "2061           13            10.879719     2         2\n",
      "2062            4             6.032510    -2         2\n",
      "2063            4            15.871185   -12        12\n",
      "\n",
      " 오차 통계 요약:\n",
      "         Diff  Abs_Diff\n",
      "count  514.00    514.00\n",
      "mean    -0.07      2.42\n",
      "std      4.01      3.19\n",
      "min    -15.00      0.00\n",
      "25%     -2.00      1.00\n",
      "50%      0.00      2.00\n",
      "75%      1.00      3.00\n",
      "max     35.00     35.00\n",
      "\n",
      "평균 오차 (예측의 방향성 확인용): -0.070 주\n",
      "평균 절대 오차 (실질 오차 크기): 2.424 주\n"
     ]
    }
   ],
   "source": [
    "# 예측 결과를 반올림하여 정수형으로 변환 후 실제값과의 차이 계산\n",
    "df_test_encoded[\"Diff\"] = df_test_encoded[\"Total_Weeks\"] - np.round(df_test_encoded[\"Total_weeks_predict\"]).astype(int)\n",
    "\n",
    "# 절대 오차(오차 크기)도 계산\n",
    "df_test_encoded[\"Abs_Diff\"] = df_test_encoded[\"Diff\"].abs()\n",
    "\n",
    "# 요약 통계 확인\n",
    "print(df_test_encoded[[\"Total_Weeks\", \"Total_weeks_predict\", \"Diff\", \"Abs_Diff\"]].head(10))\n",
    "print(\"\\n 오차 통계 요약:\")\n",
    "print(df_test_encoded[[\"Diff\", \"Abs_Diff\"]].describe().round(2))\n",
    "\n",
    "# 평균 오차 (bias) 및 평균 절대 오차 (MAE)\n",
    "mean_diff = df_test_encoded[\"Diff\"].mean()\n",
    "mean_abs_diff = df_test_encoded[\"Abs_Diff\"].mean()\n",
    "\n",
    "print(f\"\\n평균 오차 (예측의 방향성 확인용): {mean_diff:.3f} 주\")\n",
    "print(f\"평균 절대 오차 (실질 오차 크기): {mean_abs_diff:.3f} 주\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b908370e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\uni\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 8722 (\\N{MINUS SIGN}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# 시각화 스타일 설정\n",
    "sns.set(style=\"whitegrid\", font=\"Malgun Gothic\")  # 한글 폰트 설정 (Windows 기준)\n",
    "\n",
    "# 오차 분포 히스토그램\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.histplot(df_test_encoded[\"Diff\"], kde=True, bins=20, color=\"skyblue\", edgecolor=\"black\")\n",
    "plt.axvline(0, color=\"red\", linestyle=\"--\", label=\"정확 예측 (0)\")\n",
    "plt.title(\"예측 오차 분포 (실제 - 예측)\")\n",
    "plt.xlabel(\"오차 (주 단위)\")\n",
    "plt.ylabel(\"빈도수\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a72ceba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      Movie_Title  Total_Weeks  Total_weeks_predict\n",
      "2063  인피니트 15주년 콘서트 리미티드 에디션 더 무비            4            15.871185\n",
      "2078                         색, 계           26            16.219342\n",
      "2079                           원스           33            22.007970\n",
      "2095                     컴플리트 언노운           19             6.107564\n",
      "2112                    마당을 나온 암탉           24            12.052661\n",
      "2147                    프리즌 이스케이프           11            22.787937\n",
      "2168                      퍼펙트 데이즈           39            18.597239\n",
      "2229                          그루지            7            22.073774\n",
      "2262                         데스노트            6            17.766223\n",
      "2269                      한국이 싫어서           17             6.605492\n",
      "2389                  아치의 노래, 정태춘           24            12.790611\n",
      "2432                      본 얼티메이텀           10            22.650353\n",
      "2485                   권순분여사 납치사건            7            21.951589\n",
      "2488                       위대한 침묵           52            22.396087\n",
      "2497                   아픈 만큼 사랑한다           26            14.327277\n",
      "2518                            듄            9            22.393361\n",
      "2543                   극장판 주술회전 0           59            24.119202\n",
      "2561                    첫키스만 50번째            6            15.780203\n"
     ]
    }
   ],
   "source": [
    "print(df_test_encoded[ df_test_encoded[\"Abs_Diff\"] >= 10 ][['Movie_Title','Total_Weeks','Total_weeks_predict']])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
